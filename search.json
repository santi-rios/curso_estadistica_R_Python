[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Inicio",
    "section": "",
    "text": "Bienvenido al curso de R para principiantes. En este curso, aprenderás a programar en R, un lenguaje de programación ampliamente utilizado en análisis de datos y estadística. R es una herramienta poderosa para visualizar datos, realizar cálculos estadísticos y crear gráficos."
  },
  {
    "objectID": "docs/70-b-pruebahipotesis-intro.html",
    "href": "docs/70-b-pruebahipotesis-intro.html",
    "title": "Introducción a las Pruebas de Hipótesis",
    "section": "",
    "text": "Las pruebas de hipótesis son una parte fundamental del método científico y se utilizan para evaluar la validez de las afirmaciones sobre un fenómeno o proceso.\nEn la investigación científica, las pruebas de hipótesis se utilizan para determinar si los resultados observados son estadísticamente significativos o si se deben a la variabilidad aleatoria de los datos.\nEn este módulo, exploraremos los conceptos básicos de las pruebas de hipótesis.\nEste módulo es un poco más teórico que práctico’. Mucho de lo que se discute aquí es fundamental para comprender cómo funcionan las pruebas de hipótesis y cómo interpretar los resultados.\n\n\n\nTener una comprensión de las bases filosóficas del método científico es esencial para realizar investigaciones de manera adecuada. Aunque existen diversos enfoques sobre la filosofía de la ciencia en distintos contextos, es importante partir de algunas referencias clave para comprender las diversas perspectivas que se aplican en la investigación científica. Entre las obras recomendadas se encuentran las de autores como Chalmers (1999) y Gower (1997), quienes ofrecen una visión general del desarrollo de la ciencia y sus métodos. En este módulo encontrarás estas lecturas si gustas profundizar en el tema.\n\n\n\n\n\n\nTip\n\n\n\nDesde un enfoque biológico, textos como los de Ford (2000), James & McCulloch (1985), Loehle (1987) y Underwood (1990, 1991) son útiles para aplicar la filosofía científica en las ciencias naturales. Por otro lado, Maxwell & Delaney (1990) ofrecen una perspectiva desde las ciencias del comportamiento, mientras que Hilborn & Mangel (1997) presentan alternativas al enfoque popperiano en situaciones donde no es posible realizar pruebas experimentales.\n\n\n\n\n\n\nEn el método científico, una hipótesis es una declaración que puede ser probada mediante investigación, de preferencia de manera experimental.\nCuando se formula una hipótesis, se puede predecir un conjunto de observaciones bajo ciertas condiciones si el modelo o teoría que se está probando es correcto.\nEste proceso de hacer predicciones y someterlas a prueba es parte de lo que Peters (1991) denominó la fase analítica, pública o popperiana del método científico.\n\nAquí, las hipótesis se evalúan mediante pruebas críticas o formales, con el objetivo de falsificarlas (es decir, refutarlas si no son correctas). Este enfoque sigue la filosofía de Karl Popper, quien sostenía que las teorías científicas nunca pueden ser probadas definitivamente, pero sí pueden ser falsificadas.\n\n\n\n\n\n\n\n\nKarl Popper y el falsacionismo\n\n\n\nLa teoría de Karl Popper, conocida como falsacionismo, es un enfoque filosófico para la ciencia que se centra en la idea de que una hipótesis o teoría científica nunca puede ser probada como verdadera de manera definitiva, sino que solo puede ser falsada o refutada. Popper argumentó que el progreso científico se logra a través de la eliminación de teorías falsas, más que por la acumulación de confirmaciones.\n\n\nFalsabilidad: Una característica esencial de una teoría científica es que debe ser falsable, es decir, debe ser posible concebir un experimento o una observación que pueda demostrar que la teoría es falsa. Si una teoría no es falsable, Popper la considera no científica. Por ejemplo, no puedes probar que todos los cisnes son blancos, pero puedes refutar esta afirmación si encuentras un cisne no blanco.\nProvisionalidad del conocimiento: Según Popper, todo conocimiento científico es provisional y está sujeto a revisión. Ninguna teoría puede ser considerada definitiva, ya que siempre es posible que nuevas evidencias la refuten.\nPreferencia por teorías arriesgadas: Popper valoraba las teorías que hacen predicciones específicas y arriesgadas, porque estas son más susceptibles de ser falsadas. Cuanto más arriesgada es una predicción y más improbable parecía antes de la prueba, más informativa es la teoría.\nCrítica y debate: La ciencia avanza a través de la crítica constante y el debate de las teorías existentes, buscando siempre refutar y mejorar la comprensión actual.\n\n\n\nLa falsabilidad de Popper se relaciona directamente con la prueba de hipótesis en la estadística y la investigación científica. Algunos puntos clave de esta relación son:\n\nFormulación de Hipótesis Nula (\\(H_0\\)): En la prueba de hipótesis, se formula una hipótesis nula que representa una afirmación a ser probada (por ejemplo, que no hay efecto o que dos grupos no son diferentes). La hipótesis nula es el equivalente a la teoría que uno intenta falsar.\nFalsación de la Hipótesis Nula: El objetivo de una prueba de hipótesis es intentar refutar la hipótesis nula. Si los datos proporcionan suficiente evidencia en contra de la hipótesis nula, se rechaza a favor de la hipótesis alternativa (\\(H_1\\)), que representa una afirmación contraria (por ejemplo, que hay un efecto o que los grupos son diferentes).\n\nOJO: No se puede probar la hipótesis alternativa directamente, solo se puede rechazar la hipótesis nula. NUNCA decimos que aceptamos la hipótesis alternativa, solo que no rechazamos la hipótesis nula.\n\nCriterios de Decisión: Se utilizan criterios estadísticos, como niveles de significancia y valores p, para decidir si se rechaza o no la hipótesis nula. Un resultado estadísticamente significativo sugiere que hay suficiente evidencia para rechazar la hipótesis nula, aunque esto no “prueba” la hipótesis alternativa.\nProvisionalidad de los Resultados: Similar al enfoque de Popper, los resultados de las pruebas de hipótesis son provisionales, sujetos a revisión y refutación con nuevas evidencias o mejores análisis.\n\n\n\n\n\nLos filósofos (como Popper) han señalado que probar una teoría de manera definitiva es lógicamente imposible.\nEsto se debe a que, para probar completamente una hipótesis, sería necesario observar absolutamente todos los casos relacionados con la hipótesis.\nUn ejemplo clásico de esto es la creencia de que todos los cisnes son blancos, basada en siglos de observación en Europa. Sin embargo, esta creencia fue refutada con el descubrimiento de cisnes negros en Australia.\n\n\n\n\n\n\n\n\nEn el contexto de las pruebas científicas, se introduce la hipótesis nula como un punto de partida para la falsificación.\nLa hipótesis nula incluye todas las posibilidades excepto la predicción de la hipótesis original.\n\nPor ejemplo, en un estudio sobre la bioluminiscencia de los dinoflagelados, la hipótesis nula podría ser que la bioluminiscencia no tiene ningún efecto o incluso reduce la tasa de mortalidad de los copépodos que se alimentan de dinoflagelados.\nEsta hipótesis nula abarca todas las posibilidades excepto la predicción de que la bioluminiscencia aumenta la mortalidad de los copépodos.\n\n\n\n\n\nSupongamos que un grupo de investigadores está estudiando un nuevo medicamento que se cree que reduce la presión arterial en pacientes con hipertensión.\n\nhipótesis alternativa (\\(H_a\\)): La hipótesis original de los investigadores es que “el nuevo medicamento reduce la presión arterial en pacientes con hipertensión”. Esta es la hipótesis que los investigadores esperan demostrar.\nLa hipótesis nula (\\(H_0\\)), en cambio, es una declaración que niega la hipótesis original. En este caso, sería: “El nuevo medicamento no tiene ningún efecto en la reducción de la presión arterial en pacientes con hipertensión”.\n\nLa hipótesis nula incluye todas las posibilidades excepto la predicción de la hipótesis original. Esto significa que bajo la hipótesis nula, cualquier observación que no resulte en una reducción de la presión arterial significativa se considera consistente con esta hipótesis. Por ejemplo, si el medicamento:\n\nNo tiene efecto en la presión arterial (los niveles de presión arterial permanecen iguales).\nAumenta la presión arterial.\nReduce la presión arterial, pero no de manera significativa.\n\nCada una de estas situaciones es consistente con la hipótesis nula, ya que en ninguna de ellas se observa el efecto específico que los investigadores desean comprobar (una reducción significativa de la presión arterial).\nProceso de Prueba: Durante el análisis estadístico, se recopilan datos del estudio y se evalúa si hay suficiente evidencia para rechazar la hipótesis nula en favor de la hipótesis original. Si los datos muestran una reducción significativa en la presión arterial, los investigadores pueden rechazar la hipótesis nula y aceptar que el medicamento tiene un efecto positivo. Sin embargo, si no hay evidencia suficiente, no pueden rechazar la hipótesis nula, lo que significa que no hay pruebas concluyentes de que el medicamento funcione como se esperaba."
  },
  {
    "objectID": "docs/70-b-pruebahipotesis-intro.html#introducción-a-las-pruebas-de-hipótesis",
    "href": "docs/70-b-pruebahipotesis-intro.html#introducción-a-las-pruebas-de-hipótesis",
    "title": "Introducción a las Pruebas de Hipótesis",
    "section": "",
    "text": "Las pruebas de hipótesis son una parte fundamental del método científico y se utilizan para evaluar la validez de las afirmaciones sobre un fenómeno o proceso.\nEn la investigación científica, las pruebas de hipótesis se utilizan para determinar si los resultados observados son estadísticamente significativos o si se deben a la variabilidad aleatoria de los datos.\nEn este módulo, exploraremos los conceptos básicos de las pruebas de hipótesis.\nEste módulo es un poco más teórico que práctico’. Mucho de lo que se discute aquí es fundamental para comprender cómo funcionan las pruebas de hipótesis y cómo interpretar los resultados.\n\n\n\nTener una comprensión de las bases filosóficas del método científico es esencial para realizar investigaciones de manera adecuada. Aunque existen diversos enfoques sobre la filosofía de la ciencia en distintos contextos, es importante partir de algunas referencias clave para comprender las diversas perspectivas que se aplican en la investigación científica. Entre las obras recomendadas se encuentran las de autores como Chalmers (1999) y Gower (1997), quienes ofrecen una visión general del desarrollo de la ciencia y sus métodos. En este módulo encontrarás estas lecturas si gustas profundizar en el tema.\n\n\n\n\n\n\nTip\n\n\n\nDesde un enfoque biológico, textos como los de Ford (2000), James & McCulloch (1985), Loehle (1987) y Underwood (1990, 1991) son útiles para aplicar la filosofía científica en las ciencias naturales. Por otro lado, Maxwell & Delaney (1990) ofrecen una perspectiva desde las ciencias del comportamiento, mientras que Hilborn & Mangel (1997) presentan alternativas al enfoque popperiano en situaciones donde no es posible realizar pruebas experimentales.\n\n\n\n\n\n\nEn el método científico, una hipótesis es una declaración que puede ser probada mediante investigación, de preferencia de manera experimental.\nCuando se formula una hipótesis, se puede predecir un conjunto de observaciones bajo ciertas condiciones si el modelo o teoría que se está probando es correcto.\nEste proceso de hacer predicciones y someterlas a prueba es parte de lo que Peters (1991) denominó la fase analítica, pública o popperiana del método científico.\n\nAquí, las hipótesis se evalúan mediante pruebas críticas o formales, con el objetivo de falsificarlas (es decir, refutarlas si no son correctas). Este enfoque sigue la filosofía de Karl Popper, quien sostenía que las teorías científicas nunca pueden ser probadas definitivamente, pero sí pueden ser falsificadas.\n\n\n\n\n\n\n\n\nKarl Popper y el falsacionismo\n\n\n\nLa teoría de Karl Popper, conocida como falsacionismo, es un enfoque filosófico para la ciencia que se centra en la idea de que una hipótesis o teoría científica nunca puede ser probada como verdadera de manera definitiva, sino que solo puede ser falsada o refutada. Popper argumentó que el progreso científico se logra a través de la eliminación de teorías falsas, más que por la acumulación de confirmaciones.\n\n\nFalsabilidad: Una característica esencial de una teoría científica es que debe ser falsable, es decir, debe ser posible concebir un experimento o una observación que pueda demostrar que la teoría es falsa. Si una teoría no es falsable, Popper la considera no científica. Por ejemplo, no puedes probar que todos los cisnes son blancos, pero puedes refutar esta afirmación si encuentras un cisne no blanco.\nProvisionalidad del conocimiento: Según Popper, todo conocimiento científico es provisional y está sujeto a revisión. Ninguna teoría puede ser considerada definitiva, ya que siempre es posible que nuevas evidencias la refuten.\nPreferencia por teorías arriesgadas: Popper valoraba las teorías que hacen predicciones específicas y arriesgadas, porque estas son más susceptibles de ser falsadas. Cuanto más arriesgada es una predicción y más improbable parecía antes de la prueba, más informativa es la teoría.\nCrítica y debate: La ciencia avanza a través de la crítica constante y el debate de las teorías existentes, buscando siempre refutar y mejorar la comprensión actual.\n\n\n\nLa falsabilidad de Popper se relaciona directamente con la prueba de hipótesis en la estadística y la investigación científica. Algunos puntos clave de esta relación son:\n\nFormulación de Hipótesis Nula (\\(H_0\\)): En la prueba de hipótesis, se formula una hipótesis nula que representa una afirmación a ser probada (por ejemplo, que no hay efecto o que dos grupos no son diferentes). La hipótesis nula es el equivalente a la teoría que uno intenta falsar.\nFalsación de la Hipótesis Nula: El objetivo de una prueba de hipótesis es intentar refutar la hipótesis nula. Si los datos proporcionan suficiente evidencia en contra de la hipótesis nula, se rechaza a favor de la hipótesis alternativa (\\(H_1\\)), que representa una afirmación contraria (por ejemplo, que hay un efecto o que los grupos son diferentes).\n\nOJO: No se puede probar la hipótesis alternativa directamente, solo se puede rechazar la hipótesis nula. NUNCA decimos que aceptamos la hipótesis alternativa, solo que no rechazamos la hipótesis nula.\n\nCriterios de Decisión: Se utilizan criterios estadísticos, como niveles de significancia y valores p, para decidir si se rechaza o no la hipótesis nula. Un resultado estadísticamente significativo sugiere que hay suficiente evidencia para rechazar la hipótesis nula, aunque esto no “prueba” la hipótesis alternativa.\nProvisionalidad de los Resultados: Similar al enfoque de Popper, los resultados de las pruebas de hipótesis son provisionales, sujetos a revisión y refutación con nuevas evidencias o mejores análisis.\n\n\n\n\n\nLos filósofos (como Popper) han señalado que probar una teoría de manera definitiva es lógicamente imposible.\nEsto se debe a que, para probar completamente una hipótesis, sería necesario observar absolutamente todos los casos relacionados con la hipótesis.\nUn ejemplo clásico de esto es la creencia de que todos los cisnes son blancos, basada en siglos de observación en Europa. Sin embargo, esta creencia fue refutada con el descubrimiento de cisnes negros en Australia.\n\n\n\n\n\n\n\n\nEn el contexto de las pruebas científicas, se introduce la hipótesis nula como un punto de partida para la falsificación.\nLa hipótesis nula incluye todas las posibilidades excepto la predicción de la hipótesis original.\n\nPor ejemplo, en un estudio sobre la bioluminiscencia de los dinoflagelados, la hipótesis nula podría ser que la bioluminiscencia no tiene ningún efecto o incluso reduce la tasa de mortalidad de los copépodos que se alimentan de dinoflagelados.\nEsta hipótesis nula abarca todas las posibilidades excepto la predicción de que la bioluminiscencia aumenta la mortalidad de los copépodos.\n\n\n\n\n\nSupongamos que un grupo de investigadores está estudiando un nuevo medicamento que se cree que reduce la presión arterial en pacientes con hipertensión.\n\nhipótesis alternativa (\\(H_a\\)): La hipótesis original de los investigadores es que “el nuevo medicamento reduce la presión arterial en pacientes con hipertensión”. Esta es la hipótesis que los investigadores esperan demostrar.\nLa hipótesis nula (\\(H_0\\)), en cambio, es una declaración que niega la hipótesis original. En este caso, sería: “El nuevo medicamento no tiene ningún efecto en la reducción de la presión arterial en pacientes con hipertensión”.\n\nLa hipótesis nula incluye todas las posibilidades excepto la predicción de la hipótesis original. Esto significa que bajo la hipótesis nula, cualquier observación que no resulte en una reducción de la presión arterial significativa se considera consistente con esta hipótesis. Por ejemplo, si el medicamento:\n\nNo tiene efecto en la presión arterial (los niveles de presión arterial permanecen iguales).\nAumenta la presión arterial.\nReduce la presión arterial, pero no de manera significativa.\n\nCada una de estas situaciones es consistente con la hipótesis nula, ya que en ninguna de ellas se observa el efecto específico que los investigadores desean comprobar (una reducción significativa de la presión arterial).\nProceso de Prueba: Durante el análisis estadístico, se recopilan datos del estudio y se evalúa si hay suficiente evidencia para rechazar la hipótesis nula en favor de la hipótesis original. Si los datos muestran una reducción significativa en la presión arterial, los investigadores pueden rechazar la hipótesis nula y aceptar que el medicamento tiene un efecto positivo. Sin embargo, si no hay evidencia suficiente, no pueden rechazar la hipótesis nula, lo que significa que no hay pruebas concluyentes de que el medicamento funcione como se esperaba."
  },
  {
    "objectID": "docs/70-b-pruebahipotesis-intro.html#principios-clave-del-falsacionismo-de-popper",
    "href": "docs/70-b-pruebahipotesis-intro.html#principios-clave-del-falsacionismo-de-popper",
    "title": "Introducción a las Pruebas de Hipótesis",
    "section": "",
    "text": "Falsabilidad: Una característica esencial de una teoría científica es que debe ser falsable, es decir, debe ser posible concebir un experimento o una observación que pueda demostrar que la teoría es falsa. Si una teoría no es falsable, Popper la considera no científica. Por ejemplo, no puedes probar que todos los cisnes son blancos, pero puedes refutar esta afirmación si encuentras un cisne no blanco.\nProvisionalidad del conocimiento: Según Popper, todo conocimiento científico es provisional y está sujeto a revisión. Ninguna teoría puede ser considerada definitiva, ya que siempre es posible que nuevas evidencias la refuten.\nPreferencia por teorías arriesgadas: Popper valoraba las teorías que hacen predicciones específicas y arriesgadas, porque estas son más susceptibles de ser falsadas. Cuanto más arriesgada es una predicción y más improbable parecía antes de la prueba, más informativa es la teoría.\nCrítica y debate: La ciencia avanza a través de la crítica constante y el debate de las teorías existentes, buscando siempre refutar y mejorar la comprensión actual."
  },
  {
    "objectID": "docs/70-b-pruebahipotesis-intro.html#relación-con-la-prueba-de-hipótesis",
    "href": "docs/70-b-pruebahipotesis-intro.html#relación-con-la-prueba-de-hipótesis",
    "title": "Introducción a las Pruebas de Hipótesis",
    "section": "",
    "text": "La falsabilidad de Popper se relaciona directamente con la prueba de hipótesis en la estadística y la investigación científica. Algunos puntos clave de esta relación son:\n\nFormulación de Hipótesis Nula (\\(H_0\\)): En la prueba de hipótesis, se formula una hipótesis nula que representa una afirmación a ser probada (por ejemplo, que no hay efecto o que dos grupos no son diferentes). La hipótesis nula es el equivalente a la teoría que uno intenta falsar.\nFalsación de la Hipótesis Nula: El objetivo de una prueba de hipótesis es intentar refutar la hipótesis nula. Si los datos proporcionan suficiente evidencia en contra de la hipótesis nula, se rechaza a favor de la hipótesis alternativa (\\(H_1\\)), que representa una afirmación contraria (por ejemplo, que hay un efecto o que los grupos son diferentes).\n\nOJO: No se puede probar la hipótesis alternativa directamente, solo se puede rechazar la hipótesis nula. NUNCA decimos que aceptamos la hipótesis alternativa, solo que no rechazamos la hipótesis nula.\n\nCriterios de Decisión: Se utilizan criterios estadísticos, como niveles de significancia y valores p, para decidir si se rechaza o no la hipótesis nula. Un resultado estadísticamente significativo sugiere que hay suficiente evidencia para rechazar la hipótesis nula, aunque esto no “prueba” la hipótesis alternativa.\nProvisionalidad de los Resultados: Similar al enfoque de Popper, los resultados de las pruebas de hipótesis son provisionales, sujetos a revisión y refutación con nuevas evidencias o mejores análisis."
  },
  {
    "objectID": "docs/70-b-pruebahipotesis-intro.html#la-imposibilidad-de-probar-una-teoría",
    "href": "docs/70-b-pruebahipotesis-intro.html#la-imposibilidad-de-probar-una-teoría",
    "title": "Introducción a las Pruebas de Hipótesis",
    "section": "",
    "text": "Los filósofos (como Popper) han señalado que probar una teoría de manera definitiva es lógicamente imposible.\nEsto se debe a que, para probar completamente una hipótesis, sería necesario observar absolutamente todos los casos relacionados con la hipótesis.\nUn ejemplo clásico de esto es la creencia de que todos los cisnes son blancos, basada en siglos de observación en Europa. Sin embargo, esta creencia fue refutada con el descubrimiento de cisnes negros en Australia."
  },
  {
    "objectID": "docs/70-b-pruebahipotesis-intro.html#resumen-hasta-ahora",
    "href": "docs/70-b-pruebahipotesis-intro.html#resumen-hasta-ahora",
    "title": "Introducción a las Pruebas de Hipótesis",
    "section": "Resumen hasta ahora",
    "text": "Resumen hasta ahora\n\nEl método científico es un proceso basado en la formulación de hipótesis que pueden ser falsificadas mediante pruebas experimentales.\nLa elección de qué hipótesis probar debe basarse tanto en el contenido empírico de las mismas como en su capacidad para hacer predicciones claras y distintivas.\nAdemás, es importante recordar que, aunque una hipótesis no puede ser probada de manera definitiva, sí puede ser refutada por una sola observación en contra."
  },
  {
    "objectID": "docs/70-b-pruebahipotesis-intro.html#ejemplo-en-r",
    "href": "docs/70-b-pruebahipotesis-intro.html#ejemplo-en-r",
    "title": "Introducción a las Pruebas de Hipótesis",
    "section": "Ejemplo en R",
    "text": "Ejemplo en R\nA continuación, un ejemplo simple de cómo realizar una prueba de hipótesis en R. Supongamos que queremos probar si el promedio de una variable numérica es mayor que un valor específico (por ejemplo, si el promedio de una muestra es mayor que 50).\n\nRPython\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEn este código:\n\nGeneramos un conjunto de datos con una variable llamada valor, que sigue una distribución normal con media de 52 y desviación estándar de 10.\nRealizamos una prueba t para evaluar la hipótesis nula de que el promedio de valor es igual a 50, contra la hipótesis alternativa de que el promedio es mayor que 50.\nEl resultado de t_test nos indicará si podemos rechazar la hipótesis nula a favor de la hipótesis alternativa, dependiendo del valor p.\n\nSi el valor p es menor que el nivel de significancia (generalmente 0.05), rechazaríamos la hipótesis nula y concluiríamos que el promedio de valor es mayor que 50.\nEn este caso, el valor p es 0.0001, lo que sugiere que hay suficiente evidencia para rechazar la hipótesis nula."
  },
  {
    "objectID": "docs/74-anova-medidasrep.html",
    "href": "docs/74-anova-medidasrep.html",
    "title": "ANOVA de medidas repetidas",
    "section": "",
    "text": "El ANOVA de medidas repetidas se utiliza para analizar datos donde los mismos sujetos se miden más de una vez. Esta prueba también se conoce como ANOVA intra-sujetos o ANOVA con medidas repetidas. El término “intra-sujetos” significa que los mismos individuos son medidos en la misma variable de resultado bajo diferentes puntos de tiempo o condiciones. Por ejemplo, podrías haber medido la puntuación de autoestima (la variable de resultado o dependiente) de 10 individuos en tres momentos durante una dieta específica para determinar si su autoestima mejoró.\nExisten diferentes tipos de ANOVA de medidas repetidas, incluyendo:"
  },
  {
    "objectID": "docs/74-anova-medidasrep.html#anova-de-una-vía",
    "href": "docs/74-anova-medidasrep.html#anova-de-una-vía",
    "title": "ANOVA de medidas repetidas",
    "section": "ANOVA de una vía",
    "text": "ANOVA de una vía\n\nDatos\n\nvamos a usar datos de autoestima medido en tres momentos diferentes:\n\n\n\n\n\n\n\n\n\n\nid: identificador del sujeto\nt_: tiempo de medición\n\nVamos a ordenar los datos para que las 3 columnas de tiempo estén juntas en una sola columna:\n\n\n\n\n\n\n\n\n\n\nANOVA\n\nVamos a realizar el ANOVA con la función anova_test() de rstatix.\nObserva que estamos especificando el id del sujeto y la variable tiempo como factores intra-sujetos. Esto es importante para que el análisis sea correcto y considere que es un diseño de medidas repetidas. Al final, se usa get_anova_table() para obtener la tabla ANOVA.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSi quisiéramos realizar este mismo ANOVA con la función aov() de R, tendríamos que especificar el diseño de medidas repetidas con la función Error(). Esto puede ser un poco más complicado que con anova_test().\n\n\n\n\n\n\n\n\nTambién se puede realizar con la función ezANOVA() del paquete ez:\n\n\n\n\n\n\n\n\n\n\n\n\ngráfico y post-hoc\n\nVamos a hacer el gráfico con los valores del ANOVA y los resultados del post-hoc:"
  },
  {
    "objectID": "docs/74-anova-medidasrep.html#anova-de-dos-vías",
    "href": "docs/74-anova-medidasrep.html#anova-de-dos-vías",
    "title": "ANOVA de medidas repetidas",
    "section": "ANOVA de dos vías",
    "text": "ANOVA de dos vías\n\nDatos\nAhora usaremos los datos selfesteem2 que contienen autoestima de 12 individuos en 2 tiempos bajo 2 condiciones diferentes: control y tratamiento.\n\n\n\n\n\n\n\n\n\nLimpiar datos:\n\n\n\n\n\n\n\n\n\n\n\nANOVA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncon aov:\n\n\n\n\n\n\n\n\n\n\nCon ez:"
  },
  {
    "objectID": "docs/23-distribuciones-probabilidad.html#introducción-y-objetivos",
    "href": "docs/23-distribuciones-probabilidad.html#introducción-y-objetivos",
    "title": "Distribuciones de Probabilidad",
    "section": "Introducción y Objetivos",
    "text": "Introducción y Objetivos\n\nAntes de comenzar con las lecciones de estadística, es importante entender las distribuciones de probabilidad.\nLas distribuciones de probabilidad describen cómo se distribuyen los valores posibles de una variable aleatoria. Estas representan la probabilidad de los valores que puede tomar una variable, siendo algunos valores más probables que otros.\nUna variable aleatoria es una variable (lección previa) cuyos valores son el resultado de un fenómeno aleatorio, como el lanzamiento de un dado o la altura de un grupo de personas.\nEn las siguientes lecciones, abordaremos algunas de las distribuciones más comunes y cómo trabajarlas en R.\nPara ello, nos enfocaremos en un ejemplo fictício de alturas de jirafas “miniatura” en 2 diferentes islas.\n\nImagina que tomas aleatoriamente la altura de 100 jirafas: 50 pertenecienctes a la isla A y 50 a la isla B, como se muestra en las imágenes.\n\n\n\nIsla A e Isla B\n\n\n\n\n\nToma de alturas de jirafas miniatura\n\n\nGráficos por tinystats.\n\n¿Cómo podemos visualizar los 100 datos para ver cuál es la altura más común, la menos común y el rango de las alturas?\nUna forma practica sería la siguiente: tomas la altura de cada jirafa y llevas un conteo de cuántas veces se repite cada altura (frecuencia).\nPara simplificar este conteo, vamos a redondear las alturas a números enteros (por ejemplo, 6 cm, 7 cm, 8 cm, etc.).\nEsta es la base de un gráfico conocido como histograma, que muestra la distribución de los datos. Como verás, hay valores que se repiten más que otros, lo que se observa como picos en el gráfico.\nEjecuta el código de la siguiente diapositiva y observa cómo se va construyendo el histograma. Cada “bolita” que aparece en el gráfico representa un dato de altura. Si hay más de un dato para esa altura, se apila para llevar el conteo o frecuencia. No te preocupes por el código, solo observa el gráfico.\nNOTA: Puedes hacer click en el botón de reproducción (play) para ver la animación después de ejecutar el código; tarda unos segundos en cargar la animación.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCódigo usado para el gráfico de la distribución de alturas de jirafas\n\n\n\n\n\nlibrary(plotly)\nlibrary(tidyverse)\nlibrary(tweenr)\n\nset.seed(12)\nx &lt;- round(rnorm(25, 10, 2))\nx2 &lt;- round(rnorm(25, 18, 1.2))\nx &lt;- c(x, x2)\ndf &lt;- data.frame(x = x, y = 23, type = rep(c(\"Isla #1\", \"Isla #2\"), each = 25))\ndfs &lt;- list(df)\nfor (i in seq_len(nrow(df))) {\n  dftemp &lt;- tail(dfs, 1)\n  dftemp[[1]]$y[i] &lt;- sum(dftemp[[1]]$x[seq_len(i)] == dftemp[[1]]$x[i])\n  dfs &lt;- append(dfs, dftemp)\n}\ndfs &lt;- append(dfs, dfs[rep(length(dfs), 3)])\n# Reduce nframes to 100\ndft &lt;- tween_states(dfs, tweenlength = 10, statelength = 1, ease = \"cubic-in\", nframes = 100)\ndft$y &lt;- dft$y - 0.5\ndft &lt;- dft[dft$y != 23, ]\n\nm &lt;- list(l = 50, r = 50, b = 10, t = 10, pad = 4)\n\nhistograma_plot &lt;- \n  dft %&gt;% \n  plot_ly(\n    x = ~x, y = ~y, frame = ~.frame, color = ~type,\n    colors = c(\"green3\", \"turquoise3\"),\n    marker = list(size = 16), width = 630, height = 390\n  ) %&gt;%\n  config(displayModeBar = F) %&gt;%\n  layout(\n    xaxis = list(range = c(4, 23), title = \"Altura de jirafas en cm\", zeroline = F),\n    yaxis = list(range = c(-0.5, 21), title = \"Frecuencia\", zeroline = F),\n    legend = list(x = 0.075, y = 0.91),\n    autosize = F, margin = m\n  ) %&gt;%\n  animation_opts(frame = 25, transition = 0, redraw = FALSE) %&gt;%\n  animation_slider(hide = T) %&gt;%\n  animation_button(x = 1, xanchor = \"right\", y = 0, yanchor = \"bottom\")\n\n\n\n\nEl grafico que acabamos de ver (histograma) muestra la distribución o forma de nuestros datos.\nA partir de la distribución de nuestra variable de altura, podemos observar lo siguiente:\n\nDónde se concentran la mayoría de los valores de altura para cada isla.\nLa altura más común es diferente para las firafas de la isla 1 y 2.\nHay una variabilidad en las alturas, con algunas jirafas más altas y otras más bajas.\n\nDependiendo de la forma de la distribución, se le da un nombre a esta distribución de los datos.\nLa más común y utilizada en ciencias biomédicas es la distribución normal, también conocida como campana de Gauss. Muchas variables en la naturaleza siguen una distribución normal, como la altura de las personas, el peso de los animales, la temperatura, etc. Sin embargo, no todas las variables siguen una distribución normal, por lo que es importante verificar la forma de la distribución de los datos antes de realizar cualquier análisis estadístico.\nObserva el siguiente gráfico de la distribución normal, que muestra la forma típica de esta distribución. En lo que resta de la lección veremos las características de esta distribución y cómo se relaciona con nuestros datos de alturas de jirafas.\n\n\n\n\n\n\n\n\n\n\nCada distribución tiene sus propias características y propiedades, lo que las hace únicas y útiles para diferentes situaciones.\nEn el caso de la distribución normal, podemos describirla con dos parámetros: la media y la desviación estándar que se verán a continuación.\nExploremos la distribución normal con nuestro ejemplo de alturas de jirafas. Podemos observar las siguientes características:\n\nTiene un solo pico o punto más alto donde se concentran los datos.\n\nNOTA: En nuestro gráfico se observan 2 picos, pero esto es porque estamos observando las alturas de 2 grupos de jirafas diferentes. Sin embargo, cada grupo tiene un único pico.\n\nLos datos se distribuyen simétricamente alrededor de este punto medio.\n\n\n\n\nUna vez que hemos visualizado la distribución de los datos de nuestra variable, el siguiente paso es describir las alturas con medidas numéricas.\nPara esto, utilizamos las medidas de tendencia central y dispersión.\nEstas medidas nos ayudan a comprender tanto el “centro” de los datos como la “dispersión” de estos."
  },
  {
    "objectID": "docs/23-distribuciones-probabilidad.html#medidas-de-tendencia-central",
    "href": "docs/23-distribuciones-probabilidad.html#medidas-de-tendencia-central",
    "title": "Distribuciones de Probabilidad",
    "section": "Medidas de Tendencia Central",
    "text": "Medidas de Tendencia Central\n\nLas medidas de tendencia central nos ayudan a resumir la “ubicación” de los datos, en especial, dónde se concentran los datos. Las medidas más comunes son:\n\nMedia: el promedio de los datos.\nMediana: el valor que se encuentra en el centro de los datos.\nModa: el valor que se repite con mayor frecuencia.\n\nEn una distribución normal teórica, la media, mediana y moda son idénticas. Sin embargo, en la práctica, suelen ser diferentes, aunque cercanas.\n\n\n\nMedia o Promedio\n\nLa media es el promedio de todos los valores en un conjunto de datos.\nSe calcula sumando todos los valores y dividiendo por el número total de observaciones.\nPuede ser calculada fácilmente en R con la función mean(), la cuál podemos usar denrtro de las funciones de manipulación de datos de dplyr como ya hemos visto.\nObserva cómo calculmos la media de las alturas de las jirafas en el siguiente código. Nuestro dataframe se llama alturas_df (ya está cargado en la diapositiva) y tiene las columnas altura e isla.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nCuando nos referimos a la media, podemos hablar de la media poblacional o la media muestral.\nLa media poblacional es el promedio de todos los valores en una población completa y se denota con el símbolo μ (mu). Esta media es desconocida en la práctica, ya que rara vez tenemos acceso a todos los datos de una población.\nLa media muestral es el promedio de los valores en una muestra de la población y se denota con el símbolo x̄ (x barra). Esta es la media que calculamos con nuestros datos.\nDe manera similar, cuando nos referimos al tamaño de la población, usamos N, y cuando nos referimos al tamaño de la muestra, usamos n (en nuestro caso, n = 100).\n\n\n\nPodemos visualizar la media en nuestro histograma de alturas de jirafas. La línea vertical en el gráfico representa la media de las alturas de las jirafas en cada isla. Observa cómo la media se encuentra en el centro de la distribución de los datos. Nota: en la próxima lección veremos y explicaremos cómo realizar estos gráficos.\n\n\n\n\n\n\n\n\n\n\nMediana\n\nLa mediana es el valor que se encuentra en el centro de los datos cuando estos están ordenados de menor a mayor.\nEs una medida de tendencia central robusta, ya que no se ve afectada por valores extremos o atípicos.\nEn R, podemos calcular la mediana con la función median().\n\n\n\n\n\n\n\n\n\nPara graficarlo (observa que el valor de la mediana es muy similar al de la media):"
  },
  {
    "objectID": "docs/23-distribuciones-probabilidad.html#moda",
    "href": "docs/23-distribuciones-probabilidad.html#moda",
    "title": "Distribuciones de Probabilidad",
    "section": "Moda",
    "text": "Moda\n\nLa moda es el valor que se repite con mayor frecuencia en un conjunto de datos.\nPuede haber más de una moda en un conjunto de datos, lo que se conoce como distribución multimodal.\nEn R, podemos calcular la moda con la función mode(). NOTA: esta función no está disponible en R por defecto, por lo que debemos definirla manualmente."
  },
  {
    "objectID": "docs/23-distribuciones-probabilidad.html#medidas-de-dispersión",
    "href": "docs/23-distribuciones-probabilidad.html#medidas-de-dispersión",
    "title": "Distribuciones de Probabilidad",
    "section": "Medidas de Dispersión",
    "text": "Medidas de Dispersión\n\nLas medidas de dispersión nos ayudan a entender cuánto varían los datos (qué tan dispersos están).\nEn la siguiente figura, se muestran 3 distribuciones de probabilidad de una variable con la misma media pero diferente dispersión. La distribución de la izquierda tiene una menor dispersión que la del centro, aunque la figura de la derecha es la que menor dispersión tiene. Vamos a ver qué significa esto en términos de medidas de dispersión.\n\n\n\nVarianza\n\nLa varianza mide cuánto varían los datos alrededor de la media.\nSe calcula sumando las diferencias al cuadrado entre cada valor y la media, y luego dividiendo por el número total de observaciones.\nLa varianza es una medida de dispersión cuadrática, ya que considera la magnitud de las diferencias al cuadrado. Esto se hace para evitar que las diferencias positivas y negativas se cancelen entre sí.\nEn R, podemos calcular la varianza con la función var().\n\n\n\n\n\n\n\n\n\n\n\n\nLa varianza es una medida de qué tanto se aleja cada medición de la media\n\n\n\n\n\n\n\n\nNote\n\n\n\nCuando se habla de varianza, también se puede hacer referencia a la varianza poblacional y la varianza muestral. La varianza poblacional es la varianza de todos los valores en una población completa y se denota con el símbolo \\(\\sigma^2\\) (sigma al cuadrado). La varianza muestral es la varianza de los valores en una muestra de la población y se denota con el símbolo \\(s^2\\). En la práctica, usamos la varianza muestral, ya que rara vez tenemos acceso a todos los datos de una población."
  },
  {
    "objectID": "docs/23-distribuciones-probabilidad.html#desviación-estándar",
    "href": "docs/23-distribuciones-probabilidad.html#desviación-estándar",
    "title": "Distribuciones de Probabilidad",
    "section": "Desviación Estándar",
    "text": "Desviación Estándar\n\nEl problema con la varianza es que está en unidades al cuadrado, lo que puede ser difícil de interpretar. Por eso, a menudo usamos la desviación estándar, que es la raíz cuadrada de la varianza.\nLa desviación estándar mide cuánto se desvían los datos de la media, pero en las mismas unidades que los datos.\nEn R, podemos calcular la desviación estándar con la función sd().\n\n\n\n\n\n\n\n\n\n\n\n\nLa desviación estándar mide la dispersión de los datos alrededor de la media\n\n\n\n\n\n\n\n\nNote\n\n\n\nCuando se habla de desviación estándar, también se puede hacer referencia a la desviación estándar poblacional y la desviación estándar muestral. La desviación estándar poblacional es la desviación estándar de todos los valores en una población completa y se denota con el símbolo \\(\\sigma\\) (sigma). La desviación estándar muestral es la desviación estándar de los valores en una muestra de la población y se denota con el símbolo \\(s\\). En la práctica, usamos la desviación estándar muestral, ya que rara vez tenemos acceso a todos los datos de una población.\n\n\nPodemos graficarlo de esta manera, donde se muestra la media y la desviación estándar de las alturas de las jirafas en cada isla como una línea punteada alrededor de la media. Observa cómo la desviación estándar nos da una idea de cuánto varían las alturas alrededor de la media (varían más en la isla 1 que en la isla 2)."
  },
  {
    "objectID": "docs/23-distribuciones-probabilidad.html#significado-de-la-desviación-estándar",
    "href": "docs/23-distribuciones-probabilidad.html#significado-de-la-desviación-estándar",
    "title": "Distribuciones de Probabilidad",
    "section": "Significado de la Desviación Estándar",
    "text": "Significado de la Desviación Estándar\n\nLa desviación estándar nos indica cuánto se desvían los datos de la media.\nPuede ser usada para predecir que tan raro o común es un valor en la distribución.\nPara una distribución normal, un 97.7% de los datos caen dentro de 3 desviaciones estándar de la media; un 95.4% caen dentro de 2 desviaciones estándar; y un 68.3% caen dentro de 1 desviación estándar.\n\n\n\nObserva este fenómeno en nustros datos con el siguiente gráfico, donde se muestran las alturas de las jirafas en cada isla y las líneas punteadas representan la media y las líneas de puntos representan 1, 2 y 3 desviaciones estándar de la media. Observa cómo la mayoría de los datos caen dentro de 1, 2 y 3 desviaciones estándar de la media.\nEste concepto sera muy importante cuando veamos inferencia estadística ya que nos permitirá hacer predicciones sobre los datos. Por ejemplo, si sabemos que la altura promedio de las jirafas en la isla 1 es de 10 cm con una desviación estándar de 2 cm, podemos predecir que la mayoría de las jirafas tendrán alturas entre 8 y 12 cm (1 desviación estándar), entre 6 y 14 cm (2 desviaciones estándar), y entre 4 y 16 cm (3 desviaciones estándar). Si encontramos una jirafa con una altura de 20 cm, sabemos que es un valor raro, ya que está a más de 5 desviaciones estándar de la media.\nEsto es la base de la inferencia estadística, que veremos en futuras lecciones. La inferencia estadística es el proceso de hacer predicciones o sacar conclusiones sobre una población basadas en una muestra de datos.\nA partir de la distribución normal, podemos hacer inferencias sobre los datos, es decir, sacar conclusiones sobre la población basadas en nuestra muestra de datos.\nPor ejemplo, podemos estimar la probabilidad de que un valor caiga dentro de cierto rango o comparar dos grupos de datos."
  },
  {
    "objectID": "docs/23-distribuciones-probabilidad.html#distribución-normal-estandarizada-o-distribución-z",
    "href": "docs/23-distribuciones-probabilidad.html#distribución-normal-estandarizada-o-distribución-z",
    "title": "Distribuciones de Probabilidad",
    "section": "Distribución normal estandarizada o Distribución Z",
    "text": "Distribución normal estandarizada o Distribución Z\n\nHasta ahora, hemos visto cómo calcular la media y la desviación estándar de una distribución normal. Sin embargo, en la práctica, a menudo necesitamos comparar diferentes distribuciones normales.\nPara facilitar la comparación, podemos estandarizar cualquier distribución normal en una distribución normal estandarizada o distribución Z.\nLa distribución normal estandarizada es una versión especial de la distribución normal donde la media es 0 y la desviación estándar es 1.\n\nEsto se logra al transformar cualquier distribución normal general en una distribución normal estandarizada mediante la siguiente fórmula:\n\\[\nZ = \\frac{X - \\mu}{\\sigma}\n\\]\nDonde:\n\n\\(Z\\) es el valor estandarizado (con media 0 y desviación estándar 1).\n\\(X\\) es el valor original de la variable.\n\\(\\mu\\) es la media de la distribución original.\n\\(\\sigma\\) es la desviación estándar de la distribución original.\n\n¿Por qué se hace esto?\nLa razón por la que se estandarizan las distribuciones es para facilitar la comparación entre diferentes conjuntos de datos. Cuando diferentes distribuciones normales se transforman a una forma común (media = 0 y desviación estándar = 1), es más fácil comparar resultados de diferentes estudios o poblaciones.\nEjemplo\n\nImagina que estamos trabajando con alturas de personas en un país, donde la media es 170 cm y la desviación estándar es 10 cm.\nSi una persona mide 180 cm, podemos estandarizar su altura con la fórmula:\n\\[\nZ = \\frac{180 - 170}{10} = 1\n\\]\nEsto significa que esta persona está 1 desviación estándar por encima de la media.\nSi otra persona mide 160 cm:\n\\[\nZ = \\frac{160 - 170}{10} = -1\n\\]\nEsta persona está 1 desviación estándar por debajo de la media.\nAl estandarizar las alturas, podemos comparar fácilmente las alturas de estas dos personas, ya que están en la misma escala de puntuaciones Z.\nEn R, podemos estandarizar una distribución normal con la función scale(). Observa cómo estandarizamos las alturas de las jirafas en cada isla en el siguiente código.\nEn este código, hemos estandarizado las alturas de cada jirafa con la función scale(). La función hace lo siguiente: Para cada isla, calculará la media y desviación estándar de las alturas de los individuos. Luego, para cada valor de altura, restará la media de la isla correspondiente y dividirá el resultado por la desviación estándar de esa isla, obteniendo los valores estandarizados.\n\n\n\n\n\n\n\n\n\nAhora, observa qué pasa si calculamos la media y la desviación estándar de las alturas estandarizadas. En una distribución normal estandarizada, la media es 0 y la desviación estándar es 1. Observa cómo se cumple esto en nuestro ejemplo de las alturas de las jirafas. Nota: verás que las medias no son exactamente 0 debido a la precisión de los cálculos en R. Sin embargo, los valores son exponentes muy pequeños, lo que indica que son cercanos a 0.\n\n\n\n\n\n\n\n\n\nAhora, vamos a graficar estas alturas estandarizadas. Observa cómo ahora es más fácil comparar las alturas de las jirafas en cada isla, ya que todas están en la misma escala de puntuaciones Z.\nAdemás, observa cómo la distribución normal estandarizada tiene una media de 0 y una desviación estándar de 1, lo que facilita la comparación entre las alturas de las jirafas en cada isla.\nSe resaltan las áreas correspondientes a 1, 2 y 3 desviaciones estándar de la media, que corresponden al 68.27%, 95.45% y 99.73% de los datos en una distribución normal.\nNo te preocupes por el código. En las próximas lecciones veremos una introducción a la visualización de datos en R. Este es un gráfico un poco más complejo que los que veremos en las primeras lecciones. Sin embargo, más adelante con la práctica, podrás entender y crear gráficos como este en las últimas lecciones del curso.\nEl gráfico utiliza curvas de densidad, que son estimaciones suavizadas de los histogramas."
  },
  {
    "objectID": "docs/23-distribuciones-probabilidad.html#reflexión",
    "href": "docs/23-distribuciones-probabilidad.html#reflexión",
    "title": "Distribuciones de Probabilidad",
    "section": "Reflexión",
    "text": "Reflexión\n\nToma en cuenta que en nuestro ejemplo de las jirafas, es probable que no hayamos tomado las alturas de TODAS las jirafas de las islas.\nPor lo tanto, nuestro histograma es una aproximación de la verdadera distribución de alturas.\nEsta aproximación está basada en nuestro muestreo aleatorio de las alturas. Esto es común en la estadística, donde trabajamos con muestras de datos en lugar de la población completa.\nExiste la posibilidad de que nuestro muestreo no sea adecuado para representar la verdadera distribución de alturas en la población. Esto es un tema importante en la estadística y se conoce como error de muestreo.\nDebido a esto, es importante tomar una muestra lo suficientemente grande y representativa.\n\nPara ilustrar este concepto, observa cómo cambia la forma del histograma al tomar muestras de diferentes tamaños de los datos de las jirafas. El siguiente gráfico muestra el histograma de las jirafas, asumiendo que realizamos un muestreo aleatorio de las alturas varias veces (cada cuadro del GIF representa un muestreo diferente, es decir, cada vez que vamos a la isla y tomamos la altura de N jirafas). En cada muestreo, el número de alturas de jirafas tomadas varía, denotado por la letra N, que indica el tamaño de la muestra. Observa cómo con una muestra pequeña, la forma del histograma cambia drásticamente, mientras que con una muestra grande, se mantiene constante y asemeja la forma de la distribución normal. Esto también se verá más adelante."
  },
  {
    "objectID": "docs/60-lineales-corrintro.html#introducción",
    "href": "docs/60-lineales-corrintro.html#introducción",
    "title": "Análisis de Correlación",
    "section": "Introducción",
    "text": "Introducción\nLa correlación es una medida estadística que indica la relación entre dos variables. Nos ayuda a entender cómo una variable puede cambiar en relación con otra. El coeficiente de correlación de Pearson es uno de los métodos más comunes para medir la correlación y cuantifica la dirección y la fuerza de la relación lineal entre dos variables continuas."
  },
  {
    "objectID": "docs/60-lineales-corrintro.html#conceptos-clave",
    "href": "docs/60-lineales-corrintro.html#conceptos-clave",
    "title": "Análisis de Correlación",
    "section": "Conceptos Clave",
    "text": "Conceptos Clave\nCoeficiente de Correlación de Pearson (r):\n    Rango de -1 a 1.\n    Un valor cercano a 1 indica una fuerte relación positiva (cuando una variable aumenta, la otra también).\n    Un valor cercano a -1 indica una fuerte relación negativa (cuando una variable aumenta, la otra disminuye).\n    Un valor cercano a 0 indica poca o ninguna relación lineal.\n\nInterpretación:\n    (r &gt; 0): Correlación positiva.\n    (r &lt; 0): Correlación negativa.\n    (r = 0): Sin correlación lineal aparente."
  },
  {
    "objectID": "docs/60-lineales-corrintro.html#ejercicio-práctico-en-r",
    "href": "docs/60-lineales-corrintro.html#ejercicio-práctico-en-r",
    "title": "Análisis de Correlación",
    "section": "Ejercicio Práctico en R",
    "text": "Ejercicio Práctico en R\n\nRPython\n\n\nAnalizaremos la relación entre dos variables simuladas: horas de estudio y calificación del examen."
  },
  {
    "objectID": "docs/60-lineales-corrintro.html#reflexión-y-discusión",
    "href": "docs/60-lineales-corrintro.html#reflexión-y-discusión",
    "title": "Análisis de Correlación",
    "section": "Reflexión y Discusión:",
    "text": "Reflexión y Discusión:\nExamina el valor del coeficiente de correlación calculado: ¿Qué te indica sobre la relación entre las horas de estudio y las calificaciones?\nDiscute cómo podrías usar la correlación para explorar otras relaciones en datos reales. ¿Cuáles son algunas limitaciones de usar la correlación para inferir causalidad?\nEsta lección proporciona una introducción práctica al análisis de correlación en R, equipando a los estudiantes con la capacidad de identificar y cuantificar relaciones lineales entre variables dentro de un conjunto de datos."
  },
  {
    "objectID": "docs/53-anova-kruskal-wallis-python.html",
    "href": "docs/53-anova-kruskal-wallis-python.html",
    "title": "ANOVA y Test de Kruskal-Wallis con Python",
    "section": "",
    "text": "Cuando se necesita comparar las medias de tres o más grupos, el Análisis de Varianza (ANOVA) de una vía es la herramienta estadística indicada. Si los datos no cumplen con los supuestos del ANOVA (como la normalidad), el test de Kruskal-Wallis ofrece una alternativa no paramétrica robusta."
  },
  {
    "objectID": "docs/53-anova-kruskal-wallis-python.html#introducción",
    "href": "docs/53-anova-kruskal-wallis-python.html#introducción",
    "title": "ANOVA y Test de Kruskal-Wallis con Python",
    "section": "",
    "text": "Cuando se necesita comparar las medias de tres o más grupos, el Análisis de Varianza (ANOVA) de una vía es la herramienta estadística indicada. Si los datos no cumplen con los supuestos del ANOVA (como la normalidad), el test de Kruskal-Wallis ofrece una alternativa no paramétrica robusta."
  },
  {
    "objectID": "docs/53-anova-kruskal-wallis-python.html#conceptos-clave",
    "href": "docs/53-anova-kruskal-wallis-python.html#conceptos-clave",
    "title": "ANOVA y Test de Kruskal-Wallis con Python",
    "section": "Conceptos Clave",
    "text": "Conceptos Clave\n\nANOVA de Una Vía: Compara las medias de tres o más grupos para determinar si al menos uno de los grupos es diferente de los demás. Se basa en la relación entre la varianza entre los grupos y la varianza dentro de los grupos.\nTest de Kruskal-Wallis: Es la contraparte no paramétrica del ANOVA. Funciona con los rangos de los datos en lugar de los valores originales, lo que lo hace ideal para datos que no se distribuyen normalmente."
  },
  {
    "objectID": "docs/53-anova-kruskal-wallis-python.html#ejercicio-práctico-en-python",
    "href": "docs/53-anova-kruskal-wallis-python.html#ejercicio-práctico-en-python",
    "title": "ANOVA y Test de Kruskal-Wallis con Python",
    "section": "Ejercicio Práctico en Python",
    "text": "Ejercicio Práctico en Python\nVamos a comparar el rendimiento de tres grupos de tratamiento diferentes utilizando tanto el ANOVA de una vía como el test de Kruskal-Wallis."
  },
  {
    "objectID": "docs/53-anova-kruskal-wallis-python.html#interpretación-y-discusión",
    "href": "docs/53-anova-kruskal-wallis-python.html#interpretación-y-discusión",
    "title": "ANOVA y Test de Kruskal-Wallis con Python",
    "section": "Interpretación y Discusión",
    "text": "Interpretación y Discusión\n\nCompara los valores p del ANOVA y del test de Kruskal-Wallis: ¿Llegan a la misma conclusión sobre las diferencias entre los grupos?\nAnaliza el gráfico de cajas: ¿Qué te dice visualmente sobre las medianas y la dispersión de los datos en cada grupo? ¿Apoya los resultados de las pruebas estadísticas?\n\nEsta lección demuestra cómo utilizar tanto el ANOVA como el test de Kruskal-Wallis en Python para comparar múltiples grupos, proporcionando a los estudiantes las herramientas para elegir la prueba adecuada según la naturaleza de sus datos."
  },
  {
    "objectID": "docs/81-comparar-3kruka.html",
    "href": "docs/81-comparar-3kruka.html",
    "title": "Kruskal-Wallis Test",
    "section": "",
    "text": "El test de Kruskal-Wallis es una prueba no paramétrica utilizada para determinar si hay diferencias significativas entre tres o más grupos en una variable continua. Es una alternativa al ANOVA de una vía cuando los datos no cumplen con los supuestos de normalidad y homogeneidad de varianzas.\nSupongamos que tenemos un experimento con dos factores: Tipo de Suplemento (con niveles “OJ” para jugo de naranja y “VC” para vitamina C) y Dosis (con niveles 0.5, 1 y 2). La variable de respuesta es la Longitud del Diente. Aquí está cómo se vería una tabla que muestra las celdas formadas por las combinaciones de niveles de estos factores:\n\n\n\nTipo de Suplemento\nDosis\nLongitud del Diente (ejemplo)\n\n\n\n\nOJ\n0.5\n13.2\n\n\nOJ\n1.0\n22.7\n\n\nOJ\n2.0\n26.4\n\n\nVC\n0.5\n8.2\n\n\nVC\n1.0\n15.5\n\n\nVC\n2.0\n23.3\n\n\n\nVamos a utilizar el test de Kruskal-Wallis para determinar si hay diferencias significativas en la longitud del diente entre los diferentes niveles del factor Tipo de Suplemento.\n\n\n\nHipótesis Nula (H0): La media de longitud del diente es igual para todos los tipos de suplemento.\nHipótesis Alternativa (H1): Al menos una de las medias de longitud del diente es diferente.\n\n\n\n\nUsaremos el conjunto de datos incorporado en R llamado ToothGrowth. Contiene datos de un estudio que evalúa el efecto de la vitamina C en el crecimiento dental en cobayas. El experimento se ha realizado en 60 cobayas, donde cada animal recibió uno de tres niveles de dosis de vitamina C (0.5, 1 y 2 mg/día) mediante uno de dos métodos de administración (jugo de naranja o ácido ascórbico, y codificado como VC). Se midió la longitud del diente y se muestra una muestra de los datos a continuación.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQueremos saber si la longitud del diente depende de supp.\n\nPodemos usar la función kruskal.test() para realizar el test de Kruskal-Wallis en R.\nLa función kruskal.test() toma la fórmula fórmula y los datos data como argumentos.\n\nLa fórmula es de la forma y ~ x, donde y es la variable de respuesta y x es la variable de factor."
  },
  {
    "objectID": "docs/81-comparar-3kruka.html#hipótesis-del-test-de-kruskal-wallis",
    "href": "docs/81-comparar-3kruka.html#hipótesis-del-test-de-kruskal-wallis",
    "title": "Kruskal-Wallis Test",
    "section": "",
    "text": "Hipótesis Nula (H0): La media de longitud del diente es igual para todos los tipos de suplemento.\nHipótesis Alternativa (H1): Al menos una de las medias de longitud del diente es diferente."
  },
  {
    "objectID": "docs/81-comparar-3kruka.html#datos",
    "href": "docs/81-comparar-3kruka.html#datos",
    "title": "Kruskal-Wallis Test",
    "section": "",
    "text": "Usaremos el conjunto de datos incorporado en R llamado ToothGrowth. Contiene datos de un estudio que evalúa el efecto de la vitamina C en el crecimiento dental en cobayas. El experimento se ha realizado en 60 cobayas, donde cada animal recibió uno de tres niveles de dosis de vitamina C (0.5, 1 y 2 mg/día) mediante uno de dos métodos de administración (jugo de naranja o ácido ascórbico, y codificado como VC). Se midió la longitud del diente y se muestra una muestra de los datos a continuación."
  },
  {
    "objectID": "docs/81-comparar-3kruka.html#calcular-el-test-de-kruskal-wallis",
    "href": "docs/81-comparar-3kruka.html#calcular-el-test-de-kruskal-wallis",
    "title": "Kruskal-Wallis Test",
    "section": "",
    "text": "Queremos saber si la longitud del diente depende de supp.\n\nPodemos usar la función kruskal.test() para realizar el test de Kruskal-Wallis en R.\nLa función kruskal.test() toma la fórmula fórmula y los datos data como argumentos.\n\nLa fórmula es de la forma y ~ x, donde y es la variable de respuesta y x es la variable de factor."
  },
  {
    "objectID": "docs/22.1-distribuciones-nonom-python.html",
    "href": "docs/22.1-distribuciones-nonom-python.html",
    "title": "Distribuciones de Probabilidad en Python",
    "section": "",
    "text": "En Python, puedes simular y visualizar distribuciones de probabilidad usando numpy, scipy.stats y seaborn/matplotlib.\nAquí exploraremos la distribución normal, binomial y de Poisson, y cómo graficarlas y simular datos."
  },
  {
    "objectID": "docs/22.1-distribuciones-nonom-python.html#introducción-y-objetivos",
    "href": "docs/22.1-distribuciones-nonom-python.html#introducción-y-objetivos",
    "title": "Distribuciones de Probabilidad en Python",
    "section": "",
    "text": "En Python, puedes simular y visualizar distribuciones de probabilidad usando numpy, scipy.stats y seaborn/matplotlib.\nAquí exploraremos la distribución normal, binomial y de Poisson, y cómo graficarlas y simular datos."
  },
  {
    "objectID": "docs/22.1-distribuciones-nonom-python.html#distribución-normal",
    "href": "docs/22.1-distribuciones-nonom-python.html#distribución-normal",
    "title": "Distribuciones de Probabilidad en Python",
    "section": "Distribución Normal",
    "text": "Distribución Normal"
  },
  {
    "objectID": "docs/22.1-distribuciones-nonom-python.html#distribución-binomial",
    "href": "docs/22.1-distribuciones-nonom-python.html#distribución-binomial",
    "title": "Distribuciones de Probabilidad en Python",
    "section": "Distribución Binomial",
    "text": "Distribución Binomial\n\n\n\n\n\n\n\n\n\nSi la moneda está cargada (p=0.85):"
  },
  {
    "objectID": "docs/22.1-distribuciones-nonom-python.html#distribución-de-poisson",
    "href": "docs/22.1-distribuciones-nonom-python.html#distribución-de-poisson",
    "title": "Distribuciones de Probabilidad en Python",
    "section": "Distribución de Poisson",
    "text": "Distribución de Poisson"
  },
  {
    "objectID": "docs/22.1-distribuciones-nonom-python.html#otras-distribuciones",
    "href": "docs/22.1-distribuciones-nonom-python.html#otras-distribuciones",
    "title": "Distribuciones de Probabilidad en Python",
    "section": "Otras Distribuciones",
    "text": "Otras Distribuciones\n\nAdemás de la normal, binomial y Poisson, existen muchas otras distribuciones en scipy.stats.\nEjemplos: chi-cuadrada (scipy.stats.chi2), t de Student (scipy.stats.t), F de Fisher (scipy.stats.f), etc.\nConsulta la documentación de scipy.stats para más detalles."
  },
  {
    "objectID": "docs/22.1-distribuciones-nonom-python.html#reflexión",
    "href": "docs/22.1-distribuciones-nonom-python.html#reflexión",
    "title": "Distribuciones de Probabilidad en Python",
    "section": "Reflexión",
    "text": "Reflexión\n\n¿Cómo cambia la forma de la distribución al modificar los parámetros?\n¿Qué tipo de variables reales se ajustan a cada distribución?\n\nEsta lección te da una base para simular y visualizar distribuciones de probabilidad en Python."
  },
  {
    "objectID": "docs/75-fundamentos-anova-python.html",
    "href": "docs/75-fundamentos-anova-python.html",
    "title": "Fundamentos del ANOVA con Python",
    "section": "",
    "text": "El Análisis de Varianza (ANOVA, por sus siglas en inglés) es una técnica estadística utilizada para comparar las medias de tres o más grupos. La prueba ANOVA permite determinar si existen diferencias estadísticamente significativas entre las medias de diferentes grupos, basándose en la variabilidad dentro de los grupos y entre los grupos. Sin embargo, ANOVA no indica cuáles grupos son diferentes entre sí; para ello, se utilizan pruebas post-hoc.\nEn esta lección, vamos a ver los fundamentos del ANOVA, incluyendo los conceptos clave, los supuestos y los tipos de ANOVA. En las próximas lecciones, veremos cómo realizar ANOVA en Python y cómo visualizar los resultados."
  },
  {
    "objectID": "docs/75-fundamentos-anova-python.html#introducción-al-análisis-de-varianza-anova",
    "href": "docs/75-fundamentos-anova-python.html#introducción-al-análisis-de-varianza-anova",
    "title": "Fundamentos del ANOVA con Python",
    "section": "",
    "text": "El Análisis de Varianza (ANOVA, por sus siglas en inglés) es una técnica estadística utilizada para comparar las medias de tres o más grupos. La prueba ANOVA permite determinar si existen diferencias estadísticamente significativas entre las medias de diferentes grupos, basándose en la variabilidad dentro de los grupos y entre los grupos. Sin embargo, ANOVA no indica cuáles grupos son diferentes entre sí; para ello, se utilizan pruebas post-hoc.\nEn esta lección, vamos a ver los fundamentos del ANOVA, incluyendo los conceptos clave, los supuestos y los tipos de ANOVA. En las próximas lecciones, veremos cómo realizar ANOVA en Python y cómo visualizar los resultados."
  },
  {
    "objectID": "docs/75-fundamentos-anova-python.html#por-qué-utilizamos-anova-para-probar-hipótesis",
    "href": "docs/75-fundamentos-anova-python.html#por-qué-utilizamos-anova-para-probar-hipótesis",
    "title": "Fundamentos del ANOVA con Python",
    "section": "¿Por qué utilizamos ANOVA para probar hipótesis?",
    "text": "¿Por qué utilizamos ANOVA para probar hipótesis?\nCuando queremos comparar las medias de más de dos grupos, hacer múltiples pruebas t individuales aumenta el riesgo de cometer errores de Tipo I (falsos positivos). ANOVA ofrece una solución al proporcionar una prueba estadística única que evalúa si hay al menos una diferencia significativa entre las medias de los grupos, controlando adecuadamente la tasa de error de Tipo I."
  },
  {
    "objectID": "docs/75-fundamentos-anova-python.html#conceptos-clave-en-anova",
    "href": "docs/75-fundamentos-anova-python.html#conceptos-clave-en-anova",
    "title": "Fundamentos del ANOVA con Python",
    "section": "Conceptos clave en ANOVA",
    "text": "Conceptos clave en ANOVA\n\nLa varianza es una medida de dispersión que indica cuánto varían los datos respecto a la media. En ANOVA, la varianza se utiliza para comparar la variabilidad dentro de los grupos y entre los grupos.\n\n\n\n\nEn la figura observamos que cada grupo tiene distintas medias y varianza. Además, hay grupos con medias más cercanas y otros, como el 1, con medias más alejadas de los otros grupos.\n\n\n\nSuma de cuadrados Entre-grupos y Dentro de los grupos\n\nLa suma de cuadrados representa una medida de variación o desviación con respecto a la media.\nSe puede dividir en dos partes: la Suma de Cuadrados dentro de grupos (variabilidad de las observaciones individuales dentro de cada grupo) y la Suma de Cuadrados entre grupos (variabilidad de las medias de los grupos respecto a la media general).\n\n\n\nRazón F\n\nLa razón F es el estadístico utilizado en ANOVA para comparar la variabilidad entre los grupos con la variabilidad dentro de los grupos.\nEs la relación entre la varianza media entre grupos (MSB) y la varianza media dentro de los grupos (MSE).\nSe utiliza para probar la hipótesis nula en ANOVA.\n\n\\[\nF = \\frac{\\text{Varianza entre grupos}}{\\text{Varianza dentro de los grupos}} = \\frac{MSB}{MSE}\n\\]\nDonde: - \\(MSB = \\frac{SSB}{df_{\\text{entre}}}\\) (Suma de cuadrados entre grupos / grados de libertad entre grupos) - \\(MSE = \\frac{SSE}{df_{\\text{dentro}}}\\) (Suma de cuadrados dentro de los grupos / grados de libertad dentro de los grupos)"
  },
  {
    "objectID": "docs/75-fundamentos-anova-python.html#la-lógica-de-anova",
    "href": "docs/75-fundamentos-anova-python.html#la-lógica-de-anova",
    "title": "Fundamentos del ANOVA con Python",
    "section": "La lógica de ANOVA",
    "text": "La lógica de ANOVA\nANOVA se basa en comparar dos estimaciones de la varianza:\n\nVarianza entre grupos: Estima la varianza a partir de la variabilidad entre las medias de los grupos.\nVarianza dentro de los grupos: Estima la varianza a partir de la variabilidad dentro de cada grupo.\n\nSi todas las medias de los grupos son iguales, esperamos que estas dos estimaciones de la varianza sean aproximadamente iguales, resultando en una razón F cercana a 1. Si al menos una media es diferente, la varianza entre grupos será mayor que la varianza dentro de los grupos, y la razón F será mayor que 1.\n\n\n\nEn este ejemplo, hay poca variación dentro de los grupos, pero mucha entre los grupos. En este caso, el valor F será alto. Esto indica que las diferencias entre los grupos son estadísticamente significativas.\n\n\n\n\n\nEn este ejemplo, hay más variación dentro de los grupos, pero poca entre los grupos. El valor F será bajo. Esto indica que las diferencias observadas entre las medias de los grupos probablemente no son estadísticamente significativas."
  },
  {
    "objectID": "docs/75-fundamentos-anova-python.html#hipótesis-en-anova",
    "href": "docs/75-fundamentos-anova-python.html#hipótesis-en-anova",
    "title": "Fundamentos del ANOVA con Python",
    "section": "Hipótesis en ANOVA",
    "text": "Hipótesis en ANOVA\n\nHipótesis nula (\\(H_0\\))\nTodas las medias poblacionales son iguales:\n\\[\nH_0: \\mu_1 = \\mu_2 = \\dots = \\mu_k\n\\]\n\n\nHipótesis alternativa (\\(H_a\\))\nAl menos una de las medias poblacionales es diferente:\n\\[\nH_a: \\text{Al menos una } \\mu_i \\text{ es diferente}\n\\]"
  },
  {
    "objectID": "docs/75-fundamentos-anova-python.html#tipos-de-anova",
    "href": "docs/75-fundamentos-anova-python.html#tipos-de-anova",
    "title": "Fundamentos del ANOVA con Python",
    "section": "Tipos de ANOVA",
    "text": "Tipos de ANOVA\n\nANOVA de una vía (One-way ANOVA): Compara las medias de tres o más grupos independientes basados en un solo factor.\nANOVA de dos vías (Two-way ANOVA): Compara las medias considerando dos factores y su interacción.\nANOVA de medidas repetidas (Repeated Measures ANOVA): Se utiliza cuando los mismos sujetos son medidos bajo diferentes condiciones o a lo largo del tiempo."
  },
  {
    "objectID": "docs/75-fundamentos-anova-python.html#supuestos-de-anova",
    "href": "docs/75-fundamentos-anova-python.html#supuestos-de-anova",
    "title": "Fundamentos del ANOVA con Python",
    "section": "Supuestos de ANOVA",
    "text": "Supuestos de ANOVA\n\nIndependencia de las observaciones: Las observaciones en cada grupo son independientes entre sí.\nNormalidad: Los residuos (la diferencia entre los valores observados y los predichos por el modelo) siguen una distribución normal.\nHomogeneidad de varianzas (homocedasticidad): Las varianzas de los residuos son iguales en todos los grupos.\n\nSi estos supuestos no se cumplen, se pueden considerar transformaciones de datos o utilizar pruebas no paramétricas alternativas, como la prueba de Kruskal-Wallis."
  },
  {
    "objectID": "docs/75-fundamentos-anova-python.html#ejemplo-de-anova-de-una-vía-en-python",
    "href": "docs/75-fundamentos-anova-python.html#ejemplo-de-anova-de-una-vía-en-python",
    "title": "Fundamentos del ANOVA con Python",
    "section": "Ejemplo de ANOVA de una vía en Python",
    "text": "Ejemplo de ANOVA de una vía en Python\nVamos a realizar un ANOVA de una vía para ver si hay diferencias en el peso de los pollitos (chickwts dataset) según el tipo de alimento que recibieron.\n\n\n\n\n\n\n\n\n\nRealizar el ANOVA\nUsaremos la librería statsmodels para ajustar el modelo lineal y obtener la tabla ANOVA.\n\n\n\n\n\n\n\n\n\n\nInterpretación\n\nsum_sq (Suma de cuadrados): C(suplemento) (entre grupos) tiene una suma de cuadrados de 231129.5, mientras que Residual (dentro de los grupos) tiene 195556.0.\ndf (Grados de libertad): Hay 5 grados de libertad para el factor suplemento (6 grupos - 1) y 65 para los residuos (71 observaciones - 6 grupos).\nF (Estadístico F): El valor F es 15.38.\nPR(&gt;F) (Valor p): El valor p es 5.9e-10, que es extremadamente pequeño.\n\nConclusión: Dado que el valor p es mucho menor que 0.05, rechazamos la hipótesis nula. Hay evidencia estadística suficiente para concluir que al menos uno de los tipos de suplemento tiene un efecto diferente en el peso medio de los pollitos. Para saber qué grupos son diferentes, necesitaríamos realizar pruebas post-hoc."
  },
  {
    "objectID": "docs/54-correlacion-python.html",
    "href": "docs/54-correlacion-python.html",
    "title": "Correlación de Pearson y Spearman con Python",
    "section": "",
    "text": "La correlación es una medida estadística que expresa la extensión en la que dos variables están relacionadas linealmente (Pearson) o monótonamente (Spearman). Es una herramienta fundamental para entender cómo se mueven juntas las variables."
  },
  {
    "objectID": "docs/54-correlacion-python.html#introducción",
    "href": "docs/54-correlacion-python.html#introducción",
    "title": "Correlación de Pearson y Spearman con Python",
    "section": "",
    "text": "La correlación es una medida estadística que expresa la extensión en la que dos variables están relacionadas linealmente (Pearson) o monótonamente (Spearman). Es una herramienta fundamental para entender cómo se mueven juntas las variables."
  },
  {
    "objectID": "docs/54-correlacion-python.html#conceptos-clave",
    "href": "docs/54-correlacion-python.html#conceptos-clave",
    "title": "Correlación de Pearson y Spearman con Python",
    "section": "Conceptos Clave",
    "text": "Conceptos Clave\n\nCorrelación de Pearson (r): Mide la fuerza y dirección de una relación lineal entre dos variables continuas. El coeficiente varía de -1 (correlación lineal negativa perfecta) a +1 (correlación lineal positiva perfecta). Un valor de 0 indica que no hay relación lineal.\nCorrelación de Spearman (ρ o rho): Mide la fuerza y dirección de una relación monótona entre dos variables. No requiere que la relación sea lineal. Funciona con los rangos de los datos, lo que la hace robusta a los valores atípicos y adecuada para datos no normales.\nHipótesis Nula (H₀): En el contexto de la correlación, la hipótesis nula es que no existe relación entre las variables (el coeficiente de correlación es 0)."
  },
  {
    "objectID": "docs/54-correlacion-python.html#ejercicio-práctico-en-python",
    "href": "docs/54-correlacion-python.html#ejercicio-práctico-en-python",
    "title": "Correlación de Pearson y Spearman con Python",
    "section": "Ejercicio Práctico en Python",
    "text": "Ejercicio Práctico en Python\nCalcularemos y visualizaremos las correlaciones de Pearson y Spearman para dos conjuntos de datos: uno con una relación lineal y otro con una relación monótona no lineal."
  },
  {
    "objectID": "docs/54-correlacion-python.html#interpretación-y-discusión",
    "href": "docs/54-correlacion-python.html#interpretación-y-discusión",
    "title": "Correlación de Pearson y Spearman con Python",
    "section": "Interpretación y Discusión",
    "text": "Interpretación y Discusión\n\nPara los datos lineales: Observa que tanto Pearson como Spearman dan coeficientes altos y similares. ¿Por qué crees que ocurre esto?\nPara los datos monótonos no lineales: Compara los coeficientes. La correlación de Spearman es más alta que la de Pearson. ¿Qué te dice esto sobre la capacidad de cada prueba para capturar diferentes tipos de relaciones?\n\nEsta lección ilustra la importancia de elegir la medida de correlación correcta según la naturaleza de la relación entre las variables, una habilidad clave en el análisis de datos exploratorio."
  },
  {
    "objectID": "docs/52-anova-dosvias.html",
    "href": "docs/52-anova-dosvias.html",
    "title": "Comparación de Tres o Más Medias: ANOVA y Test de Kruskal-Wallis",
    "section": "",
    "text": "Lección sobre ANOVA de Dos Vías y Efectos de Interacción en Ciencias de la Salud y Biológicas\n\n\nIntroducción al ANOVA de Dos Vías\nEl ANOVA de dos vías es una extensión del ANOVA de una vía que permite evaluar los efectos de dos factores diferentes y sus efectos de interacción sobre una variable dependiente. Este tipo de análisis es útil cuando se desea entender cómo dos factores conjuntamente afectan la respuesta de los individuos en un estudio.\nEn un ANOVA de dos vías, el modelo lineal incluye términos para los efectos principales de cada factor y un término adicional para su interacción. Los efectos principales representan las diferencias entre los niveles de cada factor por separado, mientras que la interacción examina si el efecto de un factor depende del nivel del otro factor.\n\n\n\n\nPuntos clave a enseñar:\n\nANOVA de dos vías como modelo lineal: El modelo lineal en un ANOVA de dos vías extiende la fórmula utilizada en los modelos anteriores para incluir los efectos de interacción entre los factores.\n\\([\ny = \\beta_0 + \\beta_1 \\cdot X_1 + \\beta_2 \\cdot X_2 + \\beta_3 \\cdot X_1 \\cdot X_2\\)]\n\n\\((\\beta_0\\)) es la intersección (la media para el primer nivel de ambos factores).\n\\((\\beta_1\\)) y \\((\\beta_2\\)) representan los efectos principales de los factores \\((X_1\\)) y \\((X_2\\)).\n\\((\\beta_3\\)) es el efecto de interacción entre \\((X_1\\)) y \\((X_2\\)).\n\nEfectos de interacción: El término de interacción (\\((\\beta_3\\))) examina si el efecto de un factor cambia en función del nivel del otro factor. Por ejemplo, en un estudio que analiza el efecto de un tratamiento en hombres y mujeres, la interacción buscaría si el efecto del tratamiento es diferente entre los géneros.\nCodificación dummy: Al igual que en los modelos anteriores, se utiliza la codificación dummy para representar los niveles de los factores. Cada nivel de un factor se convierte en una variable indicadora (0 o 1), y las interacciones entre los factores se representan como productos de estas variables indicadoras.\n\n\n\n\nEjemplo en R: ANOVA de Dos Vías\nA continuación, realizamos un ANOVA de dos vías utilizando R y visualizamos los resultados.\n\nPaso 1: Generar los datos\nUtilizamos el conjunto de datos anterior, añadiendo un segundo factor (mood) que tiene dos niveles: happy y sad. Esto nos permite realizar un ANOVA de dos vías con un diseño 3x2 (tres niveles del factor group y dos niveles del factor mood).\n\n\n\n\n\n\n\n\n\n\nPaso 2: Codificación dummy para el ANOVA de dos vías\nCodificamos de manera explícita los grupos y los niveles del factor mood utilizando variables indicadoras (dummy variables).\n\n\n\n\n\n\n\n\n\n\nPaso 3: Visualización del ANOVA de Dos Vías\nCreamos una gráfica que muestra las medias de los grupos para cada nivel del factor mood, incluyendo las barras de error correspondientes.\n\n\n\n\n\n\n\n\n\n\nPaso 4: Códigos en R: ANOVA de Dos Vías\nPodemos realizar el ANOVA de dos vías utilizando la función aov() o el paquete car::Anova(). También podemos obtener el mismo resultado mediante un modelo lineal explícito que incluya los términos de interacción.\n\n\n\n\n\n\n\n\n\n\nPaso 5: Efectos principales del ANOVA de Dos Vías\nA continuación, calculamos los efectos principales por separado para cada factor (group y mood), utilizando modelos lineales más simples.\n\n\n\n\n\n\n\n\n\n\n\n\nEjercicio Práctico\n\nEjercicio 1: Usa el conjunto de datos mtcars para realizar un ANOVA de dos vías, comparando el consumo de combustible (mpg) según el número de cilindros (cyl) y el tipo de transmisión (am).\n\n\n\n\n\n\n\n\nEjercicio 2: Realiza un análisis de los efectos principales de cyl y am en el consumo de combustible (mpg), utilizando modelos lineales sin interacción.\n\n\n\n\n\n\n\n\n\n\n\n\nConclusión\nEl ANOVA de dos vías es una técnica poderosa para analizar los efectos de dos factores y sus interacciones sobre una variable dependiente. Al entender cómo los efectos principales y de interacción se representan en un modelo lineal, podemos interpretar los resultados de manera más clara y aplicar estos principios en una amplia variedad de estudios en ciencias de la salud y biológicas."
  },
  {
    "objectID": "docs/60-a-lineales-intro.html",
    "href": "docs/60-a-lineales-intro.html",
    "title": "Introducción a Modelos Lineales en Estadística",
    "section": "",
    "text": "La mayoría de las pruebas estadísticas comunes utilizadas en ciencias de la salud y biológicas, como el t-test, ANOVA, correlación, y otras, son casos especiales de modelos lineales o aproximaciones muy cercanas a ellos. Esta simplicidad subyacente nos permite simplificar el proceso de aprendizaje y enseñanza de la estadística. En lugar de tratar cada prueba estadística como una herramienta aislada, podemos enfocar el aprendizaje en el modelo lineal general y luego reconocer cada prueba como una variación de este modelo.\n\n\nSimplicidad del modelo lineal: Un modelo lineal sigue la fórmula básica: \\[\ny = a \\cdot x + b\n\\]\ndonde \\(y\\) es la variable dependiente, \\(x\\) es la variable independiente, \\(a\\) es la pendiente de la recta, y \\(b\\) es la intersección con el eje \\(y\\). Esta simplicidad subyacente es la base de muchas pruebas estadísticas comunes.\n\nEvitar la memorización: En lugar de memorizar las suposiciones paramétricas de cada prueba estadística por separado, los estudiantes pueden deducirlas a partir del modelo lineal, lo que simplifica el aprendizaje. Muchas veces es dificil recordar los supuestos de cada prueba, ¿qué tipo de distribución tienen los datos?, ¿son independientes?, ¿son homocedásticos?, etc. En su lugar, podemos recordar que el modelo lineal tiene supuestos más generales y que las pruebas específicas son casos especiales de este modelo.\nEnseñar modelos lineales primero: Al enseñar primero los modelos lineales y luego introducir los casos especiales (como el t-test o ANOVA), se promueve una comprensión más profunda de la estadística, en lugar de simplemente aprender mecánicamente cómo aplicar cada prueba.\nPruebas no paramétricas: Las pruebas “no paramétricas” pueden enseñarse como versiones ordenadas (ranking) de las pruebas paramétricas correspondientes. De esta forma, los estudiantes entienden que estas pruebas se basan en rangos y no en supuestos mágicos de eliminación de restricciones. Entenderás esto más adelante.\nAplicaciones en ciencias de la salud y biológicas: En estas disciplinas, el uso de modelos lineales es fundamental para analizar relaciones entre variables, como la relación entre un tratamiento y una respuesta biológica o la influencia de factores sociales en la salud."
  },
  {
    "objectID": "docs/60-a-lineales-intro.html#introducción-a-los-modelos-lineales",
    "href": "docs/60-a-lineales-intro.html#introducción-a-los-modelos-lineales",
    "title": "Introducción a Modelos Lineales en Estadística",
    "section": "",
    "text": "La mayoría de las pruebas estadísticas comunes utilizadas en ciencias de la salud y biológicas, como el t-test, ANOVA, correlación, y otras, son casos especiales de modelos lineales o aproximaciones muy cercanas a ellos. Esta simplicidad subyacente nos permite simplificar el proceso de aprendizaje y enseñanza de la estadística. En lugar de tratar cada prueba estadística como una herramienta aislada, podemos enfocar el aprendizaje en el modelo lineal general y luego reconocer cada prueba como una variación de este modelo.\n\n\nSimplicidad del modelo lineal: Un modelo lineal sigue la fórmula básica: \\[\ny = a \\cdot x + b\n\\]\ndonde \\(y\\) es la variable dependiente, \\(x\\) es la variable independiente, \\(a\\) es la pendiente de la recta, y \\(b\\) es la intersección con el eje \\(y\\). Esta simplicidad subyacente es la base de muchas pruebas estadísticas comunes.\n\nEvitar la memorización: En lugar de memorizar las suposiciones paramétricas de cada prueba estadística por separado, los estudiantes pueden deducirlas a partir del modelo lineal, lo que simplifica el aprendizaje. Muchas veces es dificil recordar los supuestos de cada prueba, ¿qué tipo de distribución tienen los datos?, ¿son independientes?, ¿son homocedásticos?, etc. En su lugar, podemos recordar que el modelo lineal tiene supuestos más generales y que las pruebas específicas son casos especiales de este modelo.\nEnseñar modelos lineales primero: Al enseñar primero los modelos lineales y luego introducir los casos especiales (como el t-test o ANOVA), se promueve una comprensión más profunda de la estadística, en lugar de simplemente aprender mecánicamente cómo aplicar cada prueba.\nPruebas no paramétricas: Las pruebas “no paramétricas” pueden enseñarse como versiones ordenadas (ranking) de las pruebas paramétricas correspondientes. De esta forma, los estudiantes entienden que estas pruebas se basan en rangos y no en supuestos mágicos de eliminación de restricciones. Entenderás esto más adelante.\nAplicaciones en ciencias de la salud y biológicas: En estas disciplinas, el uso de modelos lineales es fundamental para analizar relaciones entre variables, como la relación entre un tratamiento y una respuesta biológica o la influencia de factores sociales en la salud."
  },
  {
    "objectID": "docs/60-a-lineales-intro.html#introducción-a-los-modelos-lineales-1",
    "href": "docs/60-a-lineales-intro.html#introducción-a-los-modelos-lineales-1",
    "title": "Introducción a Modelos Lineales en Estadística",
    "section": "Introducción a los Modelos Lineales",
    "text": "Introducción a los Modelos Lineales\n\n¿Qué es un Modelo Lineal?\nUn modelo lineal es una herramienta matemática que describe la relación entre una o más variables predictoras (también llamadas variables independientes o explicativas) y una variable respuesta (también conocida como variable dependiente). Estos modelos son ampliamente utilizados en estadística y ciencia de datos porque permiten hacer predicciones, interpretar relaciones y entender los efectos de diferentes variables sobre un resultado de interés.\n\nUna variable predictora es una variable que se utiliza para predecir o explicar la variabilidad en otra variable (la variable de respuesta). Por ejemplo, en un modelo que predice el rendimiento académico de los estudiantes, las variables predictoras podrían ser el tiempo de estudio, la asistencia a clases y el nivel socioeconómico.\n\nEn su forma más simple, un modelo lineal busca ajustar una línea recta a los datos, de manera que exprese cómo cambia la variable de interés a medida que cambian las variables predictoras. La linealidad del modelo implica que el impacto de cada predictor sobre la variable de interés es constante y puede ser representado por una pendiente (o coeficiente) en la ecuación de la línea recta. Esto quedará más claro cuando construyamos un modelo lineal en R.\n\n\nEstructura del Modelo Lineal\nMatemáticamente, un modelo lineal simple para una variable predictora \\((x)\\) y una variable de respuesta \\((y)\\) se expresa como (observa que es una ecución de una recta, pero con un término de error que veremos más adelante):\n\\[\ny = \\beta_0 + \\beta_1 \\cdot x + \\epsilon\n\\]\n\n\\(y\\) es la variable respuesta o dependiente.\n\\(\\beta_0\\) es el intercepto o término constante, que representa el valor promedio de \\(y\\) cuando \\(x = 0\\).\n\\(\\beta_1\\) es la pendiente o el coeficiente de regresión, que mide el cambio en \\(y\\) por cada unidad de cambio en \\(x\\).\n\\(\\epsilon\\) es el término de error o residuo, que captura las variaciones de \\(y\\) no explicadas por el modelo lineal.\n\n\nVamos a visualizar un modelo lineal simple con un ejemplo práctico en R.\n\nRPython\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEste modelo es lineal porque la relación entre \\(x\\) y \\(y\\) está representada por una relación lineal.\nExplora cómo cambia la línea recta al modificar los valores de los coeficientes \\(\\beta_0\\) y \\(\\beta_1\\) en el modelo lineal. ¿Qué sucede con la pendiente y la intersección de la línea? ¿Cómo afecta esto a la relación entre \\(x\\) y \\(y\\)? Para cambiar los valores, haz click con tu mouse y arrastra los valores de 5 y 2 en la siguiente parte. El gráfico se actualizará automáticamente para que observes los cambios.\n\n\\(\\beta_0=\\)  (Intercepto)\n\\(\\beta_1=\\)  (Pendiente)\n\n\nimport {Tangle} from \"@mbostock/tangle\"\n\n// Setup Tangle reactive inputs\nviewof mean = Inputs.input(5); // Input for intercept (beta_0)\nviewof sd = Inputs.input(2);   // Input for slope (beta_1)\nmeanTgl = Inputs.bind(Tangle({min: -10, max: 10, minWidth: \"1em\", step: 0.1}), viewof mean); // Intercept control\nsdTgl = Inputs.bind(Tangle({min: -5, max: 5, minWidth: \"1em\", step: 0.1}), viewof sd);       // Slope control\n\n// draw plot in R\ndraw_plot_lineal(mean, sd)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExtensión a Múltiples Variables Predictoras: Regresión Lineal Múltiple\nEn muchos casos, queremos modelar el efecto de más de una variable predictora. El modelo lineal se extiende fácilmente a múltiples predictores:\n\\[\ny = \\beta_0 + \\beta_1 \\cdot x_1 + \\beta_2 \\cdot x_2 + \\dots + \\beta_p \\cdot x_p + \\epsilon\n\\]\nDonde: - (x_1, x_2, , x_p) son las variables predictoras. - **(_1, _2, , _p)** son los coeficientes asociados a cada predictor. - () es el término de error, que representa la diferencia entre los valores observados de \\(y\\) y los valores predichos por el modelo.\nEn el contexto de la regresión lineal múltiple, cada predictor tiene un efecto independiente sobre \\(y\\), y el modelo estima cómo cambiará \\(y\\) en función de cambios en cualquiera de los predictores, manteniendo los demás constantes. Este tipo de modelos es útil para estudiar la relación simultánea de varias variables con el resultado de interés.\nInterpretación de los Coeficientes del Modelo\nUno de los aspectos más útiles de los modelos lineales es la interpretación directa de los coeficientes (\\(\\beta_0, \\beta_1\\)):\n\nIntersección (\\(\\beta_0\\)): Representa el valor promedio de la variable respuesta \\(y\\) cuando todas las variables predictoras son iguales a cero. En muchos casos, esto tiene un significado concreto (por ejemplo, un valor base o inicial).\nPendiente (\\(\\beta_1\\)): Nos dice en cuánto cambiará \\(y\\) si \\(x\\) aumenta en una unidad.\n\n\n\n\n\n\n\nImportant\n\n\n\n\nAntes de seguir con las siguientes lecciones, observa este ejemplo con datos reales para entender cómo se ajusta un modelo lineal a los datos y cómo interpretar los coeficientes del modelo.\nVamos a regresar al ejemplo del módulo pasado de los pinguinos de Palmer. Primero, vamos a hacer el gráfico de dispersión de las variables masa_corporal_g y largo_aleta_mm para visualizar la relación entre ellas. Por el momento no vamos a dividir los datos por especie, sino que vamos a considerar todos los datos juntos.\n\n\n\n\n\n\n\n\n\n\nAhora, vamos a ajustar un modelo lineal simple a estos datos para predecir la longitud del pico a partir de la masa corporal.\nEn r, podemos lograr esto facilmente con la función geom_smooth() de ggplot2. Esta función ajusta un modelo lineal a los datos y muestra la línea de regresión en el gráfico de dispersión.\nObserva que geom_smooth toma el argumento method = \"lm\", que indica que queremos ajustar un modelo lineal a los datos. Este modelo será ajustado con la fórmula y ~ x, donde y es la variable dependiente y x es la variable independiente (estos datos los toma de los argumentos x y y de aes()). El argumento se = FALSE indica que no queremos mostrar el intervalo de confianza alrededor de la línea de regresión (esto se verá en otro módulo).\n\n\n\n\n\n\n\n\n\n\nObserva la línea roja en el gráfico de dispersión. Esta línea representa el modelo lineal ajustado a los datos. La intersección de la línea con el eje y es el valor de \\(\\beta_0\\) (intercepto) y la pendiente de la línea es el valor de \\(\\beta_1\\) (pendiente). En este caso, la pendiente nos dice cuánto aumenta la longitud del pico por cada gramo de masa corporal.\nSi quisieras obtener los valores de los coeficientes (intercepto y pendiente) del modelo lineal ajustado (la linea roja), puedes usar la función lm() de R. Esta función ajusta un modelo lineal (linear model) a los datos y te da acceso a los coeficientes del modelo utilizando la función coef(modelo). Por ejemplo, para ajustar un modelo lineal a los datos de masa corporal y longitud del pico, puedes hacer lo siguiente:\n\n\n\n\n\n\n\n\n\nEl resultado es:\n&gt; coeficientes\n    (Intercept) masa_corporal_g \n   136.72955927      0.01527592\ndonde el valor de Intercept es el valor de \\(\\beta_0\\) y el valor de masa_corporal_g es el valor de \\(\\beta_1\\). Esto significa que la longitud del pico aumenta en promedio 0.015 mm por cada gramo de masa corporal."
  },
  {
    "objectID": "docs/60-a-lineales-intro.html#resumen",
    "href": "docs/60-a-lineales-intro.html#resumen",
    "title": "Introducción a Modelos Lineales en Estadística",
    "section": "Resumen",
    "text": "Resumen\n\nLos modelos lineales son una herramienta matemática fundamental en estadística y ciencia de datos para describir la relación entre variables predictoras y una variable de respuesta.\nUn modelo lineal simple se ajusta a los datos mediante una línea recta, donde la pendiente y el intercepto representan la relación entre las variables.\nLa interpretación de los coeficientes del modelo lineal es directa: la pendiente nos dice cuánto cambia la variable de respuesta por cada unidad de cambio en la variable predictora, y el intercepto es el valor promedio de la variable de respuesta cuando la variable predictora es cero.\nLos modelos lineales son una base sólida para comprender y aplicar pruebas estadísticas comunes, como el t-test, ANOVA, regresión logística y más."
  },
  {
    "objectID": "docs/21-funciones-visualizacion.html#introducción",
    "href": "docs/21-funciones-visualizacion.html#introducción",
    "title": "Visualización de Datos Básica",
    "section": "Introducción",
    "text": "Introducción\nggplot2 es un paquete en R diseñado para crear visualizaciones de datos atractivas y flexibles. Sigue el paradigma de “The Grammar of Graphics”, que permite construir gráficos de manera incremental, añadiendo capas para personalizar cada aspecto de la gráfica.\nEste enfoque es potente, ya que puede crear visualizaciones desde gráficos sencillos hasta representaciones complejas, con una sintaxis consistente y entendible."
  },
  {
    "objectID": "docs/21-funciones-visualizacion.html#instalación-y-carga-de-ggplot2",
    "href": "docs/21-funciones-visualizacion.html#instalación-y-carga-de-ggplot2",
    "title": "Visualización de Datos Básica",
    "section": "Instalación y Carga de ggplot2",
    "text": "Instalación y Carga de ggplot2\nPara usar ggplot2, primero necesitas asegurarte de tenerlo instalado y cargado en tu entorno de R:\n# Instalar ggplot2 si aún no está instalado install.packages(\"ggplot2\")\n# Cargar ggplot2 library(ggplot2)"
  },
  {
    "objectID": "docs/21-funciones-visualizacion.html#conceptos-básicos-de-ggplot2",
    "href": "docs/21-funciones-visualizacion.html#conceptos-básicos-de-ggplot2",
    "title": "Visualización de Datos Básica",
    "section": "Conceptos Básicos de ggplot2",
    "text": "Conceptos Básicos de ggplot2\nLa función principal de ggplot2 es ggplot(). Aquí te mostramos cómo crear un gráfico básico utilizando el conjunto de datos mtcars.\nCrear un Gráfico de Dispersión:"
  },
  {
    "objectID": "docs/21-funciones-visualizacion.html#añadir-colores-por-categoría",
    "href": "docs/21-funciones-visualizacion.html#añadir-colores-por-categoría",
    "title": "Visualización de Datos Básica",
    "section": "Añadir Colores por Categoría",
    "text": "Añadir Colores por Categoría\nSupongamos que queremos colorear los puntos según la cantidad de cilindros del auto:"
  },
  {
    "objectID": "docs/21-funciones-visualizacion.html#crear-un-histograma",
    "href": "docs/21-funciones-visualizacion.html#crear-un-histograma",
    "title": "Visualización de Datos Básica",
    "section": "Crear un Histograma:",
    "text": "Crear un Histograma:"
  },
  {
    "objectID": "docs/21-funciones-visualizacion.html#ejercicio-crear-un-gráfico-básico",
    "href": "docs/21-funciones-visualizacion.html#ejercicio-crear-un-gráfico-básico",
    "title": "Visualización de Datos Básica",
    "section": "Ejercicio: Crear un Gráfico Básico",
    "text": "Ejercicio: Crear un Gráfico Básico\nUsa el conjunto de datos mtcars para crear un gráfico de dispersión de wt (peso) contra mpg.\nAñade un título y etiquetas a los ejes.\nColorea los puntos según gear.\nCódigo del Ejercicio:"
  },
  {
    "objectID": "docs/21-funciones-visualizacion.html#reflexión",
    "href": "docs/21-funciones-visualizacion.html#reflexión",
    "title": "Visualización de Datos Básica",
    "section": "Reflexión",
    "text": "Reflexión\n¿Cómo ayuda la visualización a entender mejor los datos que estás analizando?\nExplora otros conjuntos de datos y trata de visualizar relaciones clave o distribuciones interesantes.\nEsta lección te ofrece un vistazo rápido al poder de ggplot2, preparando el terreno para futuras exploraciones más profundas en visualización de datos. Familiarizarte con estos conceptos básicos te permitirá comunicar tus hallazgos de manera más eficaz y atractiva."
  },
  {
    "objectID": "docs/86-anova-una-via-python.html",
    "href": "docs/86-anova-una-via-python.html",
    "title": "ANOVA de Una Vía en Python",
    "section": "",
    "text": "El Análisis de Varianza de una vía (One-way ANOVA) es una extensión de la prueba t independiente para comparar medias cuando tenemos tres o más grupos. Es la versión paramétrica del test de Kruskal-Wallis.\n\n\n\nCompara medias: Evalúa si las medias de varios grupos son estadísticamente diferentes\nUn solo factor: Analiza el efecto de una sola variable independiente (factor)\nMúltiples grupos: Funciona con 3 o más grupos (con 2 grupos es equivalente a t-test)\n\n\n\n\nEl ANOVA compara dos tipos de variabilidad: 1. Variabilidad entre grupos: ¿Qué tan diferentes son las medias de los grupos? 2. Variabilidad dentro de grupos: ¿Qué tan variables son los datos dentro de cada grupo?\nSi la variabilidad entre grupos es mucho mayor que la variabilidad dentro de grupos, concluimos que hay diferencias significativas."
  },
  {
    "objectID": "docs/86-anova-una-via-python.html#qué-es-el-anova-de-una-vía",
    "href": "docs/86-anova-una-via-python.html#qué-es-el-anova-de-una-vía",
    "title": "ANOVA de Una Vía en Python",
    "section": "",
    "text": "El Análisis de Varianza de una vía (One-way ANOVA) es una extensión de la prueba t independiente para comparar medias cuando tenemos tres o más grupos. Es la versión paramétrica del test de Kruskal-Wallis.\n\n\n\nCompara medias: Evalúa si las medias de varios grupos son estadísticamente diferentes\nUn solo factor: Analiza el efecto de una sola variable independiente (factor)\nMúltiples grupos: Funciona con 3 o más grupos (con 2 grupos es equivalente a t-test)\n\n\n\n\nEl ANOVA compara dos tipos de variabilidad: 1. Variabilidad entre grupos: ¿Qué tan diferentes son las medias de los grupos? 2. Variabilidad dentro de grupos: ¿Qué tan variables son los datos dentro de cada grupo?\nSi la variabilidad entre grupos es mucho mayor que la variabilidad dentro de grupos, concluimos que hay diferencias significativas."
  },
  {
    "objectID": "docs/86-anova-una-via-python.html#hipótesis-del-anova",
    "href": "docs/86-anova-una-via-python.html#hipótesis-del-anova",
    "title": "ANOVA de Una Vía en Python",
    "section": "Hipótesis del ANOVA",
    "text": "Hipótesis del ANOVA\n\nH₀: Todas las medias poblacionales son iguales (μ₁ = μ₂ = μ₃ = … = μₖ)\nH₁: Al menos una media poblacional es diferente"
  },
  {
    "objectID": "docs/86-anova-una-via-python.html#supuestos-del-anova",
    "href": "docs/86-anova-una-via-python.html#supuestos-del-anova",
    "title": "ANOVA de Una Vía en Python",
    "section": "Supuestos del ANOVA",
    "text": "Supuestos del ANOVA\n\nIndependencia: Las observaciones deben ser independientes\nNormalidad: Los datos deben seguir una distribución normal en cada grupo\nHomogeneidad de varianzas: Las varianzas deben ser iguales entre grupos (homocedasticidad)"
  },
  {
    "objectID": "docs/86-anova-una-via-python.html#ejemplo-práctico-crecimiento-de-plantas",
    "href": "docs/86-anova-una-via-python.html#ejemplo-práctico-crecimiento-de-plantas",
    "title": "ANOVA de Una Vía en Python",
    "section": "Ejemplo Práctico: Crecimiento de Plantas",
    "text": "Ejemplo Práctico: Crecimiento de Plantas\nUsaremos un conjunto de datos sobre el crecimiento de plantas bajo diferentes tratamientos (control, tratamiento 1, tratamiento 2).\n\n1. Cargar librerías y datos\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2. Exploración de Datos\n\n\n\n\n\n\n\n\n\n\n3. Visualización de los Datos\n\n\n\n\n\n\n\n\n\n\n4. Verificación de Supuestos\n\n4.1 Prueba de Normalidad\n\n\n\n\n\n\n\n\n\n\n4.2 Prueba de Homogeneidad de Varianzas\n\n\n\n\n\n\n\n\n\n\n4.3 Gráficos de Diagnóstico\n\n\n\n\n\n\n\n\n\n\n\n5. ANOVA de Una Vía\n\n\n\n\n\n\n\n\n\n\n6. Interpretación de Resultados\n\n\n\n\n\n\n\n\n\n\n7. Comparaciones Post-Hoc (si es necesario)\n\n\n\n\n\n\n\n\n\n\n8. Visualización Final con Resultados\n\n\n\n\n\n\n\n\n\n\n9. Comparación con Alternativa No Paramétrica"
  },
  {
    "objectID": "docs/86-anova-una-via-python.html#cuándo-usar-anova-vs-alternativas",
    "href": "docs/86-anova-una-via-python.html#cuándo-usar-anova-vs-alternativas",
    "title": "ANOVA de Una Vía en Python",
    "section": "Cuándo Usar ANOVA vs Alternativas",
    "text": "Cuándo Usar ANOVA vs Alternativas\nUsa ANOVA cuando: - Los supuestos se cumplen (normalidad y homogeneidad) - Quieres mayor poder estadístico - Los tamaños de muestra son adecuados\nUsa Kruskal-Wallis cuando: - Los supuestos del ANOVA se violan - Los datos son ordinales - Hay valores atípicos extremos\nUsa transformaciones cuando: - Los supuestos se violan ligeramente - La transformación mejora la normalidad/homogeneidad"
  },
  {
    "objectID": "docs/86-anova-una-via-python.html#resumen-de-la-metodología",
    "href": "docs/86-anova-una-via-python.html#resumen-de-la-metodología",
    "title": "ANOVA de Una Vía en Python",
    "section": "Resumen de la Metodología",
    "text": "Resumen de la Metodología\n\nExploración: Estadísticas descriptivas y visualización\nVerificación de supuestos: Normalidad (Shapiro-Wilk) y homogeneidad (Levene)\nANOVA: Calcular estadístico F y p-valor\nInterpretación: Decidir sobre H₀ y calcular tamaño del efecto\nPost-hoc: Si es significativo, identificar qué grupos difieren\nValidación: Comparar con alternativas no paramétricas si es necesario"
  },
  {
    "objectID": "docs/82-comparar-3medias.html",
    "href": "docs/82-comparar-3medias.html",
    "title": "Comparing the means of more than two groups",
    "section": "",
    "text": "What is one-way ANOVA test?\nAssumptions of ANOVA test\nHow one-way ANOVA test works?\nVisualize your data and compute one-way ANOVA in R\n\nImport your data into R\nCheck your data\nVisualize your data\nCompute one-way ANOVA test\nInterpret the result of one-way ANOVA tests\nMultiple pairwise-comparison between the means of groups\n\nTukey multiple pairwise-comparisons\nMultiple comparisons using multcomp package\nPairewise t-test\n\nCheck ANOVA assumptions: test validity?\n\nCheck the homogeneity of variance assumption\nRelaxing the homogeneity of variance assumption\nCheck the normality assumption\n\nNon-parametric alternative to one-way ANOVA test\n\nSummary\nSee also\nRead more\nInfos"
  },
  {
    "objectID": "docs/82-comparar-3medias.html#what-is-one-way-anova-test",
    "href": "docs/82-comparar-3medias.html#what-is-one-way-anova-test",
    "title": "Comparing the means of more than two groups",
    "section": "What is one-way ANOVA test?",
    "text": "What is one-way ANOVA test?\nThe one-way analysis of variance (ANOVA), also known as one-factor ANOVA, is an extension of independent two-samples t-test for comparing means in a situation where there are more than two groups. In one-way ANOVA, the data is organized into several groups base on one single grouping variable (also called factor variable). This tutorial describes the basic principle of the one-way ANOVA test and provides practical anova test examples in R software.\nANOVA test hypotheses:\n\nNull hypothesis: the means of the different groups are the same\nAlternative hypothesis: At least one sample mean is not equal to the others.\n\nNote that, if you have only two groups, you can use t-test. In this case the F-test and the t-test are equivalent.\n\n\n\nOne-Way ANOVA Test"
  },
  {
    "objectID": "docs/82-comparar-3medias.html#assumptions-of-anova-test",
    "href": "docs/82-comparar-3medias.html#assumptions-of-anova-test",
    "title": "Comparing the means of more than two groups",
    "section": "Assumptions of ANOVA test",
    "text": "Assumptions of ANOVA test\nHere we describe the requirement for ANOVA test. ANOVA test can be applied only when:\n\nThe observations are obtained independently and randomly from the population defined by the factor levels\nThe data of each factor level are normally distributed.\nThese normal populations have a common variance. (Levene’s test can be used to check this.)"
  },
  {
    "objectID": "docs/82-comparar-3medias.html#how-one-way-anova-test-works",
    "href": "docs/82-comparar-3medias.html#how-one-way-anova-test-works",
    "title": "Comparing the means of more than two groups",
    "section": "How one-way ANOVA test works?",
    "text": "How one-way ANOVA test works?\nAssume that we have 3 groups (A, B, C) to compare:\n\nCompute the common variance, which is called variance within samples (Swithin2) or residual variance.\nCompute the variance between sample means as follow:\n\nCompute the mean of each group\nCompute the variance between sample means (Sbetween2)\n\nProduce F-statistic as the ratio of Sbetween2/Swithin2.\n\nNote that, a lower ratio (ratio &lt; 1) indicates that there are no significant difference between the means of the samples being compared. However, a higher ratio implies that the variation among group means are significant."
  },
  {
    "objectID": "docs/82-comparar-3medias.html#visualize-your-data-and-compute-one-way-anova-in-r",
    "href": "docs/82-comparar-3medias.html#visualize-your-data-and-compute-one-way-anova-in-r",
    "title": "Comparing the means of more than two groups",
    "section": "Visualize your data and compute one-way ANOVA in R",
    "text": "Visualize your data and compute one-way ANOVA in R"
  },
  {
    "objectID": "docs/82-comparar-3medias.html#import-your-data-into-r",
    "href": "docs/82-comparar-3medias.html#import-your-data-into-r",
    "title": "Comparing the means of more than two groups",
    "section": "Import your data into R",
    "text": "Import your data into R\n\nPrepare your data as specified here: Best practices for preparing your data set for R\nSave your data in an external .txt tab or .csv files\nImport your data into R as follow:\n\n&lt;span&gt;# If .txt tab file, use this&lt;/span&gt;\n&lt;span&gt;my_data&lt;/span&gt; &lt;span&gt;&lt;-&lt;/span&gt; &lt;span&gt;read.delim&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;file.choose&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n&lt;span&gt;# Or, if .csv file, use this&lt;/span&gt;\n&lt;span&gt;my_data&lt;/span&gt; &lt;span&gt;&lt;-&lt;/span&gt; &lt;span&gt;read.csv&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;file.choose&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\nHere, we’ll use the built-in R data set named PlantGrowth. It contains the weight of plants obtained under a control and two different treatment conditions.\n&lt;span&gt;my_data&lt;/span&gt; &lt;span&gt;&lt;-&lt;/span&gt; &lt;span&gt;PlantGrowth&lt;/span&gt;"
  },
  {
    "objectID": "docs/82-comparar-3medias.html#check-your-data",
    "href": "docs/82-comparar-3medias.html#check-your-data",
    "title": "Comparing the means of more than two groups",
    "section": "Check your data",
    "text": "Check your data\nTo have an idea of what the data look like, we use the the function sample_n()[in dplyr package]. The sample_n() function randomly picks a few of the observations in the data frame to print out:\n&lt;span&gt;# Show a random sample&lt;/span&gt;\n&lt;span&gt;set.seed&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;1234&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n&lt;span&gt;dplyr&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;sample_n&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;my_data&lt;/span&gt;, &lt;span&gt;10&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n   weight group\n19   4.32  trt1\n18   4.89  trt1\n29   5.80  trt2\n24   5.50  trt2\n17   6.03  trt1\n1    4.17  ctrl\n6    4.61  ctrl\n16   3.83  trt1\n12   4.17  trt1\n15   5.87  trt1\nIn R terminology, the column “group” is called factor and the different categories (“ctr”, “trt1”, “trt2”) are named factor levels. The levels are ordered alphabetically.\n&lt;span&gt;# Show the levels&lt;/span&gt;\n&lt;span&gt;levels&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;my_data&lt;/span&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt;group&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n[1] \"ctrl\" \"trt1\" \"trt2\"\nIf the levels are not automatically in the correct order, re-order them as follow:\n&lt;span&gt;my_data&lt;/span&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt;group&lt;/span&gt; &lt;span&gt;&lt;-&lt;/span&gt; &lt;span&gt;ordered&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;my_data&lt;/span&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt;group&lt;/span&gt;,\n                         &lt;span&gt;levels&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;\"ctrl\"&lt;/span&gt;, &lt;span&gt;\"trt1\"&lt;/span&gt;, &lt;span&gt;\"trt2\"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\nIt’s possible to compute summary statistics (mean and sd) by groups using the dplyr package.\n\nCompute summary statistics by groups - count, mean, sd:\n\n&lt;span&gt;library&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;dplyr&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n&lt;span&gt;group_by&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;my_data&lt;/span&gt;, &lt;span&gt;group&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;%&gt;%&lt;/span&gt;\n  &lt;span&gt;summarise&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;\n    &lt;span&gt;count&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;n&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;,\n    &lt;span&gt;mean&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;mean&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;weight&lt;/span&gt;, &lt;span&gt;na.rm&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;TRUE&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;,\n    &lt;span&gt;sd&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;sd&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;weight&lt;/span&gt;, &lt;span&gt;na.rm&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;TRUE&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n  &lt;span&gt;)&lt;/span&gt;\nSource: local data frame [3 x 4]\n   group count  mean        sd\n  (fctr) (int) (dbl)     (dbl)\n1   ctrl    10 5.032 0.5830914\n2   trt1    10 4.661 0.7936757\n3   trt2    10 5.526 0.4425733"
  },
  {
    "objectID": "docs/82-comparar-3medias.html#visualize-your-data",
    "href": "docs/82-comparar-3medias.html#visualize-your-data",
    "title": "Comparing the means of more than two groups",
    "section": "Visualize your data",
    "text": "Visualize your data\n\nTo use R base graphs read this: R base graphs. Here, we’ll use the ggpubr R package for an easy ggplot2-based data visualization.\nInstall the latest version of ggpubr from GitHub as follow (recommended):\n\n&lt;span&gt;# Install&lt;/span&gt;\n&lt;span&gt;if&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;!&lt;/span&gt;&lt;span&gt;require&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;devtools&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;install.packages&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;\"devtools\"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n&lt;span&gt;devtools&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;install_github&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;\"kassambara/ggpubr\"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n\nOr, install from CRAN as follow:\n\n&lt;span&gt;install.packages&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;\"ggpubr\"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n\nVisualize your data with ggpubr:\n\n&lt;span&gt;# Box plots&lt;/span&gt;\n&lt;span&gt;# ++++++++++++++++++++&lt;/span&gt;\n&lt;span&gt;# Plot weight by group and color by group&lt;/span&gt;\n&lt;span&gt;library&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;\"ggpubr\"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n&lt;span&gt;ggboxplot&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;my_data&lt;/span&gt;, &lt;span&gt;x&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;\"group\"&lt;/span&gt;, &lt;span&gt;y&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;\"weight\"&lt;/span&gt;, \n          &lt;span&gt;color&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;\"group\"&lt;/span&gt;, &lt;span&gt;palette&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;\"#00AFBB\"&lt;/span&gt;, &lt;span&gt;\"#E7B800\"&lt;/span&gt;, &lt;span&gt;\"#FC4E07\"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;,\n          &lt;span&gt;order&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;\"ctrl\"&lt;/span&gt;, &lt;span&gt;\"trt1\"&lt;/span&gt;, &lt;span&gt;\"trt2\"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;,\n          &lt;span&gt;ylab&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;\"Weight\"&lt;/span&gt;, &lt;span&gt;xlab&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;\"Treatment\"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n\n\n\nOne-way ANOVA Test in R\n\n\n&lt;span&gt;# Mean plots&lt;/span&gt;\n&lt;span&gt;# ++++++++++++++++++++&lt;/span&gt;\n&lt;span&gt;# Plot weight by group&lt;/span&gt;\n&lt;span&gt;# Add error bars: mean_se&lt;/span&gt;\n&lt;span&gt;# (other values include: mean_sd, mean_ci, median_iqr, ....)&lt;/span&gt;\n&lt;span&gt;library&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;\"ggpubr\"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n&lt;span&gt;ggline&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;my_data&lt;/span&gt;, &lt;span&gt;x&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;\"group\"&lt;/span&gt;, &lt;span&gt;y&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;\"weight\"&lt;/span&gt;, \n       &lt;span&gt;add&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;\"mean_se\"&lt;/span&gt;, &lt;span&gt;\"jitter\"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;, \n       &lt;span&gt;order&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;\"ctrl\"&lt;/span&gt;, &lt;span&gt;\"trt1\"&lt;/span&gt;, &lt;span&gt;\"trt2\"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;,\n       &lt;span&gt;ylab&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;\"Weight\"&lt;/span&gt;, &lt;span&gt;xlab&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;\"Treatment\"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n\n\n\nOne-way ANOVA Test in R\n\n\nIf you still want to use R base graphs, type the following scripts:\n&lt;span&gt;# Box plot&lt;/span&gt;\n&lt;span&gt;boxplot&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;weight&lt;/span&gt; &lt;span&gt;~&lt;/span&gt; &lt;span&gt;group&lt;/span&gt;, &lt;span&gt;data&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;my_data&lt;/span&gt;,\n        &lt;span&gt;xlab&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;\"Treatment\"&lt;/span&gt;, &lt;span&gt;ylab&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;\"Weight\"&lt;/span&gt;,\n        &lt;span&gt;frame&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;FALSE&lt;/span&gt;, &lt;span&gt;col&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;\"#00AFBB\"&lt;/span&gt;, &lt;span&gt;\"#E7B800\"&lt;/span&gt;, &lt;span&gt;\"#FC4E07\"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n&lt;span&gt;# plotmeans&lt;/span&gt;\n&lt;span&gt;library&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;\"gplots\"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n&lt;span&gt;plotmeans&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;weight&lt;/span&gt; &lt;span&gt;~&lt;/span&gt; &lt;span&gt;group&lt;/span&gt;, &lt;span&gt;data&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;my_data&lt;/span&gt;, &lt;span&gt;frame&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;FALSE&lt;/span&gt;,\n          &lt;span&gt;xlab&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;\"Treatment\"&lt;/span&gt;, &lt;span&gt;ylab&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;\"Weight\"&lt;/span&gt;,\n          &lt;span&gt;main&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;\"Mean Plot with 95% CI\"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;"
  },
  {
    "objectID": "docs/82-comparar-3medias.html#compute-one-way-anova-test",
    "href": "docs/82-comparar-3medias.html#compute-one-way-anova-test",
    "title": "Comparing the means of more than two groups",
    "section": "Compute one-way ANOVA test",
    "text": "Compute one-way ANOVA test\nWe want to know if there is any significant difference between the average weights of plants in the 3 experimental conditions.\nThe R function aov() can be used to answer to this question. The function summary.aov() is used to summarize the analysis of variance model.\n&lt;span&gt;# Compute the analysis of variance&lt;/span&gt;\n&lt;span&gt;res.aov&lt;/span&gt; &lt;span&gt;&lt;-&lt;/span&gt; &lt;span&gt;aov&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;weight&lt;/span&gt; &lt;span&gt;~&lt;/span&gt; &lt;span&gt;group&lt;/span&gt;, &lt;span&gt;data&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;my_data&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n&lt;span&gt;# Summary of the analysis&lt;/span&gt;\n&lt;span&gt;summary&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;res.aov&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n            Df Sum Sq Mean Sq F value Pr(&gt;F)  \ngroup        2  3.766  1.8832   4.846 0.0159 *\nResiduals   27 10.492  0.3886                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nThe output includes the columns F value and Pr(&gt;F) corresponding to the p-value of the test."
  },
  {
    "objectID": "docs/82-comparar-3medias.html#interpret-the-result-of-one-way-anova-tests",
    "href": "docs/82-comparar-3medias.html#interpret-the-result-of-one-way-anova-tests",
    "title": "Comparing the means of more than two groups",
    "section": "Interpret the result of one-way ANOVA tests",
    "text": "Interpret the result of one-way ANOVA tests\nAs the p-value is less than the significance level 0.05, we can conclude that there are significant differences between the groups highlighted with “*” in the model summary."
  },
  {
    "objectID": "docs/82-comparar-3medias.html#multiple-pairwise-comparison-between-the-means-of-groups",
    "href": "docs/82-comparar-3medias.html#multiple-pairwise-comparison-between-the-means-of-groups",
    "title": "Comparing the means of more than two groups",
    "section": "Multiple pairwise-comparison between the means of groups",
    "text": "Multiple pairwise-comparison between the means of groups\nIn one-way ANOVA test, a significant p-value indicates that some of the group means are different, but we don’t know which pairs of groups are different.\nIt’s possible to perform multiple pairwise-comparison, to determine if the mean difference between specific pairs of group are statistically significant.\n\nTukey multiple pairwise-comparisons\nAs the ANOVA test is significant, we can compute Tukey HSD (Tukey Honest Significant Differences, R function: TukeyHSD()) for performing multiple pairwise-comparison between the means of groups.\nThe function TukeyHD() takes the fitted ANOVA as an argument.\n&lt;span&gt;TukeyHSD&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;res.aov&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\nFit: aov(formula = weight ~ group, data = my_data)\n$group\n            diff        lwr       upr     p adj\ntrt1-ctrl -0.371 -1.0622161 0.3202161 0.3908711\ntrt2-ctrl  0.494 -0.1972161 1.1852161 0.1979960\ntrt2-trt1  0.865  0.1737839 1.5562161 0.0120064\n\ndiff: difference between means of the two groups\nlwr, upr: the lower and the upper end point of the confidence interval at 95% (default)\np adj: p-value after adjustment for the multiple comparisons.\n\nIt can be seen from the output, that only the difference between trt2 and trt1 is significant with an adjusted p-value of 0.012.\n\n\nMultiple comparisons using multcomp package\nIt’s possible to use the function glht() [in multcomp package] to perform multiple comparison procedures for an ANOVA. glht stands for general linear hypothesis tests. The simplified format is as follow:\n&lt;span&gt;glht&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;model&lt;/span&gt;, &lt;span&gt;lincft&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n\nmodel: a fitted model, for example an object returned by aov().\nlincft(): a specification of the linear hypotheses to be tested. Multiple comparisons in ANOVA models are specified by objects returned from the function mcp().\n\nUse glht() to perform multiple pairwise-comparisons for a one-way ANOVA:\n&lt;span&gt;library&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;multcomp&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n&lt;span&gt;summary&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;glht&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;res.aov&lt;/span&gt;, &lt;span&gt;linfct&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;mcp&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;group&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;\"Tukey\"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n\n     Simultaneous Tests for General Linear Hypotheses\nMultiple Comparisons of Means: Tukey Contrasts\nFit: aov(formula = weight ~ group, data = my_data)\nLinear Hypotheses:\n                 Estimate Std. Error t value Pr(&gt;|t|)  \ntrt1 - ctrl == 0  -0.3710     0.2788  -1.331    0.391  \ntrt2 - ctrl == 0   0.4940     0.2788   1.772    0.198  \ntrt2 - trt1 == 0   0.8650     0.2788   3.103    0.012 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nPairewise t-test\nThe function pairewise.t.test() can be also used to calculate pairwise comparisons between group levels with corrections for multiple testing.\n&lt;span&gt;pairwise.t.test&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;my_data&lt;/span&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt;weight&lt;/span&gt;, &lt;span&gt;my_data&lt;/span&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt;group&lt;/span&gt;,\n                 &lt;span&gt;p.adjust.method&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;\"BH\"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n\n    Pairwise comparisons using t tests with pooled SD \ndata:  my_data$weight and my_data$group \n     ctrl  trt1 \ntrt1 0.194 -    \ntrt2 0.132 0.013\nP value adjustment method: BH \nThe result is a table of p-values for the pairwise comparisons. Here, the p-values have been adjusted by the Benjamini-Hochberg method."
  },
  {
    "objectID": "docs/82-comparar-3medias.html#check-anova-assumptions-test-validity",
    "href": "docs/82-comparar-3medias.html#check-anova-assumptions-test-validity",
    "title": "Comparing the means of more than two groups",
    "section": "Check ANOVA assumptions: test validity?",
    "text": "Check ANOVA assumptions: test validity?\nThe ANOVA test assumes that, the data are normally distributed and the variance across groups are homogeneous. We can check that with some diagnostic plots.\n\nCheck the homogeneity of variance assumption\nThe residuals versus fits plot can be used to check the homogeneity of variances.\nIn the plot below, there is no evident relationships between residuals and fitted values (the mean of each groups), which is good. So, we can assume the homogeneity of variances.\n&lt;span&gt;# 1. Homogeneity of variances&lt;/span&gt;\n&lt;span&gt;plot&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;res.aov&lt;/span&gt;, &lt;span&gt;1&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n\n\n\nOne-way ANOVA Test in R\n\n\nPoints 17, 15, 4 are detected as outliers, which can severely affect normality and homogeneity of variance. It can be useful to remove outliers to meet the test assumptions.\nIt’s also possible to use Bartlett’s test or Levene’s test to check the homogeneity of variances.\nWe recommend Levene’s test, which is less sensitive to departures from normal distribution. The function leveneTest() [in car package] will be used:\n&lt;span&gt;library&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;car&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n&lt;span&gt;leveneTest&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;weight&lt;/span&gt; &lt;span&gt;~&lt;/span&gt; &lt;span&gt;group&lt;/span&gt;, &lt;span&gt;data&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;my_data&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup  2  1.1192 0.3412\n      27               \nFrom the output above we can see that the p-value is not less than the significance level of 0.05. This means that there is no evidence to suggest that the variance across groups is statistically significantly different. Therefore, we can assume the homogeneity of variances in the different treatment groups.\n\n\nRelaxing the homogeneity of variance assumption\nThe classical one-way ANOVA test requires an assumption of equal variances for all groups. In our example, the homogeneity of variance assumption turned out to be fine: the Levene test is not significant.\nHow do we save our ANOVA test, in a situation where the homogeneity of variance assumption is violated?\nAn alternative procedure (i.e.: Welch one-way test), that does not require that assumption have been implemented in the function oneway.test().\n\nANOVA test with no assumption of equal variances\n\n&lt;span&gt;oneway.test&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;weight&lt;/span&gt; &lt;span&gt;~&lt;/span&gt; &lt;span&gt;group&lt;/span&gt;, &lt;span&gt;data&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;my_data&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n\nPairwise t-tests with no assumption of equal variances\n\n&lt;span&gt;pairwise.t.test&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;my_data&lt;/span&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt;weight&lt;/span&gt;, &lt;span&gt;my_data&lt;/span&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt;group&lt;/span&gt;,\n                 &lt;span&gt;p.adjust.method&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;\"BH\"&lt;/span&gt;, &lt;span&gt;pool.sd&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;FALSE&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n\n\nCheck the normality assumption\nNormality plot of residuals. In the plot below, the quantiles of the residuals are plotted against the quantiles of the normal distribution. A 45-degree reference line is also plotted.\nThe normal probability plot of residuals is used to check the assumption that the residuals are normally distributed. It should approximately follow a straight line.\n&lt;span&gt;# 2. Normality&lt;/span&gt;\n&lt;span&gt;plot&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;res.aov&lt;/span&gt;, &lt;span&gt;2&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n\n\n\nOne-way ANOVA Test in R\n\n\nAs all the points fall approximately along this reference line, we can assume normality.\nThe conclusion above, is supported by the Shapiro-Wilk test on the ANOVA residuals (W = 0.96, p = 0.6) which finds no indication that normality is violated.\n&lt;span&gt;# Extract the residuals&lt;/span&gt;\n&lt;span&gt;aov_residuals&lt;/span&gt; &lt;span&gt;&lt;-&lt;/span&gt; &lt;span&gt;residuals&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;object&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;res.aov&lt;/span&gt; &lt;span&gt;)&lt;/span&gt;\n&lt;span&gt;# Run Shapiro-Wilk test&lt;/span&gt;\n&lt;span&gt;shapiro.test&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;x&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;aov_residuals&lt;/span&gt; &lt;span&gt;)&lt;/span&gt;\n\n    Shapiro-Wilk normality test\ndata:  aov_residuals\nW = 0.96607, p-value = 0.4379"
  },
  {
    "objectID": "docs/82-comparar-3medias.html#non-parametric-alternative-to-one-way-anova-test",
    "href": "docs/82-comparar-3medias.html#non-parametric-alternative-to-one-way-anova-test",
    "title": "Comparing the means of more than two groups",
    "section": "Non-parametric alternative to one-way ANOVA test",
    "text": "Non-parametric alternative to one-way ANOVA test\nNote that, a non-parametric alternative to one-way ANOVA is Kruskal-Wallis rank sum test, which can be used when ANNOVA assumptions are not met.\n&lt;span&gt;kruskal.test&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;weight&lt;/span&gt; &lt;span&gt;~&lt;/span&gt; &lt;span&gt;group&lt;/span&gt;, &lt;span&gt;data&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;my_data&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;\n\n    Kruskal-Wallis rank sum test\ndata:  weight by group\nKruskal-Wallis chi-squared = 7.9882, df = 2, p-value = 0.01842"
  },
  {
    "objectID": "docs/82-comparar-3medias.html#summary",
    "href": "docs/82-comparar-3medias.html#summary",
    "title": "Comparing the means of more than two groups",
    "section": "Summary",
    "text": "Summary\n\nImport your data from a .txt tab file: my_data &lt;- read.delim(file.choose()). Here, we used my_data &lt;- PlantGrowth.\nVisualize your data: ggpubr::ggboxplot(my_data, x = “group”, y = “weight”, color = “group”)\nCompute one-way ANOVA test: summary(aov(weight ~ group, data = my_data))\nTukey multiple pairwise-comparisons: TukeyHSD(res.aov)"
  },
  {
    "objectID": "docs/82-comparar-3medias.html#see-also",
    "href": "docs/82-comparar-3medias.html#see-also",
    "title": "Comparing the means of more than two groups",
    "section": "See also",
    "text": "See also\n\nAnalysis of variance (ANOVA, parametric):\n\nOne-Way ANOVA Test in R\nTwo-Way ANOVA Test in R\nMANOVA Test in R: Multivariate Analysis of Variance\n\nKruskal-Wallis Test in R (non parametric alternative to one-way ANOVA)"
  },
  {
    "objectID": "docs/82-comparar-3medias.html#read-more",
    "href": "docs/82-comparar-3medias.html#read-more",
    "title": "Comparing the means of more than two groups",
    "section": "Read more",
    "text": "Read more\n\n(Quick-R: ANOVA/MANOVA)[http://www.statmethods.net/stats/anova.html]\n(Quick-R: (M)ANOVA Assumptions)[http://www.statmethods.net/stats/anovaAssumptions.html]\n(R and Analysis of Variance)[http://personality-project.org/r/r.guide/r.anova.html"
  },
  {
    "objectID": "docs/82-comparar-3medias.html#infos",
    "href": "docs/82-comparar-3medias.html#infos",
    "title": "Comparing the means of more than two groups",
    "section": "Infos",
    "text": "Infos\nThis analysis has been performed using R software (ver. 3.2.4).\nEnjoyed this article? I’d be very grateful if you’d help it spread by emailing it to a friend, or sharing it on Twitter, Facebook or Linked In.\nShow me some love with the like buttons below… Thank you and please don’t forget to share and comment below!!"
  },
  {
    "objectID": "docs/82-comparar-3medias.html#recommended-for-you",
    "href": "docs/82-comparar-3medias.html#recommended-for-you",
    "title": "Comparing the means of more than two groups",
    "section": "Recommended for You!",
    "text": "Recommended for You!\n Get involved :\n  Click to follow us on Facebook :   \n  Comment this article by clicking on “Discussion” button (top-right position of this page)"
  },
  {
    "objectID": "docs/41-ejercicios-evalintro-python.html",
    "href": "docs/41-ejercicios-evalintro-python.html",
    "title": "Ejercicio Práctico - Estudio de Caso con Python",
    "section": "",
    "text": "Para concluir la sección de introducción, integremos todo lo aprendido para abordar un problema práctico. Usaremos el conjunto de datos oms del paquete datos. Este dataset incluye información sobre la tuberculosis (TB), desglosada por año, país, edad, género y método de diagnóstico. Estos datos provienen del Informe de Tuberculosis de la Organización Mundial de la Salud 2014.\nEste dataset contiene mucha información epidemiológica, solo que tiene un detalle muy importante: los datos están muy “sucios”. Para limpiarlos y explorarlos, necesitamos aplicar todo lo que hemos aprendido.\nEl objetivo es que puedas limpiar, explorar, visualizar y describir el dataset oms para obtener información relevante sobre la tuberculosis en el mundo. En la vida real, los datos que obtenemos rara vez están limpios y listos para ser analizados. Por lo tanto, es fundamental que sepas cómo limpiarlos y explorarlos para obtener información valiosa."
  },
  {
    "objectID": "docs/41-ejercicios-evalintro-python.html#introducción",
    "href": "docs/41-ejercicios-evalintro-python.html#introducción",
    "title": "Ejercicio Práctico - Estudio de Caso con Python",
    "section": "",
    "text": "Para concluir la sección de introducción, integremos todo lo aprendido para abordar un problema práctico. Usaremos el conjunto de datos oms del paquete datos. Este dataset incluye información sobre la tuberculosis (TB), desglosada por año, país, edad, género y método de diagnóstico. Estos datos provienen del Informe de Tuberculosis de la Organización Mundial de la Salud 2014.\nEste dataset contiene mucha información epidemiológica, solo que tiene un detalle muy importante: los datos están muy “sucios”. Para limpiarlos y explorarlos, necesitamos aplicar todo lo que hemos aprendido.\nEl objetivo es que puedas limpiar, explorar, visualizar y describir el dataset oms para obtener información relevante sobre la tuberculosis en el mundo. En la vida real, los datos que obtenemos rara vez están limpios y listos para ser analizados. Por lo tanto, es fundamental que sepas cómo limpiarlos y explorarlos para obtener información valiosa."
  },
  {
    "objectID": "docs/41-ejercicios-evalintro-python.html#preparación",
    "href": "docs/41-ejercicios-evalintro-python.html#preparación",
    "title": "Ejercicio Práctico - Estudio de Caso con Python",
    "section": "Preparación",
    "text": "Preparación\nPrimero, vamos a cargar el dataset y a explorar su estructura.\n\n\n\n\n\n\n\n\n¿Qué problemas observas con este dataset? Observa que tiene: - Columnas redundantes. - Variables con nombres poco descriptivos. - Valores faltantes (NaN).\nSi no sabemos qué significan las variables, es imposible analizar los datos. En pandas, podemos usar el método .info() para obtener un resumen de la estructura del DataFrame.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nUsa el nombre del DataFrame seguido de .info().\n\n\n\n\n\n\n\n\n\nRespuesta\n\n\n\n\n\noms.info()"
  },
  {
    "objectID": "docs/41-ejercicios-evalintro-python.html#limpiar-datos",
    "href": "docs/41-ejercicios-evalintro-python.html#limpiar-datos",
    "title": "Ejercicio Práctico - Estudio de Caso con Python",
    "section": "Limpiar datos",
    "text": "Limpiar datos\nA partir de la descripción del dataset, podemos ver distintos problemas. Vamos a limpiar los datos por partes.\n\nExisten 3 variables que se refieren a país (pais, iso2, iso3). Vamos a quitar 2 de estas 3 variables (iso2, iso3).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nRecuerda el método .drop() de pandas.\n\n\n\n\n\n\n\n\n\nRespuesta\n\n\n\n\n\noms_2 = oms.drop(columns=['iso2', 'iso3'])\noms_2.head()\n\n\n\n\nDespués, tenemos una variable que indica año (anio). Explora qué tipo de variable es y conviértela a una variable de tipo category.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nUsa el método .astype() para cambiar el tipo de dato.\n\n\n\n\n\n\n\n\n\nRespuesta\n\n\n\n\n\noms_3 = oms_2.astype({'anio': 'category'})\n\noms_3.info() # Verificamos el cambio\n\n\n\n\nAhora, tenemos que solucionar el mayor problema de estos datos: las 56 columnas restantes son redundantes. Todas representan la cuenta de casos de TB. Podemos reestructurar estas columnas a un formato largo usando melt(). \nPara juntar y agrupar, usaremos la función melt() de pandas.\nEl reto es juntar las 56 variables. La forma más fácil es especificar las columnas que queremos mantener fijas (id_vars).\nAl correr el siguiente código, deberías tener un dataframe con 4 columnas: pais, anio, clave y casos.\nOjo: en este paso, también vamos a eliminar las filas con valores faltantes con el método .dropna().\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nLas columnas que no se “derriten” son pais y anio.\n\n\n\n\n\n\n\n\n\nRespuesta\n\n\n\n\n\noms_4 = oms_3.melt(\n    id_vars=[\"pais\", \"anio\"], \n    var_name=\"clave\", \n    value_name=\"casos\"\n).dropna(subset=[\"casos\"])\n\noms_4.head()\n\n\n\n\nAhora, pon atención en los nombres de la columna clave. Estos nombres son poco descriptivos. Vamos a limpiarlos.\nSi revisas la estructura de los datos, verás que los nombres de las columnas clave siguen ciertos patrones.\nCuando tienen las siguientes letras, significan lo siguiente:\n\nrecaida se refiere a casos reincidentes\nep se refiere a tuberculosis extra pulmonar\nfpp se refiere a casos de tuberculosis pulmonar que se pueden detectar mediante examen de frotis pulmonar (frotis pulmonar positivo)\nLa letra que aparece después del último _ se refiere al sexo de los pacientes (m o f).\nLos números finales se refieren al grupo de edad.\n\nIdealmente, queremos que estos patrones se conviertan en variables separadas.\nPara empezar, observa que hay casos donde tenemos el patrón nuevosrecaida en lugar de nuevos_recaida. Vamos a corregirlo.\nUsaremos el accesor .str de pandas y su método replace().\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRespuesta\n\n\n\n\n\noms_5 = oms_4.copy()\noms_5[\"clave\"] = oms_5[\"clave\"].str.replace(\"nuevosrecaida\", \"nuevos_recaida\")\noms_5.head()\n\n\n\n\nAhora, vamos a separar la columna clave en varias columnas usando el separador _.\nUsaremos el método .str.split() con expand=True.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRespuesta\n\n\n\n\n\noms_6 = oms_5.copy()\noms_6[['nuevos', 'tipo', 'sexo_edad']] = oms_6['clave'].str.split('_', expand=True)\noms_6.head()\n\n\n\n\nA continuación podemos eliminar las columnas nuevos y clave que ya no necesitamos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nRecuerda el método drop().\n\n\n\n\n\n\n\n\n\nRespuesta\n\n\n\n\n\noms_7 = oms_6.drop(columns=['nuevos', 'clave'])\noms_7.head()\n\n\n\n\nPara separar la columna sexo_edad en sexo y edad, podemos usar slicing con el accesor .str.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRespuesta\n\n\n\n\n\noms_8 = oms_7.copy()\noms_8['sexo'] = oms_8['sexo_edad'].str[0]\noms_8['edad'] = oms_8['sexo_edad'].str[1:]\noms_8 = oms_8.drop(columns=['sexo_edad'])\noms_8.head()"
  },
  {
    "objectID": "docs/41-ejercicios-evalintro-python.html#todo-en-un-solo-paso",
    "href": "docs/41-ejercicios-evalintro-python.html#todo-en-un-solo-paso",
    "title": "Ejercicio Práctico - Estudio de Caso con Python",
    "section": "Todo en un solo paso…",
    "text": "Todo en un solo paso…\n\nUna vez que entiendes cómo funcionan los métodos, puedes encadenarlos para hacer todo en un solo paso.\nEsto es útil y muy común en pandas.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUna vez que ejecutas el código completo, ¿cuánto tiempo tardó en limpiar estos 70,000 datos?\n¿Cuánto tiempo te hubiera tomado hacerlo a mano o en Excel?\nLa eficiencia de pandas es una de las razones por las que es tan popular en la ciencia de datos.\nAdemás, es menos propenso a errores, en especial si construyes tu código de forma ordenada y sistemática.\nAunque al principio puede ser complicado, con la práctica, te volverás más rápido y eficiente en el manejo de datos.\nImagina que tienes que hacer esto con 100 datasets. ¿Cuánto tiempo te ahorrarías?\n\n\n\n\nSi todo va bien hasta ahora, deberías de tener un dataset similar a este. En el siguiente ejercicio exploraremos estos datos limpios."
  },
  {
    "objectID": "docs/52-anova-dosvias-python.html",
    "href": "docs/52-anova-dosvias-python.html",
    "title": "ANOVA de Dos Vías con Python",
    "section": "",
    "text": "El ANOVA de dos vías es una técnica estadística que extiende el ANOVA de una vía para analizar cómo dos variables categóricas independientes (factores) influyen en una variable dependiente continua. Además, permite investigar si existe una interacción entre los dos factores, es decir, si el efecto de un factor depende del nivel del otro."
  },
  {
    "objectID": "docs/52-anova-dosvias-python.html#introducción-al-anova-de-dos-vías",
    "href": "docs/52-anova-dosvias-python.html#introducción-al-anova-de-dos-vías",
    "title": "ANOVA de Dos Vías con Python",
    "section": "",
    "text": "El ANOVA de dos vías es una técnica estadística que extiende el ANOVA de una vía para analizar cómo dos variables categóricas independientes (factores) influyen en una variable dependiente continua. Además, permite investigar si existe una interacción entre los dos factores, es decir, si el efecto de un factor depende del nivel del otro."
  },
  {
    "objectID": "docs/52-anova-dosvias-python.html#conceptos-clave",
    "href": "docs/52-anova-dosvias-python.html#conceptos-clave",
    "title": "ANOVA de Dos Vías con Python",
    "section": "Conceptos Clave",
    "text": "Conceptos Clave\n\nEfectos Principales: Miden el efecto de cada factor por separado sobre la variable dependiente.\nEfecto de Interacción: Evalúa si la relación entre un factor y la variable dependiente cambia según los niveles del otro factor.\nModelo Lineal: La fórmula del modelo incluye los efectos principales y el término de interacción: [ y = _0 + _1 X_1 + _2 X_2 + _3 (X_1 X_2) + ] Donde (X_1) y (X_2) son los factores."
  },
  {
    "objectID": "docs/52-anova-dosvias-python.html#ejercicio-práctico-en-python",
    "href": "docs/52-anova-dosvias-python.html#ejercicio-práctico-en-python",
    "title": "ANOVA de Dos Vías con Python",
    "section": "Ejercicio Práctico en Python",
    "text": "Ejercicio Práctico en Python\nRealizaremos un ANOVA de dos vías para investigar cómo el tipo de tratamiento y el sexo afectan la reducción del colesterol."
  },
  {
    "objectID": "docs/52-anova-dosvias-python.html#interpretación-y-discusión",
    "href": "docs/52-anova-dosvias-python.html#interpretación-y-discusión",
    "title": "ANOVA de Dos Vías con Python",
    "section": "Interpretación y Discusión",
    "text": "Interpretación y Discusión\n\nAnaliza la tabla ANOVA: ¿Son significativos los efectos principales del tratamiento y el sexo? ¿Y el efecto de interacción?\nObserva el gráfico de interacción: Si las líneas no son paralelas, sugiere una interacción. ¿Cómo interpretarías la relación entre el tratamiento y el sexo en este caso?\n\nEsta lección ayuda a comprender cómo el ANOVA de dos vías puede desentrañar relaciones complejas entre múltiples factores, una herramienta esencial en la investigación biológica y de la salud."
  },
  {
    "objectID": "docs/83-no-parametrico.html",
    "href": "docs/83-no-parametrico.html",
    "title": "No paramétricos y violación de supuestos",
    "section": "",
    "text": "Análisis Paramétrico y No Paramétrico: Ventajas, Supuestos y Cuándo Usarlos\n\nAnálisis Paramétrico\nEl análisis paramétrico se basa en el supuesto de que los datos provienen de una distribución específica, generalmente la distribución normal. Los análisis paramétricos son potentes, ya que utilizan las propiedades conocidas de distribuciones como la normal para calcular probabilidades y realizar inferencias sobre la población de la cual se extrajo la muestra.\n\n\nSupuestos del Análisis Paramétrico\n\nMuestras aleatorias e independientes: Este es el supuesto más importante en cualquier análisis estadístico. Los datos deben ser independientes entre sí y haberse recolectado de manera aleatoria para que los resultados sean válidos.\nDistribución especificada (normalidad): Los datos deben provenir de una distribución normal, o al menos aproximarse a ella. Para muchas pruebas paramétricas (como el ANOVA), se supone que las medias de los grupos siguen una distribución normal con varianzas homogéneas entre los grupos.\nVarianza homogénea: En pruebas como el ANOVA, se asume que las varianzas dentro de cada grupo son similares. Esta suposición puede ser violada levemente si los tamaños de muestra son grandes, pero es más importante cuando los tamaños de muestra son pequeños.\n\n\n\nVentajas del Análisis Paramétrico\n\nMayor poder estadístico: Las pruebas paramétricas tienden a ser más poderosas que las no paramétricas, lo que significa que tienen una mayor probabilidad de detectar una diferencia real cuando la hipótesis alternativa es verdadera.\nFlexibilidad en diseños complejos: Existen muchas pruebas paramétricas que se ajustan a diseños experimentales complicados, como el ANOVA de medidas repetidas, ANCOVA, y ANOVA multifactorial.\n\n\n\nDesventajas del Análisis Paramétrico\n\nSensibilidad a los supuestos: Si los datos no cumplen con los supuestos de normalidad, independencia o varianza homogénea, los resultados de las pruebas paramétricas pueden ser incorrectos o engañosos.\nDifícil de aplicar con pequeños tamaños de muestra: Cuando los tamaños de muestra son pequeños, las pruebas paramétricas pueden volverse inexactas si los datos no siguen una distribución normal.\n\n\n\n\nAnálisis No Paramétrico\nEl análisis no paramétrico, también conocido como pruebas libres de distribución, no requiere que los datos sigan una distribución específica (como la normal). Estas pruebas son útiles cuando los datos no cumplen con los supuestos de las pruebas paramétricas o cuando los datos son ordinales o categóricos.\n\nCuándo Usar una Prueba No Paramétrica\n\nDatos ordinales o de rango: Si los datos son ordinales (por ejemplo, clasificaciones o escalas de calificación), las pruebas no paramétricas son más apropiadas, ya que no se puede calcular una media significativa de estos datos.\nDatos con outliers: Si los datos contienen valores atípicos extremos que distorsionan la distribución, una prueba no paramétrica puede ser más robusta, ya que no se basa en la media, sino en posiciones relativas o rangos.\nDistribución no normal: Si los datos claramente no siguen una distribución normal (como datos sesgados o con límites claros), es mejor aplicar una prueba no paramétrica, especialmente cuando la transformación de los datos no corrige el problema.\nPequeñas muestras: Las pruebas paramétricas requieren muestras suficientemente grandes para que el Teorema Central del Límite garantice que la distribución de la media sea aproximadamente normal. Con tamaños de muestra pequeños, las pruebas no paramétricas son más confiables si no se puede asumir la normalidad.\n\n\n\nPruebas No Paramétricas Comunes\n\nPrueba de Mann-Whitney U: Es la alternativa no paramétrica a la prueba t de dos muestras independientes. Compara las diferencias en las distribuciones de dos grupos sin asumir normalidad.\nPrueba de Kruskal-Wallis: Alternativa no paramétrica al ANOVA de una vía. Compara las distribuciones de más de dos grupos independientes.\nPrueba de Wilcoxon: Alternativa no paramétrica a la prueba t de muestras pareadas. Es útil cuando se tienen dos muestras relacionadas o emparejadas.\nPrueba de Friedman: Alternativa no paramétrica al ANOVA de medidas repetidas. Se usa cuando se toman múltiples medidas en las mismas unidades experimentales.\n\n\n\nVentajas del Análisis No Paramétrico\n\nMenos supuestos: No requiere que los datos provengan de una distribución normal, lo que lo hace más flexible cuando los datos no cumplen con los supuestos paramétricos.\nRobustez: Menos influenciado por valores atípicos o desviaciones graves de la normalidad.\n\n\n\nDesventajas del Análisis No Paramétrico\n\nMenor poder estadístico: Las pruebas no paramétricas suelen ser menos poderosas que sus contrapartes paramétricas. Esto significa que, cuando la hipótesis alternativa es cierta, es menos probable que una prueba no paramétrica rechace la hipótesis nula.\nMenos información sobre parámetros: No proporcionan estimaciones de parámetros como la media o la varianza, lo que puede limitar las inferencias que se pueden hacer a partir de los resultados.\n\n\n\n\nCómo Decidir entre Pruebas Paramétricas y No Paramétricas\nLa decisión de usar una prueba paramétrica o no paramétrica no debe automatizarse, ya que depende de varios factores:\n\nEvaluar la normalidad de los datos: Si los datos son continuos, se puede evaluar la normalidad utilizando pruebas como:\n\nPrueba de Shapiro-Wilk.\nPrueba de Anderson-Darling.\nPrueba de Kolmogorov-Smirnov.\n\nSin embargo, las pruebas de normalidad pueden tener baja potencia con muestras pequeñas, lo que significa que podrían no detectar desviaciones de la normalidad. También pueden ser demasiado sensibles con tamaños de muestra grandes, detectando desviaciones triviales que no afectan los análisis.\nInspección visual: Un enfoque práctico es utilizar gráficos (como histogramas, diagramas de caja, o gráficos Q-Q) para evaluar si los datos parecen seguir una distribución normal. Si los datos son claramente no normales o contienen outliers significativos, una prueba no paramétrica puede ser más adecuada.\nConsiderar transformaciones: En lugar de pasar directamente a un análisis no paramétrico, también se puede considerar una transformación de los datos (por ejemplo, logaritmos o recíprocos) para aproximar mejor una distribución normal.\nTamaño de la muestra: En conjuntos de datos pequeños, la decisión entre una prueba paramétrica y no paramétrica es más crítica debido a la baja potencia de las pruebas. En datos grandes, incluso pequeñas desviaciones de la normalidad pueden ser detectadas, pero es importante considerar si esas desviaciones son lo suficientemente significativas como para invalidar una prueba paramétrica.\n\n\n\nErrores Comunes al Decidir entre Paramétrico y No Paramétrico\n\nNo considerar transformaciones: Saltar directamente a pruebas no paramétricas sin intentar transformar los datos primero puede ser un error, ya que las transformaciones pueden resolver los problemas de normalidad mientras conservan el poder de las pruebas paramétricas.\nUso ciego de pruebas de normalidad: Basarse exclusivamente en pruebas de normalidad automáticas puede llevar a decisiones incorrectas, especialmente con tamaños de muestra pequeños o grandes. La inspección visual y el conocimiento de la naturaleza de los datos son esenciales.\nIgnorar el contexto del estudio: La decisión entre pruebas paramétricas y no paramétricas no debe basarse solo en una prueba de normalidad; debe considerar el diseño del estudio, el tamaño de la muestra y los objetivos del análisis.\n\n\n\nConclusión\nLa elección entre una prueba paramétrica y una no paramétrica depende de varios factores, incluidos los supuestos de los datos, el tamaño de la muestra y la distribución subyacente. Los análisis paramétricos ofrecen más poder estadístico cuando se cumplen los supuestos, mientras que las pruebas no paramétricas proporcionan flexibilidad cuando los datos no siguen una distribución normal o hay outliers. La clave es no automatizar esta decisión, sino evaluar cuidadosamente la naturaleza de los datos antes de seleccionar el método más adecuado.\n\n\nCómo abordar la violación de los supuestos de normalidad en un análisis de regresión lineal múltiple (MLR)\nEn la regresión lineal múltiple (MLR), uno de los supuestos clave es que los residuos (errores) siguen una distribución normal. Sin embargo, en la práctica, este supuesto a menudo se viola. Afortunadamente, existen varias estrategias para manejar la violación de este supuesto sin comprometer la validez del análisis. A continuación se describen algunas de las técnicas más utilizadas:\n\n\n1. Transformaciones de los Datos\nLas transformaciones son una de las soluciones más comunes para abordar la no normalidad en los datos o los residuos. Las transformaciones pueden hacer que los datos se ajusten mejor a una distribución normal, especialmente cuando los datos están sesgados o tienen una dispersión desigual.\n\nTransformación logarítmica: Puede ser útil cuando los datos están sesgados positivamente (cola larga hacia la derecha). Por ejemplo, si tienes datos financieros con distribuciones sesgadas, aplicar el logaritmo puede reducir la asimetría.\n[ Y’ = (Y) ]\nTransformación raíz cuadrada: Se utiliza para datos que tienen una variabilidad creciente a medida que aumentan los valores. Es útil para reducir la heterocedasticidad y la asimetría.\n[ Y’ = ]\nTransformación inversa: Puede ser útil cuando los datos tienen una fuerte asimetría positiva.\n[ Y’ = ]\nTransformación Box-Cox: Es una transformación general que encuentra el mejor ajuste entre varias transformaciones posibles.\n[ Y’ = , ]\n\nLa elección de la transformación depende del problema específico, y es recomendable probar varias transformaciones para observar cuál mejora más la normalidad de los residuos.\n\n\n\n2. Métodos Robustos\nLos métodos robustos son menos sensibles a los outliers y a distribuciones de colas pesadas, lo que los hace útiles cuando la normalidad no se cumple. Estos métodos no dependen de los supuestos estrictos de los mínimos cuadrados ordinarios (OLS).\n\nRegresión robusta (M-estimadores): Los M-estimadores minimizan una función que penaliza menos los outliers, a diferencia de OLS, que minimiza la suma de los errores al cuadrado. Esto reduce el impacto de los valores atípicos en los coeficientes de regresión.\nRegresión con estimación S: Similar a los M-estimadores, pero se enfoca en minimizar la dispersión de los residuos, proporcionando una solución más robusta a outliers.\n\nEstos métodos te permiten realizar análisis más robustos cuando los supuestos de normalidad o la presencia de outliers pueden sesgar los resultados de OLS.\n\n\n\n3. Métodos No Paramétricos\nCuando los datos no cumplen con los supuestos de normalidad y las transformaciones no ayudan, los métodos no paramétricos pueden ser una excelente alternativa. A diferencia de los métodos paramétricos, los métodos no paramétricos no suponen ninguna distribución específica de los datos.\n\nPrueba de Wilcoxon o prueba de rangos con signo de Wilcoxon: Es una alternativa no paramétrica a la prueba t para muestras independientes o relacionadas.\nRegresión no paramétrica: Existen regresiones no paramétricas, como la regresión por núcleos (kernel regression) o la regresión local (LOESS), que no hacen suposiciones sobre la forma funcional de la relación entre las variables dependientes e independientes.\n\nEstos métodos son útiles cuando la forma funcional del modelo o la distribución de los errores no es clara y no se pueden hacer suposiciones sobre la distribución de los datos.\n\n\n\n4. Detección y Eliminación de Valores Atípicos (Outliers)\nLos outliers pueden tener un impacto desproporcionado en el análisis y violar los supuestos de normalidad. Es esencial identificarlos y decidir si deben eliminarse o manejarse de otra manera.\n\nGráficos de caja (boxplots): Son una herramienta simple y efectiva para detectar outliers. Los puntos que caen fuera de los bigotes del gráfico podrían ser posibles outliers.\nGráficos de dispersión: Ayudan a detectar outliers en relaciones bivariadas o multivariadas. Los puntos que se encuentran muy lejos del ajuste del modelo pueden ser outliers.\nDistancia de Cook: Es una métrica útil para identificar observaciones que tienen un gran impacto en el ajuste del modelo. Si una observación tiene una distancia de Cook alta, podría ser un outlier influyente.\n\nUna vez que se identifican los outliers, se puede optar por eliminarlos, tratarlos con métodos robustos o transformarlos, dependiendo de la naturaleza del estudio.\n\n\n\n5. Selección y Evaluación del Modelo\nA veces, la violación de los supuestos de normalidad puede ser una señal de que el modelo está mal especificado. En lugar de ajustar los datos al modelo, puede ser más apropiado reconsiderar el modelo en sí.\n\nModelos no lineales: Si la relación entre las variables no es lineal, el uso de un modelo no lineal (como la regresión polinómica o la regresión logarítmica) puede mejorar el ajuste y los residuos pueden ajustarse mejor a una distribución normal.\nModelos generalizados: Si los datos no son normales, los modelos lineales generalizados (GLM) ofrecen una alternativa flexible, permitiendo que la variable dependiente siga distribuciones como Poisson, binomial negativa, gamma, entre otras.\n\n\n\n\n\nConclusión\nCuando los supuestos de normalidad se violan en un análisis de regresión lineal múltiple, existen varias estrategias para abordar el problema:\n\nTransformaciones: Aplicar transformaciones a los datos puede corregir la asimetría y mejorar la normalidad.\nMétodos robustos: Usar métodos de regresión robusta que sean menos sensibles a outliers o distribuciones de colas pesadas.\nMétodos no paramétricos: Usar métodos que no requieran suposiciones sobre la distribución de los datos.\nDetección y eliminación de outliers: Identificar y manejar valores atípicos que puedan estar distorsionando el análisis.\nReevaluación del modelo: Considerar un modelo diferente, como uno no lineal o un modelo generalizado, si el modelo lineal no es apropiado.\n\nLa elección de la estrategia depende de la naturaleza de los datos y el contexto del análisis. Es fundamental evaluar cuidadosamente las opciones antes de proceder con el análisis final."
  },
  {
    "objectID": "docs/54-corr-plottip-R.html",
    "href": "docs/54-corr-plottip-R.html",
    "title": "Correlación - Tip para graficos listos para publicar",
    "section": "",
    "text": "Los diagramas de dispersión se utilizan para mostrar la relación entre dos variables, x - y.\nEn esta lección, vamos a crear gráficos de dispersión en R y a añadir información adicional para hacerlos más informativos y atractivos.\nUtilizaremos funciones auxiliares del paquete ggpubr de R para mostrar automáticamente el coeficiente de correlación y el nivel de significancia en el gráfico.\nEste paquete utiliza una sintaxis similar a ggplot2, pero está diseñado para hacer que los gráficos sean más fáciles de personalizar y añadir información adicional, como el coeficiente de correlación."
  },
  {
    "objectID": "docs/54-corr-plottip-R.html#instalar-y-cargar-paquetes-necesarios",
    "href": "docs/54-corr-plottip-R.html#instalar-y-cargar-paquetes-necesarios",
    "title": "Correlación - Tip para graficos listos para publicar",
    "section": "Instalar y cargar paquetes necesarios",
    "text": "Instalar y cargar paquetes necesarios\nPara instalar el paquete ggpubr, puedes usar el siguiente comando:\ninstall.packages(\"ggpubr\")\nSi tienes problemas con el comando anterior, también puedes instalarlo desde github con el siguiente comando:\n# Install\nif(!require(devtools)) install.packages(\"devtools\")\ndevtools::install_github(\"kassambara/ggpubr\")\nPara cargar el paquete ggpubr, puedes usar el siguiente comando:\n\n\n\n\n\n\n\n\nPara este ejemplo, vamos a usar el conjunto de datos mtcars que viene incluido en R. Este conjunto de datos contiene información sobre diferentes modelos de automóviles, incluyendo el número de cilindros, la potencia bruta, la velocidad máxima, y otras variables."
  },
  {
    "objectID": "docs/54-corr-plottip-R.html#crear-un-gráfico-de-dispersión-con-ggpubr",
    "href": "docs/54-corr-plottip-R.html#crear-un-gráfico-de-dispersión-con-ggpubr",
    "title": "Correlación - Tip para graficos listos para publicar",
    "section": "Crear un gráfico de dispersión con ggpubr",
    "text": "Crear un gráfico de dispersión con ggpubr\n\nPara crear un gráfico de dispersión con ggpubr, usaremos la función ggscatter() del paquete ggpubr.\nEsta función es similar a ggplot2::geom_point(), pero añade automáticamente el coeficiente de correlación y el nivel de significancia en el gráfico.\nA continuación, vamos a crear un gráfico de dispersión entre la variable mpg (millas por galón) y la variable wt (peso en miles de libras) del conjunto de datos mtcars.\nObserva que la estructura de la función ggscatter() es similar a la de ggplot2, con algunas diferencias en los argumentos; por ejemplo, add = \"reg.line\" añade una línea de regresión al gráfico.\nSin embargo, la idea es similar: especificamos el tipo de gráfico, los datos, las variables x y, y otros argumentos para personalizar el gráfico.\n\n\n\n\n\n\n\n\n\n\nCon tan solo unas pocas líneas de código, hemos creado un gráfico de dispersión informativo y atractivo que muestra la relación entre las variables mpg y wt del conjunto de datos mtcars.\nEl gráfico incluye:\n\nuna línea de regresión, la cual muestra la tendencia general de los datos\nel coeficiente de correlación de Pearson, que indica la fuerza y la dirección de la relación entre las variables.\nel nivel de significancia (p-valor) del coeficiente de correlación, que indica si la relación es estadísticamente significativa. Todavía no vemos a fondo los valores p, pero recuerda que un valor p menor a 0.05 generalmente se considera estadísticamente significativo, es decir, se rechaza la hipótesis nula de que no hay relación entre las variables.\n\n\n\nAgrupar por una variable categórica\n\nComo hemos visto en otros gráficos, podemos especificar una variable categórica para agrupar los puntos en el gráfico de dispersión.\nPor ejemplo, podemos usar la variable cyl (número de cilindros) para agrupar los puntos en el gráfico de dispersión. Además, podemos personalizar los colores y las formas de los puntos para cada grupo.\n\nEn ggplot, hacíamos esto de esta manera: (aes(shape = cyl, color = cyl)).\n\nEn ggpubr, es muy similar, con la ventaja que ahora podemos añadir el coeficiente de correlación y el nivel de significancia para cada grupo. Todo de manera automática.\n\nPara obtener el coeficiente de correlación por grupos, usamos stat_cor(aes(color = cyl), label.x = 25). Esto añade el coeficiente de correlación para cada grupo en la posición x = 25. El eje y se ajusta automáticamente.\n\n\nUsamos palette = \"jco\" para especificar una paleta de colores predefinida. En ggpubr, hay varias paletas de colores disponibles para personalizar los gráficos. Incluye paletas de journals científicos como “jco” (Journal of Cell), “npg” (Nature Publishing Group), y “lancet”. Puedes conocer más sobre las paletas de colores en la documentación del paquete (en este enlace)\n\n\n\n\n\n\n\n\n\n\n\nAgregar gráficos marginales\n\nOtra característica interesante de ggpubr es la capacidad de añadir gráficos marginales a los gráficos de dispersión.\nLos gráficos marginales muestran la distribución de las variables x e y en los márgenes del gráfico de dispersión.\nComo vimos previamente, para visualizar la distribución de una variable, podemos usar histogramas, densidades y/o boxplots.\nPara esto, usamos otro paquete de ayuda llamado ggExtra, que nos permite añadir gráficos marginales a los gráficos de dispersión. Puedes instalarlo con el siguiente comando: install.packages(“ggExtra”).\n\nPrimero, guardamos el gráfico de dispersión en un objeto p.\nLuego, usamos la función ggMarginal() para añadir un gráfico marginal al gráfico de dispersión. Especificamos el tipo de gráfico marginal con el argumento type. Por ejemplo, type = \"density\" añade un gráfico de densidad en los márgenes, y type = \"boxplot\" añade un gráfico de caja y bigotes (boxplot) en los márgenes."
  },
  {
    "objectID": "docs/54-corr-plottip-R.html#recursos-adicionales",
    "href": "docs/54-corr-plottip-R.html#recursos-adicionales",
    "title": "Correlación - Tip para graficos listos para publicar",
    "section": "Recursos adicionales",
    "text": "Recursos adicionales\n\nDocumentación oficial de ggpubr: enlace\nTutorial de ggpubr en DataNovia: enlace\nPaletas de colores disponibles en ggpubr: enlace"
  },
  {
    "objectID": "docs/70-a-estimacion-inferencia.html",
    "href": "docs/70-a-estimacion-inferencia.html",
    "title": "Estimación e Inferencia Estadística",
    "section": "",
    "text": "La inferencia estadística se refiere al conjunto de operaciones que realizamos sobre los datos para obtener estimaciones y declaraciones de incertidumbre sobre predicciones y parámetros de algún proceso o población subyacente. Desde una perspectiva matemática, estas declaraciones de incertidumbre probabilística se derivan sobre la base de un modelo de probabilidad asumido para los datos observados. En esta sección, cubrimos los conceptos básicos de la modelización probabilística, estimación, sesgo y varianza, y la interpretación de las inferencias y errores estadísticos en el trabajo aplicado. Además, introducimos el tema de la incertidumbre en la inferencia estadística y por qué es un error utilizar pruebas de hipótesis o significancia estadística para atribuir certeza a datos ruidosos."
  },
  {
    "objectID": "docs/70-a-estimacion-inferencia.html#inferencia-estadística",
    "href": "docs/70-a-estimacion-inferencia.html#inferencia-estadística",
    "title": "Estimación e Inferencia Estadística",
    "section": "",
    "text": "La inferencia estadística se refiere al conjunto de operaciones que realizamos sobre los datos para obtener estimaciones y declaraciones de incertidumbre sobre predicciones y parámetros de algún proceso o población subyacente. Desde una perspectiva matemática, estas declaraciones de incertidumbre probabilística se derivan sobre la base de un modelo de probabilidad asumido para los datos observados. En esta sección, cubrimos los conceptos básicos de la modelización probabilística, estimación, sesgo y varianza, y la interpretación de las inferencias y errores estadísticos en el trabajo aplicado. Además, introducimos el tema de la incertidumbre en la inferencia estadística y por qué es un error utilizar pruebas de hipótesis o significancia estadística para atribuir certeza a datos ruidosos."
  },
  {
    "objectID": "docs/70-a-estimacion-inferencia.html#muestras-y-poblaciones",
    "href": "docs/70-a-estimacion-inferencia.html#muestras-y-poblaciones",
    "title": "Estimación e Inferencia Estadística",
    "section": "Muestras y Poblaciones",
    "text": "Muestras y Poblaciones\nEn biología, a menudo se desea hacer inferencias sobre una población, que se define como el conjunto de todas las posibles observaciones de interés. Es importante aclarar que en este contexto hablamos de una población estadística, no necesariamente de una población biológica. Las observaciones que recolectamos de la población forman una muestra, y el número de observaciones en la muestra se denomina tamaño de muestra, generalmente simbolizado como \\(n\\).\n\nLas características que medimos en la muestra se llaman estadísticos (por ejemplo, la media muestral).\nLas características de la población se llaman parámetros (por ejemplo, la media poblacional).\n\nEl método básico para recolectar observaciones en una muestra se llama muestreo aleatorio simple, donde cada observación tiene la misma probabilidad de ser seleccionada. Por ejemplo, asignar un número a cada rata en un corral y seleccionar una muestra usando una tabla de números aleatorios. Sin embargo, en la práctica, rara vez realizamos un muestreo completamente aleatorio en biología, confiando a menudo en el muestreo fortuito por razones prácticas.\nEl objetivo es siempre tomar la muestra de manera que no cree sesgo a favor de ninguna observación.\n\nDefinición de la Población\nEs fundamental definir claramente la población al inicio de cualquier estudio, incluyendo los límites espaciales y temporales de dicha población, ya que nuestras inferencias estadísticas estarán restringidas a estos límites. Si, por ejemplo, recolectamos datos de una población de animales en una ubicación específica en diciembre de 1996, nuestras inferencias se limitarán a esa ubicación y período de tiempo. No podemos inferir directamente lo que sucederá en otros lugares o momentos, aunque podríamos especular o hacer predicciones.\n\n\nMuestreo Aleatorio y Estimación de Parámetros\nEl principal motivo para realizar un muestreo aleatorio de una población bien definida es usar los estadísticos muestrales (por ejemplo, la media o la varianza de la muestra) para estimar los parámetros poblacionales (por ejemplo, la media o la varianza de la población). Los parámetros poblacionales no pueden medirse directamente debido al tamaño de las poblaciones, que suelen ser demasiado grandes para una medición práctica.\nEs importante recordar que los parámetros poblacionales se consideran valores fijos pero desconocidos, por lo que no son variables aleatorias y no tienen distribuciones de probabilidad. Los estadísticos muestrales, en cambio, sí son variables aleatorias, ya que sus valores dependen del experimento de muestreo. Por lo tanto, tienen distribuciones de probabilidad, llamadas distribuciones de muestreo."
  },
  {
    "objectID": "docs/70-a-estimacion-inferencia.html#tipos-de-estimadores",
    "href": "docs/70-a-estimacion-inferencia.html#tipos-de-estimadores",
    "title": "Estimación e Inferencia Estadística",
    "section": "Tipos de Estimadores",
    "text": "Tipos de Estimadores\nExisten dos tipos principales de estimación:\n\nEstimación puntual: Proporciona un único valor que estima el parámetro poblacional. Por ejemplo, la media de una muestra se usa como una estimación puntual de la media poblacional.\nEstimación por intervalo: Proporciona un rango de valores que probablemente contengan el parámetro poblacional con una probabilidad conocida. Un ejemplo común es el intervalo de confianza, que indica un rango de valores dentro del cual es probable que se encuentre el parámetro verdadero con una cierta confianza (por ejemplo, 95%).\n\n\nEjemplos en R: Estimación Puntual e Intervalo de Confianza\nA continuación, se muestran ejemplos en R para calcular una estimación puntual (media muestral) y un intervalo de confianza para la media poblacional.\nEstimación Puntual de la Media\n\nPrimero, generamos una muestra aleatoria de 100 observaciones con una media de 50 y una desviación estándar de 10.\nLuego, calculamos la media muestral, que es una estimación puntual de la media poblacional. Esto se hace con la función mean() en R.\n\n\nRPython\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEn este código: - Generamos una muestra aleatoria de 100 observaciones con una media de 50 y una desviación estándar de 10. - Calculamos la media muestral, que es una estimación puntual de la media poblacional.\nIntervalo de Confianza para la Media\n\nUtilizamos una prueba t para calcular el intervalo de confianza para la media de los datos con un nivel de confianza del 95%. El intervalo se obtiene con la función t.test() en R y luego se extrae el intervalo de confianza con la función $conf.int.\n\n\nRPython\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEn este código: - Utilizamos una prueba t para calcular el intervalo de confianza para la media de los datos con un nivel de confianza del 95%. - El resultado intervalo_confianza nos proporciona el rango dentro del cual se espera que esté la media poblacional con un 95% de confianza.\n\n\n\n\n\n\nTip\n\n\n\nEn las próximas lecciones, vamos a calcular y visualizar los estimadores puntuales y de intervalos de manera directa con las librerías ggpubr y ggplot2 en R.\n\n\n\n\nResumen hasta ahora\n\nLa estimación es una parte fundamental de la inferencia estadística y nos permite hacer afirmaciones sobre parámetros poblacionales a partir de muestras.\nExisten dos tipos principales de estimación: la estimación puntual, que nos da un único valor como mejor estimación del parámetro, y la estimación por intervalo, que proporciona un rango de valores dentro del cual es probable que se encuentre el parámetro verdadero, acompañado de una medida de incertidumbre.\nVamos a ver ahora el Error Estándar de la Media, la cuál es una medida de la variabilidad en la media muestral que se utiliza mucho en los análisis estadísticos."
  },
  {
    "objectID": "docs/70-a-estimacion-inferencia.html#error-estándar-de-la-media",
    "href": "docs/70-a-estimacion-inferencia.html#error-estándar-de-la-media",
    "title": "Estimación e Inferencia Estadística",
    "section": "Error estándar de la media",
    "text": "Error estándar de la media\n\nError estándar de la media muestral\nEl error estándar de la media nos informa sobre la variabilidad en la media muestral. En términos simples, cuantifica cuánto varía la media de una muestra al estimar la media poblacional. Se le llama “error” porque describe la incertidumbre o el error que cometemos al utilizar la media muestral (\\((\\bar{y}\\))) para estimar el verdadero valor de la media poblacional (\\((\\mu\\))).\nEl error estándar de la media se calcula como:\n\\[ \\text{Error estándar} = \\frac{s}{\\sqrt{n}} \\]\nDonde:\n\n\\(s\\) es la desviación estándar de la muestra.\n\\(n\\) es el tamaño de la muestra.\n\n\n\n\n\n\n\nImportant\n\n\n\nEl error estándar nos da una idea de cómo cambiarían las medias muestrales si repitiéramos el proceso de muestreo varias veces. Si el error estándar es grande, las medias de las diferentes muestras variarán mucho entre sí, lo que sugiere que es menos probable que una media muestral individual esté cerca de la verdadera media poblacional. Por otro lado, si el error estándar es pequeño, las medias muestrales serán más consistentes entre sí, lo que nos da más confianza en que la media muestral es una buena estimación de la media poblacional.\nSi observas la fórmula para calcular el Error Estándar, verás que es inversamente proporcional a la raíz cuadrada del tamaño de la muestra. Esto significa que, a medida que aumenta el tamaño de la muestra, el error estándar disminuye, lo que indica que las medias muestrales son más consistentes y se acercan más a la media poblacional.\n\n\n\nGraficar el Error Estándar en R\n\nRPython\n\n\n\nPara visualizar el error estándar, podemos usar gráficos que muestren la media y el error estándar para diferentes grupos o condiciones.\nEsto nos permite comparar visualmente las medias y la incertidumbre asociada con cada una.\nLa forma más fácil de hacer esto, es con el paquete ggpubr.\nVamos a usar los datos ToothGrowth de R, que contienen la longitud de los dientes de conejos tratados con diferentes dosis de vitamina C.\n\n\n\n\n\n\n\n\n\n\nPrimero, grafiquemos SOLO la media de len (longitud de los dientes) para cada dosis de vitamina C (dose).\nEspecificamos el tipo de gráfico con ggline() y agregamos la media y un gráfico de dispersión (datos individuales) con add = c(\"mean\", \"jitter\").\n\n\n\n\n\n\n\n\n\n\nAhora, agreguemos el error estándar a la gráfica anterior.\nObserva que simplementre usamos mean_se en lugar de mean para agregar la media y el error estándar de la media a la gráfica.\n\n\n\n\n\n\n\n\n\n\nAhora, si especificamos algún color para agrupar los datos por supp (tipo de suplemento), podemos ver cómo cambia la longitud de los dientes con diferentes dosis de vitamina C y tipos de suplemento.\n\n\n\n\n\n\n\n\n\n\nSi quisieramos un gráfico de barras, escribiríamos el siguiente código.\nObserva que usamos ggbarplot() en lugar de ggline() para crear un gráfico de barras.\nEl argumento position = position_dodge(0.8) se utiliza para separar las barras de diferentes grupos.\n\n\n\n\n\n\n\n\n\n\n\nGraficar el Error Estándar en Python Para visualizar el error estándar en Python, podemos usar seaborn y matplotlib, que ofrecen una gran flexibilidad para crear gráficos estadísticos. Usaremos el mismo conjunto de datos ToothGrowth.\nPrimero, necesitamos cargar los datos en un DataFrame de pandas.\n\n\n\n\n\n\n\n\n\nGráfico de Líneas con Media y Puntos Individuales Este es el equivalente al primer gráfico de ggline que muestra la media y los puntos dispersos (jitter).\n\n\n\n\n\n\n\n\n\n\nGráfico de Líneas con Error Estándar Ahora, agregamos las barras de error estándar. seaborn puede calcular y mostrar un intervalo de confianza (por defecto al 95%), que está directamente relacionado con el error estándar. Para mostrar específicamente el error estándar, podemos calcularlo y añadirlo con plt.errorbar.\n\n\n\n\n\n\n\n\n\n\nGráfico de Líneas Agrupado por Suplemento Este es el equivalente al gráfico de ggline que agrupa los datos por el tipo de suplemento (supp).\n\n\n\n\n\n\n\n\n\n\nGráfico de Barras Agrupado con Error Estándar Finalmente, aquí está el equivalente al ggbarplot. Usamos sns.barplot que automáticamente calcula y muestra la media y el intervalo de confianza.\n\n\n\n\n\n\n\n\n\nComo puedes ver, seaborn ofrece una sintaxis muy directa y declarativa para crear gráficos estadísticos complejos, similar a ggplot2 y ggpubr en R.\n\n\n\n\n\n\nIntervalos de confianza para la media poblacional\nUn intervalo de confianza es una estimación por intervalo que proporciona un rango de valores que probablemente contengan el parámetro poblacional, en este caso, la media poblacional (\\(\\mu\\)).\n\n\n\n\n\n\nNote\n\n\n\nLa interpretación más común de un intervalo de confianza del 95% es que, si realizáramos el muestreo y el cálculo del intervalo muchas veces, el 95% de los intervalos generados contendrían el verdadero valor de la media poblacional.\n\n\nEs crucial entender que un intervalo de confianza no es una declaración probabilística sobre la media poblacional. El parámetro poblacional \\(\\mu\\) es fijo pero desconocido, por lo que el intervalo de confianza no dice que hay un 95% de probabilidad de que \\(\\mu\\) esté dentro del intervalo calculado. En su lugar, lo que este intervalo refleja es que el proceso utilizado para calcularlo generará intervalos que contienen \\(\\mu\\) el 95% de las veces si repitiéramos el procedimiento de muestreo muchas veces con muestras diferentes.\nComo resumen, Antelman (1997) describe un intervalo de confianza como “un intervalo generado por un procedimiento que proporciona intervalos correctos el 95% del tiempo”.\n\ngráficos de intervalo de confianza en R\n\nTambién podemos visualizar los intervalos de confianza en un gráfico para comparar las medias y la incertidumbre asociada.\nUsaremos los mismos datos ToothGrowth de R para este ejemplo.\nCon el paquete ggpubr, podemos usar ggerrorplot() para crear gráficos de intervalo de confianza."
  },
  {
    "objectID": "docs/70-a-estimacion-inferencia.html#grados-de-libertad-df",
    "href": "docs/70-a-estimacion-inferencia.html#grados-de-libertad-df",
    "title": "Estimación e Inferencia Estadística",
    "section": "Grados de libertad (df)",
    "text": "Grados de libertad (df)\nEl concepto de grados de libertad es fundamental en muchas pruebas estadísticas, pero a menudo se malinterpreta. En términos simples, los grados de libertad se refieren al número de observaciones en una muestra que son libres de variar cuando se estima un parámetro. Por ejemplo, si ya conocemos la media muestral, entonces solo \\(n-1\\) observaciones pueden variar libremente, ya que la última observación está determinada por la media y las demás observaciones.\nEn general, los grados de libertad se calculan como:\n\\[ \\text{df} = n - p \\]\nDonde: - \\(n\\) es el número de observaciones. - \\(p\\) es el número de parámetros estimados.\nPor ejemplo, cuando estimamos la varianza muestral, ya hemos calculado la media, por lo que solo \\(n-1\\) observaciones son libres de variar.\nEjemplo Práctico:\nSi tienes una muestra de 5 números y conoces la suma total de ellos, solo 4 de esos números pueden ser elegidos libremente. El quinto número está fijado por la necesidad de que la suma total se mantenga constante. Por lo tanto, en este caso, hay 4 grados de libertad.\n\nPrimero, calcula la media de la muestra: \\((10 + 12 + 15 + 13 + 14) / 5 = 12.8\\).\n\n\nRPython\n\n\n\n\n\n\n\n\n\n\nAhora vamos a calcular la Varianza\n\nPara calcular la varianza de la muestra, normalmente restamos la media de cada observación, elevamos al cuadrado esos valores, sumamos esos cuadrados, y luego dividimos por el número de observaciones menos 1 (n - 1), que son los grados de libertad.\n¿Por qué n - 1? Porque estamos utilizando la media de la muestra en lugar de la media verdadera de la población, lo que introduce un sesgo. Dividir por n - 1 corrige este sesgo, haciendo que la varianza calculada sea un estimador imparcial de la varianza poblacional.\n\n\n\n\n\n\n\n\n\nConsidera que si ya conoces la media de la muestra, solo 4 de los valores originales pueden variar libremente. El quinto valor está determinado por la necesidad de que la suma total de los valores sea consistente con la media calculada. Esto es lo que se refleja al usar n - 1 en el cálculo de la varianza.\n\nPor lo general, las funciones de R calculan los grados de libertad automáticamente, por lo que no es necesario hacerlo manualmente. Sin embargo, es útil comprender el concepto de grados de libertad y por qué se utilizan en las pruebas estadísticas. Por ejemplo: - La función var() de R automáticamente utiliza n - 1 como el divisor, lo que refleja el uso de los grados de libertad en el cálculo de la varianza muestral.\n\n\n\n\n\n\n\n\n\n\n\nEl concepto de grados de libertad es idéntico. Si tienes una muestra de 5 números y conoces su media, solo 4 de ellos pueden variar libremente.\nPrimero, calculamos la media de la muestra.\n\n\n\n\n\n\n\n\nAhora, calculamos la varianza muestral. En Python, al igual que en R, restamos la media de cada observación, elevamos al cuadrado, sumamos los resultados y dividimos por n-1 (los grados de libertad).\n\n\n\n\n\n\n\n\nLa razón para dividir entre n-1 es la misma: estamos usando la media de la muestra como una estimación de la media poblacional, y esto corrige el sesgo, dándonos un estimador insesgado de la varianza poblacional.\n\nDe forma similar a la función var() de R, NumPy tiene la función np.var() para calcular la varianza. Sin embargo, es muy importante saber que, por defecto, np.var() calcula la varianza poblacional (divide entre n).\n\nPara calcular la varianza muestral (dividiendo entre n-1), debes especificar el argumento ddof=1 (Delta Degrees of Freedom).\n\n\n\n\n\n\n\n\nComo puedes ver, el resultado de np.var(muestra, ddof=1) es idéntico al cálculo manual, y es el equivalente directo de la función var() de R."
  },
  {
    "objectID": "docs/62-lineales-resumen.html",
    "href": "docs/62-lineales-resumen.html",
    "title": "Resumen y reflexiones de los modelos lineales",
    "section": "",
    "text": "En este pesado módulo, revisamos los modelos lineales como una herramienta central para el análisis de datos.\nEspero haber logrado mi objetivo principal: que los estudiantes comprendan cómo estos modelos pueden aplicarse a una amplia variedad de datos, desde correlaciones hasta ANOVAs.\n\n\n\n\n\nEste es uno de los puntos más importantes del curso y la estadística en general, ya que establece la base para todo lo que sigue: pruebas de hipótesis, tests estadísticos, p-values…\nTodo se reduce (o se basa) en la ecuación de la línea recta \\((y = a \\cdot x + b\\)), las pendientes y los interceptos.\nComprobamos cómo los modelos lineales expresan relaciones entre variables.\nAbordamos la idea de transformar datos no paramétricos mediante rangos.\nSupuestos que revisamos: normalidad de los residuos, y homocedasticidad.\n\n\n\n\n\nLos modelos lineales se simplifican cuando contamos con una o dos medias.\n\nUna media: Cuando solo hay un valor de \\((x\\)), el modelo de regresión se simplifica a \\((y = b\\)), lo que es equivalente a una prueba t de una muestra. Si los datos no son métricos, pueden transformarse en rangos, lo que lleva a la prueba de rango con signo de Wilcoxon.\nDos medias: Si tenemos dos grupos, podemos modelar la diferencia entre las medias como una pendiente. Esto se relaciona directamente con la prueba t de dos muestras independientes y su versión no paramétrica, el test de Mann-Whitney U.\nMuestras pareadas: Introducción a la prueba t para muestras pareadas y la prueba de Wilcoxon pareada.\n\n\n\n\n\nLos modelos lineales se pueden extender a más de dos grupos, introduciendo el análisis de varianza (ANOVA).\n\nCodificación dummy: Mostrar cómo los coeficientes de regresión pueden representar categorías mediante la codificación dummy.\nANOVA de una vía: Introducir el ANOVA de una vía como una extensión de la regresión para tres o más medias.\nANOVA de dos vías: Extender el ANOVA para incluir más de un factor categórico, presentando el ANOVA de dos vías.\n\n\n\n\n\nEl curso seguirá con los temas de pruebas de hipótesis y cómo estas son esencialmente comparaciones de modelos lineales. En este módulo, vimos un poco de esto con las pruebas t, donde vimos:\n\nLas pruebas de hipótesis son equivalentes a comparar un modelo completo con uno donde un parámetro está fijo (generalmente en cero).\n\nInferencia estadística:\n\nVeremos en detalle cómo hacer inferencias, donde se utilizan los valores-p para determinar la significancia de los resultados."
  },
  {
    "objectID": "docs/62-lineales-resumen.html#resumen-de-modelos-lineales",
    "href": "docs/62-lineales-resumen.html#resumen-de-modelos-lineales",
    "title": "Resumen y reflexiones de los modelos lineales",
    "section": "",
    "text": "En este pesado módulo, revisamos los modelos lineales como una herramienta central para el análisis de datos.\nEspero haber logrado mi objetivo principal: que los estudiantes comprendan cómo estos modelos pueden aplicarse a una amplia variedad de datos, desde correlaciones hasta ANOVAs.\n\n\n\n\n\nEste es uno de los puntos más importantes del curso y la estadística en general, ya que establece la base para todo lo que sigue: pruebas de hipótesis, tests estadísticos, p-values…\nTodo se reduce (o se basa) en la ecuación de la línea recta \\((y = a \\cdot x + b\\)), las pendientes y los interceptos.\nComprobamos cómo los modelos lineales expresan relaciones entre variables.\nAbordamos la idea de transformar datos no paramétricos mediante rangos.\nSupuestos que revisamos: normalidad de los residuos, y homocedasticidad.\n\n\n\n\n\nLos modelos lineales se simplifican cuando contamos con una o dos medias.\n\nUna media: Cuando solo hay un valor de \\((x\\)), el modelo de regresión se simplifica a \\((y = b\\)), lo que es equivalente a una prueba t de una muestra. Si los datos no son métricos, pueden transformarse en rangos, lo que lleva a la prueba de rango con signo de Wilcoxon.\nDos medias: Si tenemos dos grupos, podemos modelar la diferencia entre las medias como una pendiente. Esto se relaciona directamente con la prueba t de dos muestras independientes y su versión no paramétrica, el test de Mann-Whitney U.\nMuestras pareadas: Introducción a la prueba t para muestras pareadas y la prueba de Wilcoxon pareada.\n\n\n\n\n\nLos modelos lineales se pueden extender a más de dos grupos, introduciendo el análisis de varianza (ANOVA).\n\nCodificación dummy: Mostrar cómo los coeficientes de regresión pueden representar categorías mediante la codificación dummy.\nANOVA de una vía: Introducir el ANOVA de una vía como una extensión de la regresión para tres o más medias.\nANOVA de dos vías: Extender el ANOVA para incluir más de un factor categórico, presentando el ANOVA de dos vías.\n\n\n\n\n\nEl curso seguirá con los temas de pruebas de hipótesis y cómo estas son esencialmente comparaciones de modelos lineales. En este módulo, vimos un poco de esto con las pruebas t, donde vimos:\n\nLas pruebas de hipótesis son equivalentes a comparar un modelo completo con uno donde un parámetro está fijo (generalmente en cero).\n\nInferencia estadística:\n\nVeremos en detalle cómo hacer inferencias, donde se utilizan los valores-p para determinar la significancia de los resultados."
  },
  {
    "objectID": "docs/76-anova-dosvias-python.html",
    "href": "docs/76-anova-dosvias-python.html",
    "title": "ANOVA de dos vías en Python",
    "section": "",
    "text": "La prueba de ANOVA de dos vías se utiliza para evaluar simultáneamente el efecto de dos variables categóricas (factores) sobre una variable de respuesta continua.\nLos factores son las variables de agrupamiento. Las diferentes categorías dentro de un factor se denominan niveles. Las combinaciones de niveles de los factores se llaman celdas.\nPor ejemplo, en un experimento que estudia el crecimiento de los dientes en cobayas, podríamos tener dos factores: 1. Tipo de Suplemento: con los niveles “Jugo de Naranja” (OJ) y “Vitamina C” (VC). 2. Dosis: con los niveles 0.5, 1.0 y 2.0 mg/día.\nLa variable de respuesta sería la longitud del diente.\n\n\n\nDiseño balanceado: Cuando los tamaños de muestra dentro de todas las celdas son iguales. En este caso, se puede aplicar el test ANOVA estándar de dos vías.\nDiseño no balanceado: Cuando los tamaños de muestra son diferentes entre las celdas. Este caso requiere ajustes en el cálculo del ANOVA (diferentes tipos de Suma de Cuadrados)."
  },
  {
    "objectID": "docs/76-anova-dosvias-python.html#qué-es-el-test-anova-de-dos-vías",
    "href": "docs/76-anova-dosvias-python.html#qué-es-el-test-anova-de-dos-vías",
    "title": "ANOVA de dos vías en Python",
    "section": "",
    "text": "La prueba de ANOVA de dos vías se utiliza para evaluar simultáneamente el efecto de dos variables categóricas (factores) sobre una variable de respuesta continua.\nLos factores son las variables de agrupamiento. Las diferentes categorías dentro de un factor se denominan niveles. Las combinaciones de niveles de los factores se llaman celdas.\nPor ejemplo, en un experimento que estudia el crecimiento de los dientes en cobayas, podríamos tener dos factores: 1. Tipo de Suplemento: con los niveles “Jugo de Naranja” (OJ) y “Vitamina C” (VC). 2. Dosis: con los niveles 0.5, 1.0 y 2.0 mg/día.\nLa variable de respuesta sería la longitud del diente.\n\n\n\nDiseño balanceado: Cuando los tamaños de muestra dentro de todas las celdas son iguales. En este caso, se puede aplicar el test ANOVA estándar de dos vías.\nDiseño no balanceado: Cuando los tamaños de muestra son diferentes entre las celdas. Este caso requiere ajustes en el cálculo del ANOVA (diferentes tipos de Suma de Cuadrados)."
  },
  {
    "objectID": "docs/76-anova-dosvias-python.html#hipótesis-en-el-anova-de-dos-vías",
    "href": "docs/76-anova-dosvias-python.html#hipótesis-en-el-anova-de-dos-vías",
    "title": "ANOVA de dos vías en Python",
    "section": "Hipótesis en el ANOVA de dos vías",
    "text": "Hipótesis en el ANOVA de dos vías\nEn un ANOVA de dos vías, se prueban tres hipótesis nulas:\n\nEfecto principal del Factor A: No hay diferencia en las medias de la variable de respuesta entre los niveles del Factor A.\nEfecto principal del Factor B: No hay diferencia en las medias de la variable de respuesta entre los niveles del Factor B.\nEfecto de interacción (A x B): No hay interacción entre los factores A y B. Esto significa que el efecto de un factor no depende del nivel del otro factor.\n\nLa hipótesis alternativa para cada caso es que sí hay una diferencia o una interacción."
  },
  {
    "objectID": "docs/76-anova-dosvias-python.html#qué-son-las-interacciones",
    "href": "docs/76-anova-dosvias-python.html#qué-son-las-interacciones",
    "title": "ANOVA de dos vías en Python",
    "section": "¿Qué son las interacciones?",
    "text": "¿Qué son las interacciones?\nUna interacción ocurre cuando el efecto de un factor sobre la variable de respuesta depende del nivel de otro factor. Los efectos de los factores no son simplemente aditivos.\nPor ejemplo, si el efecto de la dosis de vitamina C en el crecimiento de los dientes es diferente para el jugo de naranja en comparación con la vitamina C pura, entonces existe una interacción.\nDetectar interacciones es crucial porque revela relaciones complejas que no serían evidentes si solo se examinaran los efectos principales. Ignorar una interacción significativa puede llevar a conclusiones incorrectas."
  },
  {
    "objectID": "docs/76-anova-dosvias-python.html#ejemplo-en-python",
    "href": "docs/76-anova-dosvias-python.html#ejemplo-en-python",
    "title": "ANOVA de dos vías en Python",
    "section": "Ejemplo en Python",
    "text": "Ejemplo en Python\nVamos a realizar un ANOVA de dos vías usando el conjunto de datos ToothGrowth que viene con R y que podemos cargar fácilmente.\n\n1. Cargar librerías y datos\nPrimero, instalamos las librerías necesarias si no las tenemos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2. Visualización de los datos\nUn gráfico de cajas o de puntos es útil para visualizar las medias y las posibles interacciones.\n\n\n\n\n\n\n\n\nUn gráfico de interacción puede mostrar más claramente si las líneas que conectan las medias son paralelas (sin interacción) o si se cruzan/divergen (con interacción).\n\n\n\n\n\n\n\n\nEn el gráfico de interacción, las líneas no son paralelas, lo que sugiere una posible interacción entre la dosis y el tipo de suplemento.\n\n\n3. Realizar el ANOVA de dos vías\nUsaremos la librería statsmodels para ajustar el modelo ANOVA. La fórmula len ~ C(supp) * C(dose) especifica que queremos analizar la longitud (len) en función de los efectos principales de supp y dose, así como su interacción (*). C() se usa para tratar las variables como categóricas.\n\n\n\n\n\n\n\n\n\n\n4. Interpretación de los resultados\nLa tabla ANOVA nos muestra los resultados para cada factor y la interacción:\n\nC(supp) (Tipo de suplemento): El valor p es muy bajo (&lt; 0.001), lo que indica que hay una diferencia significativa en la longitud del diente entre los suplementos de jugo de naranja y vitamina C.\nC(dose) (Dosis): El valor p es extremadamente bajo (&lt; 0.001), lo que significa que la dosis tiene un efecto muy significativo en la longitud del diente.\nC(supp):C(dose) (Interacción): El valor p (0.02186) es menor que 0.05, lo que sugiere que hay una interacción estadísticamente significativa entre el tipo de suplemento y la dosis.\n\nConclusión: Dado que la interacción es significativa, no debemos interpretar los efectos principales de forma aislada. El efecto de la dosis en el crecimiento de los dientes depende del tipo de suplemento utilizado. Por ejemplo, observando el gráfico, parece que a dosis bajas (0.5 y 1.0), el jugo de naranja (OJ) es más efectivo que la vitamina C (VC), pero a la dosis más alta (2.0), la diferencia es menor.\n\n\n5. Pruebas Post-Hoc (si es necesario)\nCuando hay una interacción significativa, las pruebas post-hoc pueden ayudar a entender las diferencias específicas. Podemos usar la prueba de Tukey HSD con la librería statsmodels.\n\n\n\n\n\n\n\n\nLa tabla de Tukey muestra las comparaciones por pares entre todos los grupos. Por ejemplo, podemos ver que la diferencia entre OJ-0.5 y VC-0.5 es significativa (p-adj &lt; 0.05, reject=True), lo que confirma que a la dosis de 0.5, el jugo de naranja es más efectivo."
  },
  {
    "objectID": "docs/85-kruskal-wallis-python.html",
    "href": "docs/85-kruskal-wallis-python.html",
    "title": "Test de Kruskal-Wallis en Python",
    "section": "",
    "text": "El test de Kruskal-Wallis es una prueba no paramétrica utilizada para determinar si hay diferencias significativas entre tres o más grupos en una variable continua. Es la alternativa no paramétrica al ANOVA de una vía cuando:\n\nLos datos no siguen una distribución normal\nLas varianzas no son homogéneas entre grupos\nLos tamaños de muestra son pequeños\n\n\n\n\nNo asume normalidad: Funciona con distribuciones asimétricas\nBasado en rangos: Utiliza los rangos de los datos en lugar de los valores originales\nRobusto: Menos sensible a valores atípicos que el ANOVA"
  },
  {
    "objectID": "docs/85-kruskal-wallis-python.html#qué-es-el-test-de-kruskal-wallis",
    "href": "docs/85-kruskal-wallis-python.html#qué-es-el-test-de-kruskal-wallis",
    "title": "Test de Kruskal-Wallis en Python",
    "section": "",
    "text": "El test de Kruskal-Wallis es una prueba no paramétrica utilizada para determinar si hay diferencias significativas entre tres o más grupos en una variable continua. Es la alternativa no paramétrica al ANOVA de una vía cuando:\n\nLos datos no siguen una distribución normal\nLas varianzas no son homogéneas entre grupos\nLos tamaños de muestra son pequeños\n\n\n\n\nNo asume normalidad: Funciona con distribuciones asimétricas\nBasado en rangos: Utiliza los rangos de los datos en lugar de los valores originales\nRobusto: Menos sensible a valores atípicos que el ANOVA"
  },
  {
    "objectID": "docs/85-kruskal-wallis-python.html#hipótesis-del-test-de-kruskal-wallis",
    "href": "docs/85-kruskal-wallis-python.html#hipótesis-del-test-de-kruskal-wallis",
    "title": "Test de Kruskal-Wallis en Python",
    "section": "Hipótesis del Test de Kruskal-Wallis",
    "text": "Hipótesis del Test de Kruskal-Wallis\n\nH₀: Las medianas de todos los grupos son iguales\nH₁: Al menos una de las medianas es diferente\n\nNota: Técnicamente, el test compara las distribuciones de los rangos, pero comúnmente se interpreta en términos de medianas."
  },
  {
    "objectID": "docs/85-kruskal-wallis-python.html#ejemplo-práctico-crecimiento-dental-en-cobayas",
    "href": "docs/85-kruskal-wallis-python.html#ejemplo-práctico-crecimiento-dental-en-cobayas",
    "title": "Test de Kruskal-Wallis en Python",
    "section": "Ejemplo Práctico: Crecimiento Dental en Cobayas",
    "text": "Ejemplo Práctico: Crecimiento Dental en Cobayas\nUsaremos un conjunto de datos que evalúa el efecto de la vitamina C en el crecimiento dental en cobayas, con tres niveles de dosis: 0.5, 1.0 y 2.0 mg/día.\n\n1. Cargar librerías y datos\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2. Estadísticas Descriptivas\n\n\n\n\n\n\n\n\n\n\n3. Visualización de los Datos\n\n\n\n\n\n\n\n\n\n\n4. Verificación de Supuestos\nAntes de decidir entre ANOVA paramétrico y Kruskal-Wallis, verificaremos los supuestos:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5. Test de Kruskal-Wallis\n\n\n\n\n\n\n\n\n\n\n6. Comparaciones Post-Hoc\nSi el test de Kruskal-Wallis es significativo, realizamos comparaciones por pares:\n\n\n\n\n\n\n\n\n\n\n7. Visualización de Resultados\n\n\n\n\n\n\n\n\n\n\n8. Comparación con ANOVA Paramétrico\nPara fines educativos, comparemos con ANOVA de una vía:\n\n\n\n\n\n\n\n\n\n\n9. Tamaño del Efecto"
  },
  {
    "objectID": "docs/85-kruskal-wallis-python.html#cuándo-usar-kruskal-wallis-vs-anova",
    "href": "docs/85-kruskal-wallis-python.html#cuándo-usar-kruskal-wallis-vs-anova",
    "title": "Test de Kruskal-Wallis en Python",
    "section": "Cuándo Usar Kruskal-Wallis vs ANOVA",
    "text": "Cuándo Usar Kruskal-Wallis vs ANOVA\nUsa Kruskal-Wallis cuando: - Los datos no siguen una distribución normal - Las varianzas no son homogéneas - Tienes datos ordinales - Hay valores atípicos extremos - Los tamaños de muestra son pequeños\nUsa ANOVA cuando: - Los datos siguen una distribución normal - Las varianzas son homogéneas - Quieres mayor poder estadístico - Los tamaños de muestra son grandes"
  },
  {
    "objectID": "docs/85-kruskal-wallis-python.html#resumen-de-la-metodología",
    "href": "docs/85-kruskal-wallis-python.html#resumen-de-la-metodología",
    "title": "Test de Kruskal-Wallis en Python",
    "section": "Resumen de la Metodología",
    "text": "Resumen de la Metodología\n\nExplorar los datos: Estadísticas descriptivas y visualización\nVerificar supuestos: Normalidad (Shapiro-Wilk) y homogeneidad (Levene)\nElegir el test: Kruskal-Wallis si se violan supuestos del ANOVA\nInterpretar resultados: Estadístico H y p-valor\nComparaciones post-hoc: Si el test principal es significativo\nEvaluar tamaño del efecto: Magnitud práctica de las diferencias"
  },
  {
    "objectID": "docs/42-ejercicios-evalintroII-python.html#antes-de-comenzar",
    "href": "docs/42-ejercicios-evalintroII-python.html#antes-de-comenzar",
    "title": "Ejercicio Práctico parte II - Estudio de Caso con Python",
    "section": "Antes de comenzar",
    "text": "Antes de comenzar\n\n¿Cuántos países hay en nuestros datos?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRespuesta\n\n\n\n\n\noms_limpio['pais'].nunique()\n\n\n\n\nComo ves, son muchos países. Para facilitar el análisis, vamos a filtrar para trabajar solo con algunos países: “Mexico”, “Canada”, “Bolivia”, “Guatemala”, “United States of America”."
  },
  {
    "objectID": "docs/42-ejercicios-evalintroII-python.html#exploración-de-datos",
    "href": "docs/42-ejercicios-evalintroII-python.html#exploración-de-datos",
    "title": "Ejercicio Práctico parte II - Estudio de Caso con Python",
    "section": "Exploración de datos",
    "text": "Exploración de datos\n\nVamos a filtrar y graficar los datos de los países seleccionados.\nNos interesa ver la tendencia de los casos de tuberculosis a través de los años.\n¿Cómo podemos ver tendencias en los datos? ¿Qué tipo de gráfico nos permitiría ver esto?\nSugerencia:\n\nPodríamos usar un gráfico de líneas (lineplot) para ver la tendencia de los casos de tuberculosis a través de los años. Es conveniente juntar el gráfico de líneas con un gráfico de puntos (scatterplot) para ver mejor la tendencia.\n¿Qué variables usarías en los ejes x y y? ¿Qué variable usarías para el hue (color)?\nSugerencia:\n\nEn el eje x, podrías poner el año.\nEn el eje y, podrías poner la cantidad de casos.\nPara el hue, podrías poner el país.\n\n\nNOTA: Para agilizar el análisis, vamos a encadenar los métodos: tomamos los datos limpios -&gt; filtramos los países -&gt; graficamos.\nVamos a ver el primer ejemplo juntos:\n\n\n\n\n\n\n\n\n\n\n¿Cuál es el problema con el gráfico anterior?\nComo ves, tenemos muchas observaciones por cada país y año. Esto hace que el gráfico sea difícil de interpretar.\n¿Qué podríamos hacer para solucionar esto?\nSugerencia:\n\nPodríamos agrupar los datos por país y año, y promediar los casos de tuberculosis (también podríamos sumar los casos con .sum(), ambos son válidos).\nDe esta manera, tendríamos una sola observación por país y año.\n\nCompleta el gráfico, agrupando los datos por país y año y promediando los casos de tuberculosis:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRespuesta\n\n\n\n\n\ndatos_agrupados = (\n    oms_limpio[oms_limpio['pais'].isin(paises_seleccionados)]\n    .groupby(['anio', 'pais'])['casos']\n    .mean()\n    .reset_index()\n)\n\nsns.lineplot(data=datos_agrupados, x='anio', y='casos', hue='pais')\nsns.scatterplot(data=datos_agrupados, x='anio', y='casos', hue='pais', legend=False)\nplt.ylabel(\"Promedio de Casos\")\nplt.show()\n\n\n\n\n¿Qué puedes observar en el gráfico?\nClaramente hay un país que tiene muchos más casos de tuberculosis que los demás. ¿Cuál es este país?\n\nRespuesta: Estados Unidos de América (United States of America).\n\nPor último, grafica el número total de casos de tuberculosis por país. ¿Qué tipo de gráfico usarías para esto?\nSugerencia:\n\nPodrías usar un gráfico de barras (barplot) para ver el número total de casos de tuberculosis por país.\nEn el eje x, podrías poner el país.\nEn el eje y, podrías poner el número total de casos. Estos casos los puedes obtener sumando los casos de tuberculosis en cada país.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRespuesta\n\n\n\n\n\ndatos_totales = (\n    oms_limpio[oms_limpio['pais'].isin(paises_seleccionados)]\n    .groupby('pais')\n    ['casos'].sum()\n    .reset_index()\n)\n\nsns.barplot(data=datos_totales, x='pais', y='casos')\nplt.xticks(rotation=45, ha='right')\nplt.ylabel(\"Total de Casos\")\nplt.show()\n\n\n\n\nSigue siendo evidente que un país tiene muchos más casos de tuberculosis que los demás.\nSin embargo, esto puede deberse a muchas razones:\n\npoblación del país: a mayor población, esperamos mayor número de casos.\ncalidad de los servicios de salud: a mejor calidad de los servicios de salud, esperamos menor número de casos.\nla calidad de los datos: es posible que un país tenga un mayor registro de datos que otro. En este caso, podríamos tener un sesgo en los datos.\nentre otras razones.\n\nEn lo que queda del curso, vamos a ver cómo podemos responder a estas preguntas y cómo podemos hacer inferencias sobre nuestros datos.\nEn las siguientes lecciones, veremos cómo podemos hacer pruebas de hipótesis para responder preguntas como: ¿hay una diferencia significativa en el número de casos de tuberculosis entre hombres y mujeres?, ¿hay una diferencia significativa en el número de casos de tuberculosis entre países? Este tipo de preguntas son muy comunes en la investigación científica y en la toma de decisiones basada en datos.\nPor ahora, sigue practicando con tus datos y familiarizándote con las funciones de pandas y seaborn. Trata de tomar datos de diferentes fuentes (preferentemente de tu tesis o trabajo) y practica lo que has aprendido en este curso: limpia tus datos, explóralos y visualízalos."
  },
  {
    "objectID": "docs/42-ejercicios-evalintroII-python.html#extra---gráfico-interactivo",
    "href": "docs/42-ejercicios-evalintroII-python.html#extra---gráfico-interactivo",
    "title": "Ejercicio Práctico parte II - Estudio de Caso con Python",
    "section": "Extra - Gráfico Interactivo",
    "text": "Extra - Gráfico Interactivo"
  },
  {
    "objectID": "docs/26.1-ejercicios-visualizacion-python.html",
    "href": "docs/26.1-ejercicios-visualizacion-python.html",
    "title": "Ejercicios y Buenas Prácticas de Visualización en Python",
    "section": "",
    "text": "Simula 1000 datos de una distribución normal con media 60 y desviación estándar 8.\nGrafica el histograma y personaliza el color y el número de bins."
  },
  {
    "objectID": "docs/26.1-ejercicios-visualizacion-python.html#ejercicio-1-histograma-de-datos-simulados",
    "href": "docs/26.1-ejercicios-visualizacion-python.html#ejercicio-1-histograma-de-datos-simulados",
    "title": "Ejercicios y Buenas Prácticas de Visualización en Python",
    "section": "",
    "text": "Simula 1000 datos de una distribución normal con media 60 y desviación estándar 8.\nGrafica el histograma y personaliza el color y el número de bins."
  },
  {
    "objectID": "docs/26.1-ejercicios-visualizacion-python.html#ejercicio-2-comparación-de-grupos",
    "href": "docs/26.1-ejercicios-visualizacion-python.html#ejercicio-2-comparación-de-grupos",
    "title": "Ejercicios y Buenas Prácticas de Visualización en Python",
    "section": "Ejercicio 2: Comparación de grupos",
    "text": "Ejercicio 2: Comparación de grupos\n\nSimula dos grupos de datos (n=50 cada uno) con medias y desviaciones estándar diferentes.\nGrafica ambos grupos en un solo histograma, usando diferentes colores."
  },
  {
    "objectID": "docs/26.1-ejercicios-visualizacion-python.html#buenas-prácticas-para-visualización-en-python",
    "href": "docs/26.1-ejercicios-visualizacion-python.html#buenas-prácticas-para-visualización-en-python",
    "title": "Ejercicios y Buenas Prácticas de Visualización en Python",
    "section": "Buenas prácticas para visualización en Python",
    "text": "Buenas prácticas para visualización en Python\n\nUsa títulos y etiquetas claras y descriptivas.\nElige paletas de colores accesibles y consistentes.\nUsa plt.tight_layout() para mejorar la presentación.\nGuarda tus gráficos con alta resolución (dpi=300) para presentaciones o publicaciones.\nSiempre revisa que los ejes y leyendas sean legibles y no se sobrepongan."
  },
  {
    "objectID": "docs/26.1-ejercicios-visualizacion-python.html#reflexión",
    "href": "docs/26.1-ejercicios-visualizacion-python.html#reflexión",
    "title": "Ejercicios y Buenas Prácticas de Visualización en Python",
    "section": "Reflexión",
    "text": "Reflexión\n\n¿Qué aprendiste sobre la importancia de la personalización en la visualización?\n¿Cómo puedes aplicar estas prácticas en tus propios proyectos?\n\nEstas recomendaciones te ayudarán a crear visualizaciones más efectivas y profesionales en Python."
  },
  {
    "objectID": "docs/24-histogramas-ggplot.html#introducción-y-objetivos",
    "href": "docs/24-histogramas-ggplot.html#introducción-y-objetivos",
    "title": "Graficar Distribuciones de Probabilidad",
    "section": "Introducción y Objetivos",
    "text": "Introducción y Objetivos\n\nAntes de seguir con el tema de distribuciones de probabilidad, vamos a aprender a graficar en R.\nEn esta lección, aprenderemos a graficar distribuciones de probabilidad en R con el paquete ggplot2, el cual es parte del tidyverse.\nComenzaremos graficando un histograma, que es una forma común de visualizar la distribución de una variable continua.\nAl ser parte del tidyverse, ggplot2 sigue una estructura lógica y consistente que facilita la creación de gráficos complejos."
  },
  {
    "objectID": "docs/24-histogramas-ggplot.html#antes-de-empezar",
    "href": "docs/24-histogramas-ggplot.html#antes-de-empezar",
    "title": "Graficar Distribuciones de Probabilidad",
    "section": "Antes de Empezar",
    "text": "Antes de Empezar\n\nPrimero tenemos que instalar y cargar el paquete ggplot2. Si no lo tienes instalado, puedes hacerlo con el siguiente comando: install.packages(\"ggplot2\").\nLuego, cargamos el paquete con library(ggplot2) o bien, puedes cargar todos los paquetes del tidyverse con library(tidyverse).\nA continuación, iremos paso por paso en la construcción del gráfico con ggplot. Una vez que entiendas esta base, verás que graficar cualquier tipo de gráfico en R es muy similar."
  },
  {
    "objectID": "docs/24-histogramas-ggplot.html#paso-1.-cargar-la-librería",
    "href": "docs/24-histogramas-ggplot.html#paso-1.-cargar-la-librería",
    "title": "Graficar Distribuciones de Probabilidad",
    "section": "Paso 1. Cargar la librería",
    "text": "Paso 1. Cargar la librería\n\nPrimero, tenemos que cargar el paquete ggplot2 con library(ggplot2).\nAhora, para decirle a R que queremos hacer un gráfico con ggplot2, usamos la función ggplot().\nCorre el siguiente código para crear un objeto ggplot vacío."
  },
  {
    "objectID": "docs/24-histogramas-ggplot.html#paso-2.-generar-datos",
    "href": "docs/24-histogramas-ggplot.html#paso-2.-generar-datos",
    "title": "Graficar Distribuciones de Probabilidad",
    "section": "Paso 2. Generar datos",
    "text": "Paso 2. Generar datos\n\nAhora, necesitamos decirle a ggplot qué datos queremos graficar y cómo queremos visualizarlos.\nPara este ejercicio, vamos a crear un dataset de ejemplo con 1000 datos que siguen una distribución normal.\nEsto es fácil en R con la función rnorm(), que genera datos aleatorios de una distribución normal. Esta función toma tres argumentos: el número de datos que queremos, la media y la desviación estándar. Recuerda que la media y la desviación estándar son parámetros que definen la distribución normal.\nEn la siguiente diapositiva se explica más a detalle el código que se muestra a continuación."
  },
  {
    "objectID": "docs/24-histogramas-ggplot.html#section",
    "href": "docs/24-histogramas-ggplot.html#section",
    "title": "Graficar Distribuciones de Probabilidad",
    "section": "",
    "text": "set.seed(42) fija la semilla para que los resultados sean reproducibles. Se utiliza para generar números aleatorios, pero de manera controlada para que siempre obtengamos los mismos resultados. El valor específico (42) es arbitrario, pero mientras sea el mismo, los resultados serán los mismos.\nrnorm(1000, mean = 50, sd = 10) genera 1000 datos de una distribución normal con media 50 y desviación estándar 10.\nhead() y tail() muestran los primeros y últimos datos, respectivamente.\nas.data.frame() convierte los datos en un dataframe, que es el formato que ggplot2 espera."
  },
  {
    "objectID": "docs/24-histogramas-ggplot.html#paso-3.-pasar-datos-a-ggplot",
    "href": "docs/24-histogramas-ggplot.html#paso-3.-pasar-datos-a-ggplot",
    "title": "Graficar Distribuciones de Probabilidad",
    "section": "Paso 3. Pasar datos a ggplot",
    "text": "Paso 3. Pasar datos a ggplot\n\nAhora que tenemos nuestros datos, vamos a crear un histograma con ggplot2.\nEmpezamos por decirle a ggplot() estos dos argumentos:\n\ndata: el dataset que queremos graficar.\naes(): las estéticas (aesthetics) del gráfico, como qué variable va en el eje x o y. Como estamos haciendo un histograma, solo necesitamos especificar la variable x.\n\nAhora, cuando corras el siguiente código, verás un gráfico vacío con el eje que especificamos.\nSin embargo, todavía no le hemos dicho a ggplot cómo queremos visualizar los datos. Eso lo haremos en el siguiente paso."
  },
  {
    "objectID": "docs/24-histogramas-ggplot.html#paso-4.-especificar-tipo-de-gráfico",
    "href": "docs/24-histogramas-ggplot.html#paso-4.-especificar-tipo-de-gráfico",
    "title": "Graficar Distribuciones de Probabilidad",
    "section": "Paso 4. Especificar tipo de gráfico",
    "text": "Paso 4. Especificar tipo de gráfico\n\nAhora que hemos especificado los datos y las estéticas, necesitamos agregar lo que se conoce como una capa geométrica (geom layer) al gráfico.\nEsta capa determina cómo se visualizan los datos (tipo de gráfico). Para un histograma, usamos geom_histogram().\nNota que agregamos esta nueva capa con el signo + al final de la línea anterior. Esto nos permite agregar múltiples capas al gráfico si es necesario, sumando capas una tras otra. Conceptualmente es similar a cómo funciona el operador pipa %&gt;%, pero específico de ggplot2.\nPuedes observar todos los tipos de capas geométricas que ggplot2 ofrece en la documentación oficial. No te preocupes, veremos más de ellas en futuras lecciones.\nPor el momento, solo necesitas saber que cada capa tiene parámetros específicos. Por ejemplo, para geom_histogram(), podemos especificar el número de bins (contenedores) que queremos en el histograma. Esto determina cuántas barras tendrá el gráfico."
  },
  {
    "objectID": "docs/24-histogramas-ggplot.html#pequeño-paréntesis",
    "href": "docs/24-histogramas-ggplot.html#pequeño-paréntesis",
    "title": "Graficar Distribuciones de Probabilidad",
    "section": "Pequeño paréntesis",
    "text": "Pequeño paréntesis\n\n¿Cómo afecta el número de contenedores (bins) al histograma?\nCambia el número de contenedores en el siguiente código y observa cómo se modifica el gráfico. Para esto, corre el código y mueve el control deslizante en la parte inferior para cambiar el número de contenedores.\nIdealmente, el número de contenedores debe ser suficiente para capturar la forma de la distribución, pero no demasiado para perder la información.\nObserva que pasa si el número de contenedores es muy bajo o muy alto.\n\n\n\n\n\n\n\n\n\n\nviewof n = Inputs.range([0, 501], {step: 1, label: \"contenedores\"})"
  },
  {
    "objectID": "docs/24-histogramas-ggplot.html#paso-5.-asignar-el-gráfico-a-un-objeto",
    "href": "docs/24-histogramas-ggplot.html#paso-5.-asignar-el-gráfico-a-un-objeto",
    "title": "Graficar Distribuciones de Probabilidad",
    "section": "Paso 5. Asignar el gráfico a un objeto",
    "text": "Paso 5. Asignar el gráfico a un objeto\n\nEs buena práctica guardar el gráfico en un objeto para poder modificarlo más adelante, combinarlo con otros gráficos, o guardarlo como un archivo.\nEsto también será útil cuando empezamos a crear gráficos más complejos con múltiples capas para que el código sea más legible.\nPara esto, simplemente asignamos el código del gráfico a un objeto, como se muestra a continuación."
  },
  {
    "objectID": "docs/24-histogramas-ggplot.html#section-1",
    "href": "docs/24-histogramas-ggplot.html#section-1",
    "title": "Graficar Distribuciones de Probabilidad",
    "section": "",
    "text": "Observa que ahora podemos llamar el objeto histograma_ggplot para mostrar el gráfico sin necesidad de volver a escribir todo el código."
  },
  {
    "objectID": "docs/24-histogramas-ggplot.html#paso-6.-personalizar-el-gráfico",
    "href": "docs/24-histogramas-ggplot.html#paso-6.-personalizar-el-gráfico",
    "title": "Graficar Distribuciones de Probabilidad",
    "section": "Paso 6. Personalizar el gráfico",
    "text": "Paso 6. Personalizar el gráfico\n\nFinalmente, podemos personalizar el gráfico agregando títulos, etiquetas, colores, etc.\nVamos a agregar un título al gráfico y etiquetas a los ejes x e y.\nPara esto, llamamos al objeto histograma_ggplot y agregamos la función labs() (labels o etiquetas) y especificamos el título y las etiquetas que queremos."
  },
  {
    "objectID": "docs/24-histogramas-ggplot.html#section-2",
    "href": "docs/24-histogramas-ggplot.html#section-2",
    "title": "Graficar Distribuciones de Probabilidad",
    "section": "",
    "text": "Vamos a regresar al ejemplo de las jirafas para entender cómo se aplican estos conceptos en la práctica.\nNuestro dataframe se llama alturas_df (ya está cargado en la diapositiva) y tiene las columnas altura en cm e isla con dos categorías (isla #1, isla #2)."
  },
  {
    "objectID": "docs/24-histogramas-ggplot.html#section-3",
    "href": "docs/24-histogramas-ggplot.html#section-3",
    "title": "Graficar Distribuciones de Probabilidad",
    "section": "",
    "text": "Siguiendo la estructura básica que ya conocemos, vamos a crear un histograma con los datos de las jirafas (alturas_df).\nQueremos ver cómo se distribuyen las alturas (altura) de las jirafas en las dos islas.\nNota que ahora usam binwidth = 1 en geom_histogram() para especificar el ancho de las barras del histograma. Puedes experimentar con diferentes valores para ver cómo cambia el gráfico. En la próxima diapositiva está la solución."
  },
  {
    "objectID": "docs/24-histogramas-ggplot.html#solución",
    "href": "docs/24-histogramas-ggplot.html#solución",
    "title": "Graficar Distribuciones de Probabilidad",
    "section": "solución",
    "text": "solución\nggplot(data = alturas_df, \n        aes(x = altura)) +\n  geom_histogram(binwidth = 1)"
  },
  {
    "objectID": "docs/24-histogramas-ggplot.html#section-4",
    "href": "docs/24-histogramas-ggplot.html#section-4",
    "title": "Graficar Distribuciones de Probabilidad",
    "section": "",
    "text": "El gráfico es un buen comienzo, pero podemos mejorarlo.\nVamos a decirle a ggplot que cada isla tenga un color diferente.\nPara esto, agregamos fill = isla dentro de aes().\nEsto le dice a ggplot que queremos que cada barra del histograma se llene con un color diferente según el tipo de isla, almacenado en la variable llamada “isla”."
  },
  {
    "objectID": "docs/24-histogramas-ggplot.html#nota",
    "href": "docs/24-histogramas-ggplot.html#nota",
    "title": "Graficar Distribuciones de Probabilidad",
    "section": "Nota",
    "text": "Nota\n\n\n\n\nfill = isla le dice a ggplot que queremos que cada barra del histograma se llene con un color diferente según el tipo de isla.\nNo confundir fill con color… fill se refiere al relleno de las barras, mientras que color se refiere al contorno de las barras.\nObserva la diferencia si cambias fill por color en el código."
  },
  {
    "objectID": "docs/24-histogramas-ggplot.html#section-5",
    "href": "docs/24-histogramas-ggplot.html#section-5",
    "title": "Graficar Distribuciones de Probabilidad",
    "section": "",
    "text": "Ahora, vamos a especificar colores específicos que queremos para cada isla en lugar de los colores predeterminados.\nPara esto, agregamos una capa adicional con + scale_fill_manual() al gráfico.\nDentro de esta función, especificamos los colores que queremos para cada isla de la siguiente manera: values = c(\"color1\", \"color2\").\n\nNota que estamos concatenando los colores con c(). Esto es importante para que R entienda que son dos colores diferentes. Ten en cuenta que debes proporcionar tantos colores como categorías tengas en tu gráfico, en este caso, dos.\nLos colores pueden ser especificados de distinas maneras. Puedes usar palabras como red, blue, green, yellow, black, white, entre otros. También puedes usar códigos hexadecimales como #FF0000 para rojo, #0000FF para azul, etc.\nConoce todos las palabras de colores que se pueden usar en este enlace y los códigos hexadecimales en este enlace."
  },
  {
    "objectID": "docs/24-histogramas-ggplot.html#section-6",
    "href": "docs/24-histogramas-ggplot.html#section-6",
    "title": "Graficar Distribuciones de Probabilidad",
    "section": "",
    "text": "Ahora, corre el siguiente código para ver el histograma con los colores que quieras. Sustituye los valores faltantes (marcados con ------) con los colores que prefieras."
  },
  {
    "objectID": "docs/24-histogramas-ggplot.html#tip",
    "href": "docs/24-histogramas-ggplot.html#tip",
    "title": "Graficar Distribuciones de Probabilidad",
    "section": "tip",
    "text": "tip\n\nUna forma facil de modificar la apariencia del gráfico es utilizando temas predefinidos.\nPuedes conocer los diferentes temas que ggplot2 ofrece en la documentación oficial.\nEn el siguiente código, comenta y descomenta las líneas para ver cómo cambia la apariencia del gráfico con los diferentes temas.\nNota: solamente puedes tener un tema activo a la vez. Si quieres cambiar el tema, comenta la línea del tema actual y descomenta la del nuevo tema."
  },
  {
    "objectID": "docs/24-histogramas-ggplot.html#section-7",
    "href": "docs/24-histogramas-ggplot.html#section-7",
    "title": "Graficar Distribuciones de Probabilidad",
    "section": "",
    "text": "Finalmente, podemos agregar títulos y etiquetas a nuestro gráfico para hacerlo más informativo.\nPara facilitar el trabajo con multiples capas, podemos guardar el gráfico en un objeto y luego agregar las capas adicionales."
  },
  {
    "objectID": "docs/24-histogramas-ggplot.html#section-8",
    "href": "docs/24-histogramas-ggplot.html#section-8",
    "title": "Graficar Distribuciones de Probabilidad",
    "section": "",
    "text": "Agregar títulos y etiquetas al gráfico. Reemplaza los guiónes bajos con los textos que prefieras.\nRecuerda que en un gráfico, los ejes x e y deben tener etiquetas descriptivas que indiquen qué variable están representando.\nNota que estamos utilizando el objeto p que creamos anteriormente. Seguimos agregando capas al gráfico con el operador + y lo seguimos guardando en el objeto p para futuras modificaciones.\nPara mostrar el gráfico, simplemente llamamos al objeto p o bien, puedes usar print(p).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExpande para ver el código completo\n\n\nUna forma de nombrar las etiquetas del gráfico podría ser la siguiente:\np &lt;- p +\n  labs(title = \"Distribución de Alturas de Jirafas\",\n       x = \"Altura (cm)\",\n       y = \"Frecuencia\")\n\np"
  },
  {
    "objectID": "docs/24-histogramas-ggplot.html#section-9",
    "href": "docs/24-histogramas-ggplot.html#section-9",
    "title": "Graficar Distribuciones de Probabilidad",
    "section": "",
    "text": "Ahora, quitemos el espacio en blanco alrededor del gráfico para hacerlo más limpio y movamos la leyenda a la parte superior. - NOTA: en lugar de usar legend.position = \"top\", también puedes usar los valores bottom, left, right, none."
  },
  {
    "objectID": "docs/24-histogramas-ggplot.html#section-10",
    "href": "docs/24-histogramas-ggplot.html#section-10",
    "title": "Graficar Distribuciones de Probabilidad",
    "section": "",
    "text": "Por último, podemos guardar el gráfico como un archivo de imagen para compartirlo o incrustarlo en un documento.\nPara esto, usamos la función ggsave(). Esta función toma varios argumentos: primero, el nombre del archivo que queremos guardar (por ejemplo, \"histograma_jirafas.png\"), luego el objeto del gráfico que queremos guardar (en este caso, p), y finalmente, el ancho, alto y resolución de la imagen (300 dpi es una resolución estándar para impresión).\nEn este caso no se va a guardar el archivo, pero si lo haces en tu computadora se salvaría en la carpeta de trabajo con el nombre que le diste.\n\nggsave(\"histograma_jirafas.png\", plot = p, width = 8, height = 6, dpi = 300)"
  },
  {
    "objectID": "docs/79-errores-tipo1.html",
    "href": "docs/79-errores-tipo1.html",
    "title": "Pruebas Múltiples y el Problema del Error Tipo I Acumulado",
    "section": "",
    "text": "Uno de los problemas más desafiantes en las pruebas de hipótesis estadísticas es el riesgo de acumulación de errores de decisión cuando se realizan múltiples pruebas al mismo tiempo. A medida que aumenta el número de pruebas, también lo hace la probabilidad de cometer al menos un error Tipo I (rechazar incorrectamente la hipótesis nula) entre el conjunto de pruebas. Este problema se conoce como la tasa de error Tipo I familiar (o tasa de error Tipo I en experimentos), y es importante abordarlo para evitar sacar conclusiones incorrectas a partir de los datos."
  },
  {
    "objectID": "docs/79-errores-tipo1.html#tasa-de-error-tipo-i-familiar",
    "href": "docs/79-errores-tipo1.html#tasa-de-error-tipo-i-familiar",
    "title": "Pruebas Múltiples y el Problema del Error Tipo I Acumulado",
    "section": "Tasa de Error Tipo I Familiar",
    "text": "Tasa de Error Tipo I Familiar\nLa tasa de error Tipo I familiar (también conocida como tasa de error Tipo I en experimentos) se refiere a la probabilidad de cometer al menos un error Tipo I en un conjunto de pruebas de hipótesis que se realizan simultáneamente. Este problema surge en situaciones como:\n\nComparaciones por pares de grupos de tratamiento en un experimento.\nPruebas de correlaciones entre múltiples variables.\nMúltiples análisis univariados (como pruebas t) en las mismas unidades experimentales.\n\nSi las pruebas son independientes (es decir, ortogonales), la tasa de error Tipo I familiar puede calcularse mediante la siguiente fórmula:\n\\[\n1 - (1 - \\alpha)^c\n\\]\nDonde: - \\[\\alpha\\] es el nivel de significancia para cada prueba individual. - \\(c\\) es el número de pruebas.\nPor ejemplo, si realizamos 10 pruebas con un nivel de significancia \\(\\alpha = 0.05\\), la probabilidad de cometer al menos un error Tipo I sería:\n\\[\n1 - (1 - 0.05)^{10} = 1 - 0.95^{10} = 0.401\n\\]\nEsto significa que hay un 40.1% de probabilidad de cometer al menos un error Tipo I en las 10 pruebas, lo cual es mucho mayor que el 5% esperado para cada prueba individual."
  },
  {
    "objectID": "docs/79-errores-tipo1.html#enfoques-para-controlar-el-error-tipo-i-en-pruebas-múltiples",
    "href": "docs/79-errores-tipo1.html#enfoques-para-controlar-el-error-tipo-i-en-pruebas-múltiples",
    "title": "Pruebas Múltiples y el Problema del Error Tipo I Acumulado",
    "section": "Enfoques para Controlar el Error Tipo I en Pruebas Múltiples",
    "text": "Enfoques para Controlar el Error Tipo I en Pruebas Múltiples\nExisten varios enfoques para controlar la tasa de error Tipo I familiar en situaciones de pruebas múltiples. Estos enfoques se basan en ajustar el nivel de significancia de cada prueba individual para mantener controlada la tasa de error global. Veamos algunos de los métodos más comunes:\n\n1. Procedimiento de Bonferroni\nEl procedimiento de Bonferroni es uno de los métodos más simples y ampliamente utilizados para ajustar el nivel de significancia en pruebas múltiples. La idea básica es dividir el nivel de significancia original (\\(\\alpha\\)) entre el número de pruebas (\\(c\\)) para obtener un nivel de significancia ajustado para cada prueba:\n\\[\n\\alpha_{\\text{ajustado}} = \\frac{\\alpha}{c}\n\\]\nPor ejemplo, si tenemos \\(\\alpha = 0.05\\) y realizamos 10 pruebas, el nivel de significancia ajustado sería:\n\\[\n\\alpha_{\\text{ajustado}} = \\frac{0.05}{10} = 0.005\n\\]\nEsto significa que cada prueba individual debe ser significativa a un nivel de \\(0.005\\) para que podamos rechazar la hipótesis nula, lo que reduce considerablemente la probabilidad de cometer un error Tipo I en el conjunto de pruebas.\nVentajas: - Es fácil de aplicar y tiene una gran flexibilidad, ya que puede usarse en cualquier situación con pruebas múltiples.\nDesventajas: - Es muy conservador, lo que significa que reduce mucho el poder de las pruebas individuales, especialmente cuando hay muchas pruebas. - Por lo tanto, puede ser demasiado restrictivo en algunos casos, lo que lleva a un alto riesgo de errores Tipo II (no detectar un efecto real). - Esto podría considerarse incluso más grave que cometer un error Tipo I en algunas situaciones. Por ejemplo, en la investigación médica, es más grave no detectar un tratamiento efectivo y nunca más probarlo que experimentar uno que no lo es y descartarlo luego.\n\n\n2. Procedimiento de Dunn-Sidak\nEl procedimiento de Dunn-Sidak es una modificación del procedimiento de Bonferroni que mejora ligeramente el poder de las pruebas. El nivel de significancia ajustado se calcula de la siguiente manera:\n\\[\n\\alpha_{\\text{ajustado}} = 1 - (1 - \\alpha)^{1/c}\n\\]\nPor ejemplo, si tenemos \\(\\alpha = 0.05\\) y realizamos 10 pruebas, el nivel de significancia ajustado sería:\n\\[\n\\alpha_{\\text{ajustado}} = 1 - (1 - 0.05)^{1/10} = 0.005116\n\\]\nEl ajuste es muy similar al de Bonferroni, pero ligeramente menos conservador, lo que mejora un poco el poder de las pruebas.\n\n\n3. Bonferroni Secuencial (Holm, 1979)\nEl procedimiento de Bonferroni secuencial, propuesto por Holm en 1979, es una mejora significativa respecto al Bonferroni estándar. En este procedimiento, los valores p de las pruebas se ordenan de menor a mayor, y luego se ajusta el nivel de significancia para cada prueba de la siguiente manera:\n\nLa prueba con el valor p más pequeño se compara con \\(\\alpha/c\\).\nLa segunda prueba se compara con \\(\\alpha/(c-1)\\), y así sucesivamente.\nSi encontramos una prueba no significativa, dejamos de probar y no rechazamos las hipótesis restantes.\n\nEste procedimiento tiene más poder que el Bonferroni estándar, ya que ajusta gradualmente el nivel de significancia en lugar de hacerlo uniformemente para todas las pruebas."
  },
  {
    "objectID": "docs/79-errores-tipo1.html#cuándo-usar-ajustes-para-pruebas-múltiples",
    "href": "docs/79-errores-tipo1.html#cuándo-usar-ajustes-para-pruebas-múltiples",
    "title": "Pruebas Múltiples y el Problema del Error Tipo I Acumulado",
    "section": "Cuándo Usar Ajustes para Pruebas Múltiples",
    "text": "Cuándo Usar Ajustes para Pruebas Múltiples\n\nEs muy común en la investigación científica y estadística realizar múltiples pruebas de hipótesis para explorar diferentes aspectos de los datos.\nEn tales situaciones, es importante controlar la tasa de error Tipo I familiar para evitar conclusiones incorrectas.\nUn ejemplo común es la comparación de múltiples grupos de tratamiento en un experimento, donde se realizan pruebas de comparación por pares entre todos los grupos.\n\nEsto sucede a menudo cuando tenemos múltiples medias, las cuales analizamos con un ANOVA. Si recuerdas, el ANOVA NO nos dice cuáles medias son diferentes, solo que al menos una es diferente. Por lo tanto, necesitamos hacer pruebas adicionales para determinar cuáles son diferentes. En este punto, debemos ajustar el nivel de significancia para controlar el error Tipo I acumulado. Veremos esto en el siguiente módulo, donde nos adentraremos en el ANOVA y las pruebas post-hoc (pruebas adicionales para determinar cuáles medias son diferentes)."
  },
  {
    "objectID": "docs/22-distribuciones-nonom.html#introducción-y-objetivos",
    "href": "docs/22-distribuciones-nonom.html#introducción-y-objetivos",
    "title": "Distribuciones de Probabilidad II",
    "section": "Introducción y Objetivos",
    "text": "Introducción y Objetivos\n\nA pesar de que la distribución normal es la más conocida y utilizada para los datos en biología y medicina, existen muchas otras distribuciones de probabilidad que se pueden aplicar a diferentes tipos de datos.\nEn esta lección, exploraremos algunas de las distribuciones de probabilidad más comunes y cómo se pueden utilizar en la práctica.\nNuestro objetivo es comprender las características clave de estas distribuciones y cómo se pueden aplicar en el análisis de datos, además de graficarlas en R para visualizar su forma y propiedades.\nTambién aprenderas a simular datos que sigan estas distribuciones con las funciones de R.\nAl final de esta lección, tendrás una comprensión más amplia de las distribuciones de probabilidad y cómo se pueden utilizar en tu trabajo de análisis de datos.\nSin embargo, toma en cuenta que en este curso nos centraremos en la distribuciones más comun y útil para la biología y la medicina, la distribución normal."
  },
  {
    "objectID": "docs/22-distribuciones-nonom.html#distribuciones-de-probabilidad",
    "href": "docs/22-distribuciones-nonom.html#distribuciones-de-probabilidad",
    "title": "Distribuciones de Probabilidad II",
    "section": "Distribuciones de Probabilidad",
    "text": "Distribuciones de Probabilidad\n\nRecordemos que una distribución de probabilidad describe la probabilidad de ocurrencia de cada valor en un conjunto de datos.\nCada distribución tiene sus propias características y propiedades, lo que las hace únicas y útiles para diferentes situaciones.\nAlgunas de las distribuciones de probabilidad más comunes, sin contar la ya vista dist. normal, incluyen: distribución binomial, distribución de Poisson, distribución exponencial, entre otras."
  },
  {
    "objectID": "docs/22-distribuciones-nonom.html#distribución-normal",
    "href": "docs/22-distribuciones-nonom.html#distribución-normal",
    "title": "Distribuciones de Probabilidad II",
    "section": "Distribución Normal",
    "text": "Distribución Normal\n\nSe caracteriza por su forma de campana y es simétrica alrededor de su media.\nLa distribución normal tiene dos parámetros clave: la media (\\(\\mu\\)) y la desviación estándar (\\(\\sigma\\)).\nEn gran parte, los datos en la naturaleza siguen una distribución normal y es fundamental en la teoría detrás de la mayoría de métodos y pruebas estadísticas.\nEn la siguiente diapositiva generaremos datos simulados que sigan una distribución normal.\nSi no te acuerdas de estas funciones, revisa de nuevo la lección anterior de distribuciones de probabilidad y ggplot."
  },
  {
    "objectID": "docs/22-distribuciones-nonom.html#section",
    "href": "docs/22-distribuciones-nonom.html#section",
    "title": "Distribuciones de Probabilidad II",
    "section": "",
    "text": "Observa que utilizamos la función rnorm() para generar datos que sigan una distribución normal. Esta función toma tres argumentos principales:\nn: número de observaciones aleatorias a ser generadas. En este caso, generaremos 1000 observaciones.\nmean: la media de la distribución normal. Establecemos la media en 50.\nsd: la desviación estándar de la distribución normal. Establecemos la desviación estándar en 10.\nComo estamos generando datos aleatorios, establecemos una semilla (set.seed()) para que los resultados sean reproducibles. Si no estableces una semilla, los resultados serán diferentes cada vez que ejecutes el código (aunque seguirán siendo datos que siguen una distribución normal con media 50 y desviación estándar 10)."
  },
  {
    "objectID": "docs/22-distribuciones-nonom.html#distribución-binomial",
    "href": "docs/22-distribuciones-nonom.html#distribución-binomial",
    "title": "Distribuciones de Probabilidad II",
    "section": "Distribución Binomial",
    "text": "Distribución Binomial\n\nLa distribución binomial describe el número de éxitos en una secuencia de ensayos independientes (independientes significa que el resultado de un ensayo no afecta el resultado de otro, como lanzar una moneda).\nCada ensayo tiene dos resultados posibles: éxito o fracaso.\nLos parámetros clave de la distribución binomial son el número de ensayos (n) y la probabilidad de éxito (p).\nEjemplo de variables con esta distribución: lanzar una moneda o contar el número de éxitos/fracasos en una muestra.\nObserva que para simular datos de una distribución binomial, usamos la función rbinom() en lugar de rnorm().\nrbinom() genera datos de una distribución binomial con los parámetros especificados. Toma los siguientes argumentos:"
  },
  {
    "objectID": "docs/22-distribuciones-nonom.html#section-1",
    "href": "docs/22-distribuciones-nonom.html#section-1",
    "title": "Distribuciones de Probabilidad II",
    "section": "",
    "text": "rbinom(n,    # Número de observaciones aleatorias a ser generadas\n       size, # Número de ensayos (&gt; = 0)\n       prob) # La probabilidad de éxito en cada ensayo"
  },
  {
    "objectID": "docs/22-distribuciones-nonom.html#section-2",
    "href": "docs/22-distribuciones-nonom.html#section-2",
    "title": "Distribuciones de Probabilidad II",
    "section": "",
    "text": "Simulemos un experimento donde lanzas una moneda 10 veces y quieres graficar un histograma que represente el número de caras obtenidas. Repetirás este experimento por 100 días. Como solo hay dos resultados posibles, cara o cruz, nuestra probabilidad de éxito es 0.5 o 50%. La función rbinom() tiene tres argumentos principales:\n\nn: número de experimentos (en este caso, cuántas veces repetimos el experimento de lanzar la moneda 10 veces). Supongamos que repetimos el experimento 100 veces.\nsize: número de lanzamientos por experimento (en este caso, 10 lanzamientos por experimento).\nprob: probabilidad de éxito (en este caso, la probabilidad de obtener cara, que es 0.5 para una moneda justa)."
  },
  {
    "objectID": "docs/22-distribuciones-nonom.html#section-3",
    "href": "docs/22-distribuciones-nonom.html#section-3",
    "title": "Distribuciones de Probabilidad II",
    "section": "",
    "text": "El histograma mostrará la distribución del número de caras obtenidas en 10 lanzamientos de moneda, repetidos 100 veces.\nDado que las probabilidades son simétricas (0.5 para cara y 0.5 para cruz), la distribución tendrá una media en torno a 5 (la mitad de los lanzamientos deberían ser caras, en promedio), pero con variabilidad en los resultados.\nLos valores extremos (muy pocos o muchas caras) serán menos frecuentes.\nAhora imagina que repetimos el experimento, pero con una moneda cargada que tiene una probabilidad de 0.85 de obtener cara. ¿Cómo crees que cambiaría la distribución de los resultados? Antes de correr el código, piensa en cómo se vería el histograma."
  },
  {
    "objectID": "docs/22-distribuciones-nonom.html#distribución-de-poisson",
    "href": "docs/22-distribuciones-nonom.html#distribución-de-poisson",
    "title": "Distribuciones de Probabilidad II",
    "section": "Distribución de Poisson",
    "text": "Distribución de Poisson\n\nLa distribución de Poisson es una distribución de probabilidad que describe el número de eventos que ocurren en un intervalo de tiempo o espacio, cuando estos eventos suceden de manera independiente y con una tasa promedio constante.\nSe utiliza para modelar eventos raros o inusuales, como accidentes, llamadas telefónicas, o errores en un proceso.\nLa distribución de Poisson tiene un solo parámetro, la tasa de ocurrencia (\\(\\lambda\\)), que representa el número promedio de eventos en el intervalo.\nLa distribución de Poisson es útil para modelar eventos discretos y se utiliza en situaciones donde los eventos son raros y aleatorios.\nA continuación, veremos cómo se ve la distribución de Poisson y cómo se puede aplicar en la práctica."
  },
  {
    "objectID": "docs/22-distribuciones-nonom.html#section-4",
    "href": "docs/22-distribuciones-nonom.html#section-4",
    "title": "Distribuciones de Probabilidad II",
    "section": "",
    "text": "Un ejemplo de una variable con esta distribución es el número de mutaciones en una cadena de DNA en una determinada región durante un período de tiempo fijo.\nImagina que estamos investigando el número de mutaciones en una sección de ADN en células cancerígenas.\nSabemos, a partir de estudios previos, que en promedio ocurren 3 mutaciones por célula. Queremos simular y visualizar la distribución de mutaciones en 1000 células."
  },
  {
    "objectID": "docs/22-distribuciones-nonom.html#section-5",
    "href": "docs/22-distribuciones-nonom.html#section-5",
    "title": "Distribuciones de Probabilidad II",
    "section": "",
    "text": "En este caso, la tasa promedio de mutaciones por célula es 3 y el suceso que estamos modelando es el número de mutaciones en una célula. Usaremos la función rpois() para simular datos que sigan una distribución de Poisson. Esta función toma dos argumentos principales: - n: número de observaciones aleatorias a ser generadas. - lambda: la tasa de ocurrencia de eventos en un intervalo de tiempo o espacio. - En este caso, generaremos 1000 observaciones de la distribución de Poisson con una tasa de ocurrencia de 3 mutaciones por célula."
  },
  {
    "objectID": "docs/22-distribuciones-nonom.html#section-6",
    "href": "docs/22-distribuciones-nonom.html#section-6",
    "title": "Distribuciones de Probabilidad II",
    "section": "",
    "text": "El histograma muestra la distribución del número de mutaciones por célula en 1000 células. Dado que usamos una distribución de Poisson con un parámetro \\(\\lambda\\) = 3, esperamos que:\nEl pico del histograma esté alrededor de 3 (el número promedio de mutaciones por célula).\nLa distribución será asimétrica, con más células concentradas en el rango de mutaciones bajas, y una “cola” que se extiende hacia la derecha a medida que aumentan el número de mutaciones.\nPuedes ajustar el número de células para cambiar el tamaño de la muestra o cambiar el valor de lambda para simular una tasa diferente de mutaciones por célula."
  },
  {
    "objectID": "docs/22-distribuciones-nonom.html#otras-distribuciones",
    "href": "docs/22-distribuciones-nonom.html#otras-distribuciones",
    "title": "Distribuciones de Probabilidad II",
    "section": "Otras Distribuciones",
    "text": "Otras Distribuciones\n\nAdemás de la distribución normal, binomial y de Poisson, existen muchas otras distribuciones de probabilidad que se utilizan en diferentes contextos.\nEn este enlace y este puedes encontrar una lista de las distribuciones de probabilidad que puedes encontrar en R.\nAunque en el curso nos enfocaremos en la distribución normal, veremos que muchas pruebas estadísticas utilizan otras distribuciones, por lo que es útil conocerlas y comprender sus propiedades.\nAlgunos de estos ejemplos, son la distribución chi-cuadrada, t de Student, F de Fisher, entre otras que son fundamentales en la inferencia estadística y en el análisis de datos.\nSolo para conocerlas, veamos rápidamente algunas de estas distribuciones utilizadas en análisis estadístico."
  },
  {
    "objectID": "docs/22-distribuciones-nonom.html#distribuciones-y-pruebas-asociadas",
    "href": "docs/22-distribuciones-nonom.html#distribuciones-y-pruebas-asociadas",
    "title": "Distribuciones de Probabilidad II",
    "section": "Distribuciones y pruebas asociadas",
    "text": "Distribuciones y pruebas asociadas\n\n\n\n\n\n\n\n\n\nDistribución\nPrueba estadística asociada\nAplicaciones en Biomedicina\nIlustración\n\n\n\n\nt de Student\nPrueba t (una muestra, dos muestras independientes, pareada)\nComparación de medias de biomarcadores, tratamientos, etc.\n\n\n\nChi-cuadrada (χ²)\nPrueba de bondad de ajuste, prueba de independencia (χ²)\nComparación de frecuencias, análisis de tablas de contingencia\n\n\n\nF de Fisher\nANOVA, pruebas de igualdad de varianzas, regresión\nComparación de varios tratamientos, análisis de regresión\n\n\n\nNormal (Z)\nPrueba Z, intervalos de confianza\nComparación de medias para grandes muestras\n\n\n\nBinomial\nPrueba binomial, prueba exacta de Fisher\nEvaluación de proporciones de éxito (por ejemplo, respuesta a un tratamiento)"
  },
  {
    "objectID": "docs/84-normalidad-correcciones.html",
    "href": "docs/84-normalidad-correcciones.html",
    "title": "Problemas comunes en ANOVA",
    "section": "",
    "text": "En esta lección, veremos qué hacer cuando violamos los supuestos de normalidad y homogeneidad de varianzas en un ANOVA. En estos casos, es posible que necesitemos realizar correcciones para garantizar que los resultados sean válidos. También veremos cómo manejar valores atípicos en nuestros datos.\nEn caso que los supuestos de normalidad no se cumplan, puedes utilizar pruebas no paramétricas como el test de Kruskal-Wallis (que es similar al ANOVA de una vía). Sin embargo, no existen alternativas no-paramétricas para el ANOVA de dos vías ni para el ANOVA de tres vías."
  },
  {
    "objectID": "docs/84-normalidad-correcciones.html#librerías",
    "href": "docs/84-normalidad-correcciones.html#librerías",
    "title": "Problemas comunes en ANOVA",
    "section": "Librerías",
    "text": "Librerías"
  },
  {
    "objectID": "docs/84-normalidad-correcciones.html#anova-de-una-vía",
    "href": "docs/84-normalidad-correcciones.html#anova-de-una-vía",
    "title": "Problemas comunes en ANOVA",
    "section": "ANOVA de una vía",
    "text": "ANOVA de una vía\nEn este ejemplo, utilizaremos el conjunto de datos PlantGrowth para realizar un ANOVA de una vía. Este conjunto de datos contiene los datos de un experimento en el que se midió el peso de plantas bajo tres condiciones diferentes: control, tratamiento 1 y tratamiento 2.\n\n\n\n\n\n\n\n\n\nReordenar niveles de un factor\n\nUsando la función levels(), podemos ver los niveles del factor group en el conjunto de datos PlantGrowth.\n\n\n\n\n\n\n\n\n\n\nEn caso que los niveles no estén en el orden deseado, podemos reordenarlos utilizando la función reorder_levels() del paquete rstatix de la siguiente manera. Esto es útil para asegurarnos de que los niveles de un factor se muestren en el orden correcto en los gráficos y análisis. Normalmente, quieres mostrar primero el grupo de control y luego los grupos de tratamiento.\n\n\n\n\n\n\n\n\n\n\n\nPregunta de investigación\n\nLa pregunta de investigación es si las condiciones de tratamiento tienen un efecto significativo en el crecimiento de las plantas.\n\n\n\nResumen estadístico\n\n\n\n\n\n\n\n\n\n\nVisualización preliminar\n\n\n\n\n\n\n\n\n\n\nValores atípicos (outliers)\n\nEliminar valores atípicos puede mejorar la normalidad de los datos y hacer que los resultados del ANOVA sean más confiables.\nSin embargo, es importante tener en cuenta que la eliminación de valores atípicos depende del contexto de tu investigación y debe justificarse adecuadamente.\nEn el gráfico pasado, puedes ver que el boxplot identificó dos valores atípicos en el grupo trt1 (puntos fuera de la caja). Estos valores se identifican con la fórmula 1.5 * IQR (rango intercuartílico). Es decir, cualquier valor que esté a más de 1.5 veces el IQR por encima del tercer cuartil o por debajo del primer cuartil se considera un valor atípico.\nPodemos inspeccionar estos valores atípicos con la función identify_outliers() del paquete rstatix.\n\n\n\n\n\n\n\n\n\n\nPodemos ver que hay dos valores atípicos en el grupo trt1. Podemos eliminar estos valores atípicos y volver a realizar el ANOVA.\nTambién observa que esta función nos devuelve una columna is.extreme que identifica si un valor se encuentra a más de 3 veces el IQR del tercer cuartil o del primer cuartil.\nPara eliminar los valores atípicos de manera sencilla, podemos hacer lo siguiente:\n\nPrimero, identificamos los valores atípicos con la función identify_outliers() y los almacenamos en una variable.\nLuego, usamos la función anti_join() del paquete dplyr para eliminar los valores atípicos del conjunto de datos original.\nFinalmente, almacenamos el conjunto de datos limpio (sin outliers) en una nueva variable llamada plant_clean.\n\n\n\n\n\n\n\n\n\n\nVerificamos que ya no hay valores atípicos en el conjunto de datos limpio.\n\n\n\n\n\n\n\n\n\n\nPrueba de Normalidad\n\nComo estamos haciendo un ANOVA de una vía, podemos usar la función lm() o aov() por facilidad de la siguiente manera:\n\n\n\n\n\n\n\n\n\n\nComo el valor p es mayor a 0.05, podemos asumir que los residuales siguen una distribución normal.\nTambién podemos checar la normalidad de los datos en cada grupo con la función shapiro_test() de la siguiente manera:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSi tu muestra es mayor que 50, es preferible usar el QQ plot ya que la prueba de Shapiro-Wilk se vuelve muy sensible a desviaciones menores de la normalidad en muestras grandes.\n\n\n\n\nHomogeneidad de varianza o homocedasticidad\n\nLa homogeneidad de varianza es un supuesto importante en el ANOVA. Significa que las varianzas de las diferentes condiciones son iguales.\nPodemos verificar la homogeneidad de varianza con la prueba de Levene y con un gráfico de residuales vs. valores ajustados, como el siguiente:\n\n\n\n\n\n\n\n\n\n\nEn este gráfico, no hay una relación evidente entre los residuales y los valores ajustados (la media de cada grupo), lo cual es bueno. Por lo tanto, podemos asumir la homogeneidad de varianza. Recuerda la clase de supuestos de modelos lineales para más información (link de la clase).\nPodemos verificar la homogeneidad de varianza con la prueba de Levene de la siguiente manera:\n\n\n\n\n\n\n\n\n\n\nEl valor de p es mayor a 0.05, por lo que podemos asumir que las varianzas son homogéneas.\n\n\n\nANOVA\n\nVamos a usar la función anova_test() del paquete rstatix para realizar un ANOVA de una vía:\n\n\n\n\n\n\n\n\n\n\nEn este caso, el valor p es menor a 0.05, lo que indica que hay diferencias significativas entre los grupos. Por lo tanto, vamos a realizar una prueba post-hoc para determinar cuáles son los grupos que difieren entre sí.\n\n\n\nPost-hoc tests\n\nVamos a realizar una prueba post-hoc de Tukey para determinar cuáles son los grupos que difieren entre sí. Esto se hace con la función tukey_hsd() del paquete rstatix:\n\n\n\n\n\n\n\n\n\n\nPodemos ver que hay dos comparaciones con diferencias significativas: ctrl vs. trt1 y trt1 vs. trt2.\n\n\n\nReportar resultados\n\nPodemos reportar los resultados de la siguiente manera:\n\n\nSe realizó un ANOVA de una vía para evaluar si el crecimiento de las plantas era diferente para los 3 grupos de tratamiento: ctrl (n = 10), trt1 (n = 10) y trt2 (n = 10). El crecimiento de las plantas difiere de manera significativa entre los diferentes grupos de tratamiento, F(2, 25) = 13.394, p &lt; 0.001. El crecimiento de las plantas disminuyó en el grupo trt1 (media = 4.66) en comparación con el grupo ctrl (media = 5.03). Aumentó en el grupo trt2 (media = 5.53) en comparación con trt1 y ctrl. Las comparaciones post-hoc de Tukey revelaron que el aumento de trt1 a trt2 (1.19, IC 95% (0.593 a 1.78)) fue estadísticamente significativo (p &lt; 0.001). La prueba de Tukey también mostró diferencias significativas entre ctrl y trt1 (-0.693, IC 95% (-1.29 a -0.09)).\n\n\n\nGráfico con p-values\n\nPara visualizar los resultados del ANOVA con las comparaciones post-hoc, podemos hacer lo siguiente:\n\nPrimero, añadimos la posición x a los datos de las comparaciones múltiples (variable pwc) con la función add_xy_position() del paquete rstatix. Esto es necesario para que las etiquetas de significancia se muestren correctamente en el gráfico.\nLuego, creamos un gráfico de caja con ggboxplot() y añadimos las etiquetas de significancia con la función stat_pvalue_manual().\nFinalmente, añadimos el subtítulo y la leyenda con los resultados del ANOVA y las comparaciones post-hoc. En el subtitulo, usamos la función get_test_label() para obtener una etiqueta descriptiva del ANOVA.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nEn caso que quisieramos hacer un ANOVA sin asumir la igualdad de varianzas, podemos usar el test de Welch. Para ello, simplemente cambiamos la función anova_test() por welch_anova_test(). Esta función realiza un ANOVA de una vía con corrección de Welch para la igualdad de varianzas. Observa que los grados de libertad son diferentes en este caso debido a la corrección de Welch."
  },
  {
    "objectID": "docs/84-normalidad-correcciones.html#anova-de-dos-vías",
    "href": "docs/84-normalidad-correcciones.html#anova-de-dos-vías",
    "title": "Problemas comunes en ANOVA",
    "section": "ANOVA de dos vías",
    "text": "ANOVA de dos vías\nPara este ejemplo vamos a utilizar el conjunto de datos jobsatisfaction del paquete datarium. Este conjunto de datos contiene la puntuación de satisfacción laboral organizada por género y niveles de educación.\nNos interesa ver el efecto de la variable education_level en la satisfacción laboral, y cómo este efecto puede depender del género. En otras palabras, queremos ver si el efecto de education_level en la satisfacción laboral es diferente para hombres y mujeres.\n\n\n\n\n\n\n\n\n\nResumen estadístico\n\n\n\n\n\n\n\n\n\n\nVisualización preliminar\n\n\n\n\n\n\n\n\n\n\nValores atípicos\n\n\n\n\n\n\n\n\n\nNo hay valores atípicos en los datos.\n\n\n\nPrueba de Normalidad\n\n\n\n\n\n\n\n\n\nCumple con el supuesto de normalidad. Esto también lo podemos comparar con la prueba de Shapiro-Wilk en cada celda de diseño (cada combinación de género y nivel de educación):\n\n\n\n\n\n\n\n\n\n\n\nHomogeneidad de varianza\n\n\n\n\n\n\n\n\n\nLa prueba de Levine no es significativa, por lo que podemos asumir que las varianzas son homogéneas.\n\n\n\nANOVA\n\nrecuerda que tenemos un diseño de dos vías, por lo que podemos explorar la interacción entre las variables gender y education_level.\nSi usamos la función anova_test() del paquete rstatix, podemos realizar lo siguiente:\n\n\n\n\n\n\n\n\n\n\nEn este caso, el valor p de la interacción entre gender y education_level es significativo, lo que indica que el efecto de education_level en la satisfacción laboral depende del género.\nSi no tuvieramos una interacción significativa, podríamos seguir con las pruebas de los efectos principales de gender y education_level, es decir:\n\njobsatisfaction %&gt;% anova_test(score ~ gender + education_level)\n\n\nPost-hoc\n\nCuando tenemos un ANOVA de dos o más vías con interacción, una forma fácil de determinar las comparaciones significativas es realizar pruebas de comparaciones múltiples entre los niveles de cada factor organizados por el otro factor.\nPara esto, vamos a hacer estos pasos:\n\nPrimero, agrupamos los datos por gender\nLuego, realizamos pruebas de comparaciones múltiples entre los niveles de education_level organizados por gender con la función emmeans_test() del paquete emmeans.\nEl paquete emmeans es muy útil cuando tenemos diseños de ANOVA complejos con interacciones, ya que nos permite realizar comparaciones entre los niveles de un factor organizados por otro factor.\nVamos a usar el método de ajuste de Holm para corregir los valores p de las comparaciones múltiples.\n\n\n\n\n\n\n\n\n\n\n\nPodemos ver que hay diferencias significativas en la satisfacción laboral entre todos los grupos de educación para hombres y mujeres.\nSi no hubera una interacción significativa, podríamos realizar pruebas de comparaciones múltiples entre los niveles principales de cada factor organizados por el otro factor de la siguiente manera:\n\njobsatisfaction %&gt;%\n  pairwise_t_test(\n    score ~ education_level, \n    p.adjust.method = \"bonferroni\"\n    )\n\n\nReporte de resultados\n\nSe realizó un ANOVA de dos vías para evaluar los efectos del género y el nivel de educación en la satisfacción laboral. Se encontró una interacción significativa entre el género y el nivel de educación en la satisfacción laboral, F(2, 52) = 7.33, p = 0.0016. Se realizaron pruebas post-hoc de comparaciones múltiples con el método de Holm entre los niveles de educación organizados por género. Se encontraron diferencias significativas en la satisfacción laboral entre todos los grupos de educación para hombres y mujeres.\n\n\n\nGráfico con p-values"
  },
  {
    "objectID": "docs/84-normalidad-correcciones.html#correcciones-de-normalidad",
    "href": "docs/84-normalidad-correcciones.html#correcciones-de-normalidad",
    "title": "Problemas comunes en ANOVA",
    "section": "Correcciones de normalidad",
    "text": "Correcciones de normalidad\n\nEn caso que los residuales no sigan una distribución normal, podemos realizar correcciones para garantizar que los resultados del ANOVA sean válidos.\n\nPara estos ejemplos, vamos a usar los datos iris, que contienen medidas de longitud y ancho de sépalos y pétalos de tres especies de iris.\n\n\n\n\n\n\n\n\n\nskewness (asimetría)\n\nLa asimetría es una medida de la simetría de una distribución. Si la asimetría es 0, la distribución es simétrica (como en la distribución normal). Si es positiva, la distribución es asimétrica hacia la derecha (cola a la derecha). Si es negativa, la distribución es asimétrica hacia la izquierda (cola a la izquierda).\n\n\nEntre mayor sea el valor de skewness, significa que la distribución difiere más de una distribución normal. Podemos calcular la asimetría con la función skewness() del paquete moments de la siguiente manera:\n\n\n\n\n\n\n\n\n\n\nTransformación de datos\n\nUna forma común de corregir la asimetría es transformar los datos.\nAlgunos de los métodos de transformación más comunes incluyen:\n\nPara asimetría moderada:\n\nsqrt(x) para corregir asimetría positiva.\n\nsqrt(max(x+1) - x) para corregir asimetría negativa.\n\nPara simetría moderada:\n\nlog10(x) para corregir asimetría positiva.\nlog10(max(x+1) - x) para corregir asimetría negativa.\n\nPara asimetría severa:\n\n1/x para corregir asimetría positiva.\n1/(max(x+1) - x) para corregir asimetría negativa.\n\n\nCon el ejemplo anterior, vamos a probar algunas transofrmaciones. Observa como cambia la asimetría de los datos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParece que la transformación logarítmica es la que más se acerca a una distribución normal. Sin embargo, es importante recordar que la transformación de datos puede cambiar la interpretación de los resultados, por lo que debes tener cuidado al aplicarla. Por ejemplo, si transformas los datos con una raíz cuadrada, los resultados se interpretarán en términos de la raíz cuadrada de la variable original. Es decir, si la variable original era la longitud del sépalo, los resultados transformados se interpretarán en términos de la raíz cuadrada de la longitud del sépalo."
  },
  {
    "objectID": "docs/21.2-histogramas-personalizados-python.html",
    "href": "docs/21.2-histogramas-personalizados-python.html",
    "title": "Ejemplo Práctico: Histogramas y Personalización en Python",
    "section": "",
    "text": "En esta lección, profundizaremos en la personalización de histogramas y buenas prácticas para visualización en Python.\nUsaremos datos simulados de alturas de jirafas en dos islas, como en el ejemplo anterior."
  },
  {
    "objectID": "docs/21.2-histogramas-personalizados-python.html#introducción",
    "href": "docs/21.2-histogramas-personalizados-python.html#introducción",
    "title": "Ejemplo Práctico: Histogramas y Personalización en Python",
    "section": "",
    "text": "En esta lección, profundizaremos en la personalización de histogramas y buenas prácticas para visualización en Python.\nUsaremos datos simulados de alturas de jirafas en dos islas, como en el ejemplo anterior."
  },
  {
    "objectID": "docs/21.2-histogramas-personalizados-python.html#simulación-de-datos",
    "href": "docs/21.2-histogramas-personalizados-python.html#simulación-de-datos",
    "title": "Ejemplo Práctico: Histogramas y Personalización en Python",
    "section": "Simulación de datos",
    "text": "Simulación de datos"
  },
  {
    "objectID": "docs/21.2-histogramas-personalizados-python.html#histograma-básico-por-grupo",
    "href": "docs/21.2-histogramas-personalizados-python.html#histograma-básico-por-grupo",
    "title": "Ejemplo Práctico: Histogramas y Personalización en Python",
    "section": "Histograma básico por grupo",
    "text": "Histograma básico por grupo"
  },
  {
    "objectID": "docs/21.2-histogramas-personalizados-python.html#personalizar-colores-y-estilos",
    "href": "docs/21.2-histogramas-personalizados-python.html#personalizar-colores-y-estilos",
    "title": "Ejemplo Práctico: Histogramas y Personalización en Python",
    "section": "Personalizar colores y estilos",
    "text": "Personalizar colores y estilos"
  },
  {
    "objectID": "docs/21.2-histogramas-personalizados-python.html#guardar-el-gráfico-como-imagen",
    "href": "docs/21.2-histogramas-personalizados-python.html#guardar-el-gráfico-como-imagen",
    "title": "Ejemplo Práctico: Histogramas y Personalización en Python",
    "section": "Guardar el gráfico como imagen",
    "text": "Guardar el gráfico como imagen"
  },
  {
    "objectID": "docs/21.2-histogramas-personalizados-python.html#buenas-prácticas",
    "href": "docs/21.2-histogramas-personalizados-python.html#buenas-prácticas",
    "title": "Ejemplo Práctico: Histogramas y Personalización en Python",
    "section": "Buenas prácticas",
    "text": "Buenas prácticas\n\nUsa títulos y etiquetas descriptivas.\nElige paletas de colores accesibles y consistentes.\nUsa plt.tight_layout() para evitar que las etiquetas se sobrepongan.\nGuarda tus gráficos con alta resolución para presentaciones o publicaciones."
  },
  {
    "objectID": "docs/21.2-histogramas-personalizados-python.html#ejercicio",
    "href": "docs/21.2-histogramas-personalizados-python.html#ejercicio",
    "title": "Ejemplo Práctico: Histogramas y Personalización en Python",
    "section": "Ejercicio",
    "text": "Ejercicio\n\nCambia los colores de la paleta por otros de tu preferencia.\nCambia la posición de la leyenda (loc puede ser “upper left”, “lower right”, etc.).\nGuarda el gráfico con otro nombre y diferente resolución."
  },
  {
    "objectID": "docs/21.2-histogramas-personalizados-python.html#reflexión",
    "href": "docs/21.2-histogramas-personalizados-python.html#reflexión",
    "title": "Ejemplo Práctico: Histogramas y Personalización en Python",
    "section": "Reflexión",
    "text": "Reflexión\n\n¿Qué combinación de colores comunica mejor la diferencia entre los grupos?\n¿Cómo afecta la posición de la leyenda a la claridad del gráfico?\n\nEstas prácticas te ayudarán a crear visualizaciones más claras y efectivas en Python."
  },
  {
    "objectID": "docs/28-teorema-limite.html#introducción-al-teorema-del-límite-central-tlc",
    "href": "docs/28-teorema-limite.html#introducción-al-teorema-del-límite-central-tlc",
    "title": "Teorema del Límite Central",
    "section": "Introducción al Teorema del Límite Central (TLC)",
    "text": "Introducción al Teorema del Límite Central (TLC)\n\nEl Teorema del Límite Central (TLC) es uno de los conceptos más fundamentales en estadística.\nDefinición formal del Teorema del Límite Central: Cuando se extraen muestras de una población con reemplazo y el tamaño de las muestras (n) aumenta, la distribución de los promedios muestrales de dichas muestras se aproximará cada vez más a una distribución normal. Esto es cierto independientemente de la forma de la distribución original de la población, y la normalidad de los promedios muestrales suele aparecer cuando \\(n \\geq 30\\) .\ncuando hablamos de reemplazo, significa que cada vez que tomamos una muestra, la devolvemos a la población original antes de tomar la siguiente muestra. Esto es en contrastraste con el muestreo sin reemplazo, donde no se permite que los elementos se repitan en las muestras ya que se eliminan de la población original.\nUn ejemplo de muestreo con reemplazo es cuando lanzamos una moneda y anotamos los resultados, luego volvemos a lanzar la moneda y anotamos los resultados, y así sucesivamente.\nUn ejemplo de muestreo sin reemplazo es cuando seleccionamos una carta de una baraja de cartas y no la devolvemos antes de seleccionar la siguiente carta.\nVamos a ver un ejemplo para entender mejor cómo funciona el TLC y por qué es tan importante en estadística aplicada."
  },
  {
    "objectID": "docs/28-teorema-limite.html#ejemplo-niveles-de-glucosa-en-sangre",
    "href": "docs/28-teorema-limite.html#ejemplo-niveles-de-glucosa-en-sangre",
    "title": "Teorema del Límite Central",
    "section": "Ejemplo: Niveles de Glucosa en Sangre",
    "text": "Ejemplo: Niveles de Glucosa en Sangre\nPoblación Original con Distribución Sesgada a la Izquierda\n\n\nSupongamos que estamos estudiando los niveles de glucosa en sangre en una población de pacientes diabéticos. Sabemos que los niveles de glucosa no siguen una distribución normal, sino que están sesgados a la izquierda. Esto significa que la mayoría de los pacientes tiene niveles de glucosa cercanos al valor promedio, pero algunos tienen niveles mucho más bajos, lo que crea una “cola” a la izquierda en la distribución.\nPodemos simular una distribución sesgada a la izquierda en R utilizando la función rbeta (distribución beta) para generar 10,000 observaciones que representen los niveles de glucosa en sangre:"
  },
  {
    "objectID": "docs/28-teorema-limite.html#section",
    "href": "docs/28-teorema-limite.html#section",
    "title": "Teorema del Límite Central",
    "section": "",
    "text": "En este caso, la media de los niveles de glucosa en la población es de 7.13 mmol/L, y la desviación estándar es de 1.61 mmol/L. ‘rbeta’ tomará dos argumentos: el número de observaciones que queremos generar (10,000) y los parámetros de la distribución beta (5 y 2) que determinan la forma de la distribución (no te preocupes demasiado por estos valores, solo queremos simular una distribución sesgada a la izquierda).\n\nRPython"
  },
  {
    "objectID": "docs/28-teorema-limite.html#section-1",
    "href": "docs/28-teorema-limite.html#section-1",
    "title": "Teorema del Límite Central",
    "section": "",
    "text": "La cola de la distribución está sesgada a la izquierda, lo que indica que hay más pacientes con niveles bajos de glucosa alejados de la media.\nUn valor de desviación estándar \\(\\sigma = 1.61\\) nos dice que la mayoría de los valores están entre 5.52 mmol/L y 8.74 mmol/L, es decir, dentro de una desviación estándar de la media."
  },
  {
    "objectID": "docs/28-teorema-limite.html#uso-del-tlc-para-construir-la-distribución-muestral",
    "href": "docs/28-teorema-limite.html#uso-del-tlc-para-construir-la-distribución-muestral",
    "title": "Teorema del Límite Central",
    "section": "Uso del TLC para Construir la Distribución Muestral",
    "text": "Uso del TLC para Construir la Distribución Muestral\n\nSegún el TLC, si tomamos muestras lo suficientemente grandes (\\(n \\geq 30\\)), la distribución de los promedios de estas muestras será aproximadamente normal, con media igual a la media de la población y una desviación estándar ajustada llamada error estándar. Propiedades de la Distribución Muestral:\nMedia de la distribución de los promedios muestrales (\\(\\bar{x}\\)): Es igual a la media de la población original.\nError estándar (\\(\\sigma_{\\bar{x}}\\)): Es la desviación estándar de los promedios muestrales, que se calcula como ( \\(\\sigma / \\sqrt{n}\\)), donde n es el tamaño de la muestra."
  },
  {
    "objectID": "docs/28-teorema-limite.html#generar-promedios-muestrales",
    "href": "docs/28-teorema-limite.html#generar-promedios-muestrales",
    "title": "Teorema del Límite Central",
    "section": "Generar Promedios Muestrales",
    "text": "Generar Promedios Muestrales\n\nPara ilustrar el TLC, vamos a tomar muestras de tamaño n = 30 de nuestra población de niveles de glucosa y calcular los promedios muestrales. Luego, repetiremos este proceso varias veces para ver cómo se distribuyen los promedios.\nVamos a usar la función sample para tomar muestras aleatorias de tamaño 30 y la función replicate para repetir este proceso varias veces (100 veces). Luego, visualizaremos la distribución de los promedios muestrales.\n\n\nRPython"
  },
  {
    "objectID": "docs/28-teorema-limite.html#resultados",
    "href": "docs/28-teorema-limite.html#resultados",
    "title": "Teorema del Límite Central",
    "section": "Resultados",
    "text": "Resultados\n\nMedia: La media de los promedios muestrales debería estar cerca de la media de la población original, que es 7.13 mmol/L.\nForma de la Distribución: Aunque la distribución original de los datos está sesgada a la izquierda, la distribución de los promedios muestrales será aproximadamente normal.\nError Estándar: El error estándar de los promedios muestrales se puede calcular como \\(\\sigma / \\sqrt{n} = 1.61 / \\sqrt{30} \\approx 0.29\\)."
  },
  {
    "objectID": "docs/28-teorema-limite.html#verificación-del-tlc-con-más-muestras",
    "href": "docs/28-teorema-limite.html#verificación-del-tlc-con-más-muestras",
    "title": "Teorema del Límite Central",
    "section": "Verificación del TLC con Más Muestras",
    "text": "Verificación del TLC con Más Muestras\nAhora, tomemos 1,000 muestras de tamaño 30 para ver si los promedios muestrales se ajustan aún mejor a una distribución normal.\n\nRPython"
  },
  {
    "objectID": "docs/28-teorema-limite.html#resultados-con-1000-muestras",
    "href": "docs/28-teorema-limite.html#resultados-con-1000-muestras",
    "title": "Teorema del Límite Central",
    "section": "Resultados con 1,000 muestras",
    "text": "Resultados con 1,000 muestras\n\nLa media de los promedios muestrales seguirá siendo aproximadamente 7.13.\nLa distribución de los promedios muestrales será aún más cercana a una distribución normal.\nEl error estándar seguirá siendo 0.29, mostrando que la variabilidad entre los promedios muestrales es menor que la variabilidad en los datos originales."
  },
  {
    "objectID": "docs/28-teorema-limite.html#resumen-del-teorema-del-límite-central",
    "href": "docs/28-teorema-limite.html#resumen-del-teorema-del-límite-central",
    "title": "Teorema del Límite Central",
    "section": "Resumen del Teorema del Límite Central",
    "text": "Resumen del Teorema del Límite Central\n\nEl Teorema del Límite Central nos proporciona una poderosa herramienta para analizar distribuciones muestrales, incluso cuando los datos originales no siguen una distribución normal. En este ejemplo, vimos cómo los niveles de glucosa en sangre, que están sesgados a la izquierda, producen promedios muestrales que tienden a seguir una distribución normal cuando el tamaño de la muestra es suficientemente grande."
  },
  {
    "objectID": "docs/28-teorema-limite.html#aspectos-clave-del-tlc",
    "href": "docs/28-teorema-limite.html#aspectos-clave-del-tlc",
    "title": "Teorema del Límite Central",
    "section": "Aspectos clave del TLC:",
    "text": "Aspectos clave del TLC:\n\nLa forma de la distribución muestral: Si el tamaño de la muestra es suficientemente grande ( \\(n \\geq 30\\) ), la distribución de los promedios muestrales será aproximadamente normal, sin importar la forma de la distribución original.\nLa media de la distribución muestral: La media de los promedios muestrales será igual a la media de la población original.\nEl error estándar: La desviación estándar de los promedios muestrales (error estándar) se puede calcular como (\\(\\sigma / \\sqrt{n}\\)), lo que indica que la variabilidad entre los promedios muestrales disminuye a medida que aumenta el tamaño de la muestra."
  },
  {
    "objectID": "docs/28-teorema-limite.html#resumen",
    "href": "docs/28-teorema-limite.html#resumen",
    "title": "Teorema del Límite Central",
    "section": "Resumen",
    "text": "Resumen\nEl Teorema del Límite Central es un principio clave en la estadística aplicada. Nos permite:\n\nTrabajar con promedios de muestras cuando los datos originales no siguen una distribución normal.\nRealizar pruebas estadísticas como la prueba t, ANOVA, y construir intervalos de confianza usando la distribución normal.\nOfrecer una justificación teórica para aplicar herramientas estadísticas basadas en normalidad, incluso cuando los datos no son normales.\n\nEn biomedicina, el TLC es invaluable para analizar datos complejos y sesgados, como el número de mutaciones, los niveles de fármacos o las mediciones clínicas, permitiendo que los investigadores realicen análisis válidos y robustos basados en promedios de muestras."
  },
  {
    "objectID": "docs/26-intervalos-confianza.html#introducción",
    "href": "docs/26-intervalos-confianza.html#introducción",
    "title": "Intervalos de Confianza",
    "section": "Introducción",
    "text": "Introducción\nLos intervalos de confianza son rangos que proporcionan una estimación del grado de incertidumbre alrededor de un estadístico de muestra, como la media o una proporción. Nos indican el rango dentro del cual es probable que se encuentre el parámetro real de la población con un cierto nivel de confianza (habitualmente el 95%)."
  },
  {
    "objectID": "docs/26-intervalos-confianza.html#conceptos-clave",
    "href": "docs/26-intervalos-confianza.html#conceptos-clave",
    "title": "Intervalos de Confianza",
    "section": "Conceptos Clave",
    "text": "Conceptos Clave\nIntervalo de Confianza para la Media: Proporciona un rango probable para la verdadera media de la población.\n    A menudo calculado usando la media muestral, la desviación estándar de la muestra, y el tamaño de la muestra.\n\nIntervalo de Confianza para una Proporción: Indica un rango para la verdadera proporción de la población.\n    Calculado utilizando la proporción muestral, el tamaño de la muestra, y un estadístico z de la distribución normal estándar.\n\nInterpretación: Un intervalo de confianza del 95% significa que si se toman 100 muestras diferentes y se calculan 100 intervalos, aproximadamente 95 de esos intervalos deberían contener la verdadera media o proporción de la población."
  },
  {
    "objectID": "docs/26-intervalos-confianza.html#ejercicio-práctico-en-r",
    "href": "docs/26-intervalos-confianza.html#ejercicio-práctico-en-r",
    "title": "Intervalos de Confianza",
    "section": "Ejercicio Práctico en R",
    "text": "Ejercicio Práctico en R\nExploraremos cómo calcular intervalos de confianza para la media utilizando un conjunto de datos simulado."
  },
  {
    "objectID": "docs/26-intervalos-confianza.html#reflexión-y-discusión",
    "href": "docs/26-intervalos-confianza.html#reflexión-y-discusión",
    "title": "Intervalos de Confianza",
    "section": "Reflexión y Discusión:",
    "text": "Reflexión y Discusión:\nExaminar el intervalo de confianza calculado: ¿Qué significa en el contexto de estos datos de altura?\nDiscute cómo el tamaño de la muestra afecta la amplitud del intervalo de confianza. ¿Qué sucedería si tuvieras una muestra más grande o más pequeña?\nEsta lección ofrece un enfoque práctico sobre cómo calcular e interpretar intervalos de confianza en R. Con estas habilidades, podrás cuantificar la incertidumbre y comunicar tus resultados con mayor claridad y precisión."
  },
  {
    "objectID": "docs/80-comparar-2medias.html",
    "href": "docs/80-comparar-2medias.html",
    "title": "Comparar media de dos grupos independientes con t-test en R",
    "section": "",
    "text": "Muestra independiente: Las muestras son independientes si las observaciones en un grupo no están relacionadas con las observaciones en el otro grupo. Por ejemplo, si se mide el peso de dos grupos (placebo vs tratamiento) de personas diferentes, los datos de un grupo no están relacionados con los datos del otro grupo. Muestra pareada o emparejada: Las muestras son pareadas si las observaciones en un grupo están relacionadas con las observaciones en el otro grupo. Por ejemplo, si se mide el peso de las mismas personas antes y después de un tratamiento, los datos de un grupo están relacionados con los datos del otro grupo."
  },
  {
    "objectID": "docs/80-comparar-2medias.html#ejemplo-práctico",
    "href": "docs/80-comparar-2medias.html#ejemplo-práctico",
    "title": "Comparar media de dos grupos independientes con t-test en R",
    "section": "Ejemplo Práctico",
    "text": "Ejemplo Práctico\n\nVamos a trabajar con datos simulados. En estos datos, tenemos las medidas de peso de dos grupos de personas: 50 mujeres (grupo A) y 50 hombres (grupo B). Queremos saber si la media de peso de las mujeres (A) es significativamente diferente de la de los hombres (B).\nEn este caso, tenemos dos grupos de muestras no relacionadas (es decir, independientes o no pareadas). Por lo tanto, es posible utilizar una prueba t independiente para evaluar si las medias son diferentes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCondiciones para usar la prueba t de dos muestras no pareadas\n\n\n\n\nLas dos muestras (A y B) deben ser independientes. Esto lo comprobamos al recolectar los datos (sabemos que el grupo de mujeres no está relacionado con el grupo de hombres).\nLas dos muestras (A y B) deben ser aproximadamente distribuidas normalmente. Esto se puede verificar utilizando la prueba de Shapiro-Wilk.\nLas dos muestras (A y B) deben tener varianzas iguales. Esto se puede verificar utilizando la prueba F."
  },
  {
    "objectID": "docs/80-comparar-2medias.html#hipótesis-de-investigación",
    "href": "docs/80-comparar-2medias.html#hipótesis-de-investigación",
    "title": "Comparar media de dos grupos independientes con t-test en R",
    "section": "Hipótesis de investigación",
    "text": "Hipótesis de investigación\n\n\\(H_0\\): La media de peso de las mujeres (A) es igual a la media de peso de los hombres (B).\n\\(H_1\\): La media de peso de las mujeres (A) es diferente de la media de peso de los hombres (B)."
  },
  {
    "objectID": "docs/80-comparar-2medias.html#visualización-preliminar-de-los-datos",
    "href": "docs/80-comparar-2medias.html#visualización-preliminar-de-los-datos",
    "title": "Comparar media de dos grupos independientes con t-test en R",
    "section": "Visualización preliminar de los datos",
    "text": "Visualización preliminar de los datos\nGráfico de caja\n\n\n\n\n\n\n\n\nEstadísticas descriptivas"
  },
  {
    "objectID": "docs/80-comparar-2medias.html#prueba-de-normalidad",
    "href": "docs/80-comparar-2medias.html#prueba-de-normalidad",
    "title": "Comparar media de dos grupos independientes con t-test en R",
    "section": "Prueba de normalidad",
    "text": "Prueba de normalidad\nPrueba de Shapiro-Wilk\n\nHipótesis nula: los datos siguen una distribución normal.\nHipótesis alternativa: los datos no siguen una distribución normal.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEn ambos casos, el p-value es mayor que el nivel de significancia 0.05, lo que indica que los datos no son significativamente diferentes de una distribución normal."
  },
  {
    "objectID": "docs/80-comparar-2medias.html#prueba-de-homogeneidad-de-varianzas",
    "href": "docs/80-comparar-2medias.html#prueba-de-homogeneidad-de-varianzas",
    "title": "Comparar media de dos grupos independientes con t-test en R",
    "section": "Prueba de homogeneidad de varianzas",
    "text": "Prueba de homogeneidad de varianzas\n\nPodemos usar la prueba F para probar la homogeneidad de varianzas con la función var.test().\n\\(H_0\\): Las varianzas de los dos grupos son iguales.\n\\(H_1\\): Las varianzas de los dos grupos son diferentes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo hay evidencia significativa para rechazar la hipótesis nula de igualdad de varianzas.\nPor lo tanto, podemos usar la prueba t clásica que asume igualdad de varianzas.\nEn caso que las varianzas no fueran iguales, se recomienda usar la prueba t de Welch. Para esto, solo necesitas cambiar el argumento var.equal = FALSE en la función t.test()."
  },
  {
    "objectID": "docs/80-comparar-2medias.html#prueba-de-t-de-student",
    "href": "docs/80-comparar-2medias.html#prueba-de-t-de-student",
    "title": "Comparar media de dos grupos independientes con t-test en R",
    "section": "Prueba de t de Student",
    "text": "Prueba de t de Student\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEl valor p de la prueba es 0.01327, que es menor que el nivel de significancia alpha = 0.05.\nPor lo tanto, podemos concluir que la media de peso de los hombres es significativamente diferente de la de las mujeres con un valor p = 0.01327."
  },
  {
    "objectID": "docs/80-comparar-2medias.html#gráfico-para-visualizar-la-diferencia-de-medias-y-la-prueba-estadística",
    "href": "docs/80-comparar-2medias.html#gráfico-para-visualizar-la-diferencia-de-medias-y-la-prueba-estadística",
    "title": "Comparar media de dos grupos independientes con t-test en R",
    "section": "Gráfico para visualizar la diferencia de medias y la prueba estadística",
    "text": "Gráfico para visualizar la diferencia de medias y la prueba estadística\n\n\n\n\n\n\nPodemos visualizar la diferencia de medias y la prueba estadística en un gráfico de caja.\nOJO. El gráfico de ggpubr redondea el valor de la prueba de t a 3 decimales, mientras que la función t.test() devuelve un valor más preciso.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpción 2 - Con gráficos de barras y Error Estándar de la Media"
  },
  {
    "objectID": "docs/78-visualizacion-anova-python.html",
    "href": "docs/78-visualizacion-anova-python.html",
    "title": "Visualización de Resultados de ANOVA en Python",
    "section": "",
    "text": "En el análisis de datos, las visualizaciones son herramientas cruciales para comunicar hallazgos y patrones. Sin embargo, es fácil caer en trampas que resultan en gráficos engañosos o confusos. A continuación, describimos algunas de las prácticas recomendadas para evitar errores comunes al visualizar los resultados de un ANOVA.\n\n\nLos gráficos de barras son muy comunes, pero no son la mejor opción para mostrar la separación de medias entre diferentes grupos. El problema principal es que los gráficos de barras ocultan información crucial sobre la distribución y dispersión de los datos.\nProblemas de los gráficos de barras:\n\nOcultan la variabilidad: Solo muestran la media (y a veces el error estándar), pero no cómo se distribuyen los datos dentro de cada grupo.\nPueden ser engañosos: Dos grupos pueden tener la misma media pero distribuciones muy diferentes (por ejemplo, uno con datos muy agrupados y otro con datos muy dispersos). Un gráfico de barras los haría parecer idénticos.\n\nPara ejemplificar esto, vamos a simular dos grupos de datos. Ambos tendrán la misma media, pero uno tendrá una variabilidad mucho mayor que el otro.\n\n\nPrimero, cargamos las librerías y creamos los datos.\n\n\n\n\n\n\n\n\nAhora, creemos un gráfico de barras con barras de error (error estándar).\n\n\n\n\n\n\n\n\nComo puedes observar, el gráfico de barras da la ilusión de que los dos grupos son muy similares, ya que sus medias son casi idénticas. Sin embargo, esto oculta la gran diferencia en la dispersión de los datos.\n\n\n\n\nPara obtener una visión más completa y honesta de los datos, es mejor utilizar gráficos que muestren la distribución.\n\n\nMuestra cada observación individual. Es excelente para ver la distribución real, la densidad y los posibles valores atípicos.\n\n\n\n\n\n\n\n\nAquí es evidente que el Grupo B tiene una dispersión mucho mayor que el Grupo A.\n\n\n\nMuestra la mediana, los cuartiles y los valores atípicos. Es una forma estandarizada de ver la dispersión y la simetría de los datos.\n\n\n\n\n\n\n\n\nEl box plot muestra claramente que la caja del Grupo B es mucho más grande, indicando una mayor variabilidad (rango intercuartílico).\n\n\n\nCombina un box plot con una estimación de la densidad del kernel (la forma de la distribución). Es quizás la mejor opción, ya que muestra la mediana, los cuartiles y la forma completa de la distribución de los datos.\n\n\n\n\n\n\n\n\nEl gráfico de violín muestra no solo que el Grupo B es más disperso, sino también la forma de su distribución (más ancha).\n\n\n\n\nPara visualizar los resultados de un ANOVA y comparar grupos, evita los gráficos de barras. En su lugar, utiliza gráficos de cajas, de violín o de puntos para proporcionar una representación más completa y honesta de tus datos, permitiendo una mejor interpretación de las diferencias y similitudes entre los grupos."
  },
  {
    "objectID": "docs/78-visualizacion-anova-python.html#mejores-prácticas-para-la-visualización-de-datos",
    "href": "docs/78-visualizacion-anova-python.html#mejores-prácticas-para-la-visualización-de-datos",
    "title": "Visualización de Resultados de ANOVA en Python",
    "section": "",
    "text": "En el análisis de datos, las visualizaciones son herramientas cruciales para comunicar hallazgos y patrones. Sin embargo, es fácil caer en trampas que resultan en gráficos engañosos o confusos. A continuación, describimos algunas de las prácticas recomendadas para evitar errores comunes al visualizar los resultados de un ANOVA.\n\n\nLos gráficos de barras son muy comunes, pero no son la mejor opción para mostrar la separación de medias entre diferentes grupos. El problema principal es que los gráficos de barras ocultan información crucial sobre la distribución y dispersión de los datos.\nProblemas de los gráficos de barras:\n\nOcultan la variabilidad: Solo muestran la media (y a veces el error estándar), pero no cómo se distribuyen los datos dentro de cada grupo.\nPueden ser engañosos: Dos grupos pueden tener la misma media pero distribuciones muy diferentes (por ejemplo, uno con datos muy agrupados y otro con datos muy dispersos). Un gráfico de barras los haría parecer idénticos.\n\nPara ejemplificar esto, vamos a simular dos grupos de datos. Ambos tendrán la misma media, pero uno tendrá una variabilidad mucho mayor que el otro.\n\n\nPrimero, cargamos las librerías y creamos los datos.\n\n\n\n\n\n\n\n\nAhora, creemos un gráfico de barras con barras de error (error estándar).\n\n\n\n\n\n\n\n\nComo puedes observar, el gráfico de barras da la ilusión de que los dos grupos son muy similares, ya que sus medias son casi idénticas. Sin embargo, esto oculta la gran diferencia en la dispersión de los datos.\n\n\n\n\nPara obtener una visión más completa y honesta de los datos, es mejor utilizar gráficos que muestren la distribución.\n\n\nMuestra cada observación individual. Es excelente para ver la distribución real, la densidad y los posibles valores atípicos.\n\n\n\n\n\n\n\n\nAquí es evidente que el Grupo B tiene una dispersión mucho mayor que el Grupo A.\n\n\n\nMuestra la mediana, los cuartiles y los valores atípicos. Es una forma estandarizada de ver la dispersión y la simetría de los datos.\n\n\n\n\n\n\n\n\nEl box plot muestra claramente que la caja del Grupo B es mucho más grande, indicando una mayor variabilidad (rango intercuartílico).\n\n\n\nCombina un box plot con una estimación de la densidad del kernel (la forma de la distribución). Es quizás la mejor opción, ya que muestra la mediana, los cuartiles y la forma completa de la distribución de los datos.\n\n\n\n\n\n\n\n\nEl gráfico de violín muestra no solo que el Grupo B es más disperso, sino también la forma de su distribución (más ancha).\n\n\n\n\nPara visualizar los resultados de un ANOVA y comparar grupos, evita los gráficos de barras. En su lugar, utiliza gráficos de cajas, de violín o de puntos para proporcionar una representación más completa y honesta de tus datos, permitiendo una mejor interpretación de las diferencias y similitudes entre los grupos."
  },
  {
    "objectID": "docs/31.r-visualizacion-datoslIl.html#diferentes-gráficos-código-muy-similar",
    "href": "docs/31.r-visualizacion-datoslIl.html#diferentes-gráficos-código-muy-similar",
    "title": "Ejercicio II Visualización y Distribución de Datos",
    "section": "Diferentes gráficos, código muy similar",
    "text": "Diferentes gráficos, código muy similar\n\nObserva cómo el código para diferentes tipos de gráficos es muy similar.\nPara mostrar esto usaremos los datos de gapminder y el dataset Argentina que ya hemos cargado por ti.\nObserva el código que usamos para generar el gráfico de dispersión, el gráfico de líneas y el gráfico de barras."
  },
  {
    "objectID": "docs/31.r-visualizacion-datoslIl.html#más-ejemplos",
    "href": "docs/31.r-visualizacion-datoslIl.html#más-ejemplos",
    "title": "Ejercicio II Visualización y Distribución de Datos",
    "section": "Más ejemplos",
    "text": "Más ejemplos\n\nEn los siguientes ejemplos vamos a utilizar disintos paquetes de R que utilizan una gramática muy similar a ggplot.\nEl objetivo es que veas cómo la gramática de los gráficos es muy similar en diferentes paquetes de R. Sin embargo, el gráfico resultante puede ser muy diferente.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEl siguiente gráfico es interactivo. Puedes pasar el cursor sobre los puntos para ver información adicional.\nObserva que la estructura del código es muy similar a la que hemos visto en ggplot, solo que en lugar de usar geom_point() usamos geom_point_interactive() y para visualizarlo, en lugar de usar plot() o print() usamos girafe(ggobj = ). El argumento tooltip es para mostrar información adicional al pasar el cursor sobre los puntos, en este caso, el modelo del auto que está en la variable model. data_id es para identificar cada punto de manera única. hover_nearest es para que al pasar el cursor sobre los puntos, se muestre la información del punto más cercano.\nVamos a usar el dataset mpg que ya viene cargado en R y corresponde a datos de consumo de combustible de diferentes autos.\n\n\n\n\n\n\n\n\n\n\nAunque el siguiente gráfico es un poco diferente, observa que la estructura del código es muy similar a la que hemos visto en ggplot.\nEn lugar de ggplot() usamos leaflet(), en lugar de geom_ usamos add_ y en lugar de aes(x, y) usamos lng y lat para las coordenadas."
  },
  {
    "objectID": "docs/31.r-visualizacion-datoslIl.html#ejercicio",
    "href": "docs/31.r-visualizacion-datoslIl.html#ejercicio",
    "title": "Ejercicio II Visualización y Distribución de Datos",
    "section": "Ejercicio",
    "text": "Ejercicio\n\nExplora este enlace y este enlace y busca algunas gráficas que te parezcan interesantes.\nIntenta reeplicar la gráfica en tu RStudio de tu computadora. Puedes usar la consola que está en la parte inferior de la página, aunque te recomiendo que lo hagas en tu RStudio para mayor compatibilidad.\nEstas páginas vienen con el código necesario para replicar las gráficas.\nIntenta modificar los datos y los atributos visuales para ver cómo cambia la gráfica.\nElige alguna gráfica que tenga un codigo facil de entender con la gramática de ggplot que hemos visto en este módulo.\nEl objetivo es que veas que con lo poco que hemos visto en este módulo, puedes crear gráficas muy interesantes y complejas gracias a que se tiende a seguir una gramática muy similar en diferentes paquetes de R.\nComo verás, hay paquetes muy especializados que te permiten crear gráficas muy interesantes y complejas para tu área de estudio."
  },
  {
    "objectID": "docs/33-intervalos-confianza-python.html",
    "href": "docs/33-intervalos-confianza-python.html",
    "title": "Intervalos de Confianza con Python",
    "section": "",
    "text": "Los intervalos de confianza son rangos que proporcionan una estimación del grado de incertidumbre alrededor de un estadístico de muestra, como la media o una proporción. Nos indican el rango dentro del cual es probable que se encuentre el parámetro real de la población con un cierto nivel de confianza (habitualmente el 95%)."
  },
  {
    "objectID": "docs/33-intervalos-confianza-python.html#introducción",
    "href": "docs/33-intervalos-confianza-python.html#introducción",
    "title": "Intervalos de Confianza con Python",
    "section": "",
    "text": "Los intervalos de confianza son rangos que proporcionan una estimación del grado de incertidumbre alrededor de un estadístico de muestra, como la media o una proporción. Nos indican el rango dentro del cual es probable que se encuentre el parámetro real de la población con un cierto nivel de confianza (habitualmente el 95%)."
  },
  {
    "objectID": "docs/33-intervalos-confianza-python.html#conceptos-clave",
    "href": "docs/33-intervalos-confianza-python.html#conceptos-clave",
    "title": "Intervalos de Confianza con Python",
    "section": "Conceptos Clave",
    "text": "Conceptos Clave\n\nIntervalo de Confianza para la Media: Proporciona un rango probable para la verdadera media de la población. A menudo calculado usando la media muestral, la desviación estándar de la muestra, y el tamaño de la muestra.\nIntervalo de Confianza para una Proporción: Indica un rango para la verdadera proporción de la población. Calculado utilizando la proporción muestral, el tamaño de la muestra, y un estadístico z de la distribución normal estándar.\nInterpretación: Un intervalo de confianza del 95% significa que si se toman 100 muestras diferentes y se calculan 100 intervalos, aproximadamente 95 de esos intervalos deberían contener la verdadera media o proporción de la población."
  },
  {
    "objectID": "docs/33-intervalos-confianza-python.html#ejercicio-práctico-en-python",
    "href": "docs/33-intervalos-confianza-python.html#ejercicio-práctico-en-python",
    "title": "Intervalos de Confianza con Python",
    "section": "Ejercicio Práctico en Python",
    "text": "Ejercicio Práctico en Python\nExploraremos cómo calcular intervalos de confianza para la media utilizando un conjunto de datos simulado."
  },
  {
    "objectID": "docs/33-intervalos-confianza-python.html#reflexión-y-discusión",
    "href": "docs/33-intervalos-confianza-python.html#reflexión-y-discusión",
    "title": "Intervalos de Confianza con Python",
    "section": "Reflexión y Discusión:",
    "text": "Reflexión y Discusión:\n\nExaminar el intervalo de confianza calculado: ¿Qué significa en el contexto de estos datos de altura?\nDiscute cómo el tamaño de la muestra afecta la amplitud del intervalo de confianza. ¿Qué sucedería si tuvieras una muestra más grande o más pequeña?\n\nEsta lección ofrece un enfoque práctico sobre cómo calcular e interpretar intervalos de confianza en Python. Con estas habilidades, podrás cuantificar la incertidumbre y comunicar tus resultados con mayor claridad y precisión."
  },
  {
    "objectID": "docs/84-comparar-2medias-python.html",
    "href": "docs/84-comparar-2medias-python.html",
    "title": "Comparar medias de dos grupos independientes con t-test en Python",
    "section": "",
    "text": "Muestra independiente: Las muestras son independientes si las observaciones en un grupo no están relacionadas con las observaciones en el otro grupo. Por ejemplo, si se mide el peso de dos grupos diferentes de personas (placebo vs tratamiento), los datos de un grupo no están relacionados con los datos del otro grupo.\nMuestra pareada o emparejada: Las muestras son pareadas si las observaciones en un grupo están relacionadas con las observaciones en el otro grupo. Por ejemplo, si se mide el peso de las mismas personas antes y después de un tratamiento, los datos están relacionados.\nEn esta lección nos enfocaremos en muestras independientes."
  },
  {
    "objectID": "docs/84-comparar-2medias-python.html#introducción-a-las-muestras-independientes-vs-pareadas",
    "href": "docs/84-comparar-2medias-python.html#introducción-a-las-muestras-independientes-vs-pareadas",
    "title": "Comparar medias de dos grupos independientes con t-test en Python",
    "section": "",
    "text": "Muestra independiente: Las muestras son independientes si las observaciones en un grupo no están relacionadas con las observaciones en el otro grupo. Por ejemplo, si se mide el peso de dos grupos diferentes de personas (placebo vs tratamiento), los datos de un grupo no están relacionados con los datos del otro grupo.\nMuestra pareada o emparejada: Las muestras son pareadas si las observaciones en un grupo están relacionadas con las observaciones en el otro grupo. Por ejemplo, si se mide el peso de las mismas personas antes y después de un tratamiento, los datos están relacionados.\nEn esta lección nos enfocaremos en muestras independientes."
  },
  {
    "objectID": "docs/84-comparar-2medias-python.html#ejemplo-práctico",
    "href": "docs/84-comparar-2medias-python.html#ejemplo-práctico",
    "title": "Comparar medias de dos grupos independientes con t-test en Python",
    "section": "Ejemplo Práctico",
    "text": "Ejemplo Práctico\nVamos a trabajar con datos simulados. Tenemos las medidas de peso de dos grupos: mujeres (grupo A) y hombres (grupo B). Queremos saber si la media de peso de las mujeres es significativamente diferente de la de los hombres.\n\n1. Cargar librerías y crear datos\n\n\n\n\n\n\n\n\n\n\nCondiciones para usar la prueba t de dos muestras independientes\n\nLas dos muestras deben ser independientes: Esto lo verificamos al diseñar el estudio.\nLas muestras deben seguir una distribución normal: Se puede verificar con la prueba de Shapiro-Wilk.\nLas varianzas deben ser iguales (homocedasticidad): Se puede verificar con la prueba de Levene."
  },
  {
    "objectID": "docs/84-comparar-2medias-python.html#hipótesis-de-investigación",
    "href": "docs/84-comparar-2medias-python.html#hipótesis-de-investigación",
    "title": "Comparar medias de dos grupos independientes con t-test en Python",
    "section": "Hipótesis de Investigación",
    "text": "Hipótesis de Investigación\n\nH₀: La media de peso de las mujeres es igual a la media de peso de los hombres.\nH₁: La media de peso de las mujeres es diferente de la media de peso de los hombres."
  },
  {
    "objectID": "docs/84-comparar-2medias-python.html#visualización-preliminar-de-los-datos",
    "href": "docs/84-comparar-2medias-python.html#visualización-preliminar-de-los-datos",
    "title": "Comparar medias de dos grupos independientes con t-test en Python",
    "section": "Visualización Preliminar de los Datos",
    "text": "Visualización Preliminar de los Datos\n\nGráfico de cajas\n\n\n\n\n\n\n\n\n\n\nEstadísticas descriptivas"
  },
  {
    "objectID": "docs/84-comparar-2medias-python.html#verificación-de-supuestos",
    "href": "docs/84-comparar-2medias-python.html#verificación-de-supuestos",
    "title": "Comparar medias de dos grupos independientes con t-test en Python",
    "section": "Verificación de Supuestos",
    "text": "Verificación de Supuestos\n\n1. Prueba de Normalidad (Shapiro-Wilk)\nHipótesis: - H₀: Los datos siguen una distribución normal - H₁: Los datos no siguen una distribución normal\n\n\n\n\n\n\n\n\nInterpretación: En ambos casos, el p-valor es mayor que 0.05, por lo que no rechazamos la hipótesis nula. Los datos no son significativamente diferentes de una distribución normal.\n\n\n2. Prueba de Homogeneidad de Varianzas (Levene)\nHipótesis: - H₀: Las varianzas de los dos grupos son iguales - H₁: Las varianzas de los dos grupos son diferentes"
  },
  {
    "objectID": "docs/84-comparar-2medias-python.html#prueba-t-de-student",
    "href": "docs/84-comparar-2medias-python.html#prueba-t-de-student",
    "title": "Comparar medias de dos grupos independientes con t-test en Python",
    "section": "Prueba t de Student",
    "text": "Prueba t de Student\n\n\n\n\n\n\n\n\n\nInterpretación de Resultados"
  },
  {
    "objectID": "docs/84-comparar-2medias-python.html#visualización-de-resultados",
    "href": "docs/84-comparar-2medias-python.html#visualización-de-resultados",
    "title": "Comparar medias de dos grupos independientes con t-test en Python",
    "section": "Visualización de Resultados",
    "text": "Visualización de Resultados\n\nGráfico con estadísticas"
  },
  {
    "objectID": "docs/84-comparar-2medias-python.html#prueba-t-de-welch-alternativa-cuando-las-varianzas-son-diferentes",
    "href": "docs/84-comparar-2medias-python.html#prueba-t-de-welch-alternativa-cuando-las-varianzas-son-diferentes",
    "title": "Comparar medias de dos grupos independientes con t-test en Python",
    "section": "Prueba t de Welch (alternativa cuando las varianzas son diferentes)",
    "text": "Prueba t de Welch (alternativa cuando las varianzas son diferentes)\nSi las varianzas no fueran iguales, usaríamos la prueba t de Welch:"
  },
  {
    "objectID": "docs/84-comparar-2medias-python.html#tamaño-del-efecto-cohens-d",
    "href": "docs/84-comparar-2medias-python.html#tamaño-del-efecto-cohens-d",
    "title": "Comparar medias de dos grupos independientes con t-test en Python",
    "section": "Tamaño del Efecto (Cohen’s d)",
    "text": "Tamaño del Efecto (Cohen’s d)\nEl tamaño del efecto nos dice qué tan grande es la diferencia práctica entre los grupos:"
  },
  {
    "objectID": "docs/84-comparar-2medias-python.html#resumen-de-la-metodología",
    "href": "docs/84-comparar-2medias-python.html#resumen-de-la-metodología",
    "title": "Comparar medias de dos grupos independientes con t-test en Python",
    "section": "Resumen de la Metodología",
    "text": "Resumen de la Metodología\n\nVerificar supuestos: Normalidad (Shapiro-Wilk) y homogeneidad de varianzas (Levene)\nElegir la prueba apropiada: t-test clásica (varianzas iguales) vs t-test de Welch (varianzas diferentes)\nInterpretar resultados: p-valor, diferencia de medias, intervalo de confianza\nEvaluar significancia práctica: Tamaño del efecto (Cohen’s d)\nVisualizar resultados: Gráficos que muestren tanto la distribución como las estadísticas"
  },
  {
    "objectID": "docs/70-c-pruebas-hipotesis.html",
    "href": "docs/70-c-pruebas-hipotesis.html",
    "title": "Pruebas de Hipótesis Estadísticas",
    "section": "",
    "text": "En el curso, hemos discutido un componente de la inferencia estadística, que es la estimación de parámetros poblacionales. También introdujimos las diferencias filosóficas y estadísticas entre los enfoques frecuentista y bayesiano para la estimación de parámetros. El otro componente principal de la inferencia estadística, que ha dominado la aplicación de la estadística en las ciencias biológicas, es la prueba de hipótesis sobre esos parámetros.\nGran parte de la justificación filosófica para el uso continuo de las pruebas estadísticas de hipótesis parece basarse en las propuestas de Popper sobre las pruebas falsificacionistas de hipótesis. Aunque Jerzy Neyman, Egon Pearson y Sir Ronald Fisher desarrollaron sus enfoques para las pruebas estadísticas en la década de 1930, es interesante notar que Popper no consideró formalmente las pruebas estadísticas como un mecanismo para falsificar hipótesis. Hilborn & Mangel (1997) mencionaron que “Popper proporcionó la filosofía y Fisher, Pearson y sus colegas proporcionaron la estadística”."
  },
  {
    "objectID": "docs/70-c-pruebas-hipotesis.html#pruebas-de-hipótesis-estadísticas",
    "href": "docs/70-c-pruebas-hipotesis.html#pruebas-de-hipótesis-estadísticas",
    "title": "Pruebas de Hipótesis Estadísticas",
    "section": "",
    "text": "En el curso, hemos discutido un componente de la inferencia estadística, que es la estimación de parámetros poblacionales. También introdujimos las diferencias filosóficas y estadísticas entre los enfoques frecuentista y bayesiano para la estimación de parámetros. El otro componente principal de la inferencia estadística, que ha dominado la aplicación de la estadística en las ciencias biológicas, es la prueba de hipótesis sobre esos parámetros.\nGran parte de la justificación filosófica para el uso continuo de las pruebas estadísticas de hipótesis parece basarse en las propuestas de Popper sobre las pruebas falsificacionistas de hipótesis. Aunque Jerzy Neyman, Egon Pearson y Sir Ronald Fisher desarrollaron sus enfoques para las pruebas estadísticas en la década de 1930, es interesante notar que Popper no consideró formalmente las pruebas estadísticas como un mecanismo para falsificar hipótesis. Hilborn & Mangel (1997) mencionaron que “Popper proporcionó la filosofía y Fisher, Pearson y sus colegas proporcionaron la estadística”."
  },
  {
    "objectID": "docs/70-c-pruebas-hipotesis.html#pruebas-clásicas-de-hipótesis-estadísticas",
    "href": "docs/70-c-pruebas-hipotesis.html#pruebas-clásicas-de-hipótesis-estadísticas",
    "title": "Pruebas de Hipótesis Estadísticas",
    "section": "Pruebas Clásicas de Hipótesis Estadísticas",
    "text": "Pruebas Clásicas de Hipótesis Estadísticas\nLas pruebas clásicas de hipótesis estadísticas se apoyan en dos conceptos básicos:\n\n1. Hipótesis Nula (\\(H_0\\))\nPrimero, debemos establecer una hipótesis nula (\\(H_0\\)). Esta hipótesis generalmente (aunque no necesariamente) representa la ausencia de un efecto o una relación entre los parámetros poblacionales. Por ejemplo, la hipótesis nula podría ser que no hay diferencia entre las medias de dos poblaciones.\nEn muchos casos, se usa el término “efecto” para describir una diferencia entre grupos o tratamientos experimentales (o una pendiente de regresión no nula, etc.), por lo que el (\\(H_0\\)) suele ser una hipótesis de no efecto.\nEl fundamento filosófico de la hipótesis nula se relaciona, al menos en parte, con el falsificacionismo popperiano, donde el progreso científico se logra al someter las hipótesis a pruebas rigurosas y falsificarlas. La implicación es que rechazar el (\\(H_0\\)) es equivalente a falsificarlo y, por lo tanto, proporciona apoyo (o “corroboración”) para la hipótesis de investigación como la única alternativa plausible. Sin embargo, no probamos la hipótesis de investigación directamente, porque rara vez es más exacta que simplemente postular un efecto (a veces en una dirección particular).\n\n\n2. Estadístico de Prueba\nEn segundo lugar, debemos elegir un estadístico de prueba para evaluar la \\(H_0\\). Un estadístico de prueba es una variable aleatoria que puede describirse mediante una distribución de probabilidad. Por ejemplo, un estadístico comúnmente utilizado para probar hipótesis sobre las medias poblacionales es el estadístico t.\nEl estadístico de prueba nos permite calcular un valor p, que es la probabilidad de observar un valor tan extremo (o más extremo) que el observado, bajo la suposición de que la hipótesis nula es verdadera. Si el valor p es menor que un nivel de significancia predefinido (generalmente \\(\\alpha = 0.05\\)), rechazamos la hipótesis nula en favor de la hipótesis alternativa.\n\n\n\n\n\n\nQué es el valor p\n\n\n\n\nEl valor p es la probabilidad de observar un resultado al menos tan extremo como el resultado observado, bajo la suposición de que la hipótesis nula es verdadera.\nEn otras palabras, mide la evidencia en contra de la hipótesis nula. - Un valor p pequeño indica que los datos observados son poco consistentes con la hipótesis nula.\n\nValor p bajo: Si el valor p es bajo (por ejemplo, menor que 0.05), se considera que hay evidencia suficiente para rechazar la hipótesis nula.\nValor p alto: Un valor p alto sugiere que los datos son consistentes con la hipótesis nula, y no se tiene suficiente evidencia para rechazarla.\n\n\n\n\nUso en Estadísticos de Prueba\n\nCuando realizas una prueba estadística (como una prueba t, ANOVA, o chi-cuadrado), calculas un estadístico de prueba basado en tus datos.\nA partir de este estadístico de prueba determinar el valor p.\nLos valores p se utilizan frecuentemente para decir que un resultado es “estadísticamente significativo” si el valor p es menor que un nivel de significancia predefinido (como \\(\\alpha = 0.05\\)).\nLa significancia estadística es otra forma de decir que los resultados son poco probables de haber ocurrido por azar si la hipótesis nula es verdadera.\nLa significancia estadística no es lo mismo que la importancia práctica o biológica. Un resultado puede ser estadísticamente significativo, pero no necesariamente importante desde un punto de vista práctico.\n\n\n\n¿Por qué 0.05?\nConvención Histórica de \\(\\alpha = 0.05\\)\n\nEl nivel de significancia \\(\\alpha = 0.05\\) se ha convertido en un estándar en muchas disciplinas científicas debido a su uso temprano y adopción por estadísticos influyentes como Ronald Fisher.\nRepresenta un compromiso razonable entre el riesgo de cometer un error de Tipo I (rechazar \\(H_0\\) cuando es verdadera) y la necesidad de detectar un efecto verdadero.\n\nError tipo I: Rechazar la hipótesis nula cuando es verdadera. Por ejemplo, concluir que un tratamiento es efectivo cuando no lo es.\nError tipo II: No rechazar la hipótesis nula cuando es falsa. Por ejemplo, no detectar un tratamiento efectivo cuando realmente lo es.\n\nAunque \\(0.05\\) es común, no es un estándar rígido. Dependiendo del contexto, los investigadores pueden usar niveles de significancia más estrictos (como \\(0.01\\)) o más laxos (como $0.10), especialmente si las consecuencias de cometer errores son más o menos severas.\nUsar \\(\\alpha = 0.05\\) significa que aceptamos un 5% de probabilidad de cometer un error de Tipo I. Esto es considerado un nivel aceptable de riesgo en muchos campos, aunque siempre se debe considerar el contexto específico del estudio.\nEste \\(\\alpha = 0.05\\) puede distribuirse en dos colas (0.025 en cada cola) o en una cola (0.05 en una cola). Esto depende de la naturaleza de la hipótesis de investigación y el diseño del estudio. Normalmente, las pruebas de dos colas se utilizan cuando se espera una diferencia en cualquier dirección, mientras que las pruebas de una cola se utilizan cuando se espera una diferencia en una dirección específica (por ejemplo, un tratamiento va a producir un efecto positivo y no esperas que sea negativo)."
  },
  {
    "objectID": "docs/70-c-pruebas-hipotesis.html#uso-en-estadísticos-de-prueba",
    "href": "docs/70-c-pruebas-hipotesis.html#uso-en-estadísticos-de-prueba",
    "title": "Pruebas de Hipótesis Estadísticas",
    "section": "Uso en Estadísticos de Prueba",
    "text": "Uso en Estadísticos de Prueba\n\nCuando realizas una prueba estadística (como una prueba t, ANOVA, o chi-cuadrado), calculas un estadístico de prueba basado en tus datos.\nA partir de este estadístico de prueba determinar el valor p.\nLos valores p se utilizan frecuentemente para decir que un resultado es “estadísticamente significativo” si el valor p es menor que un nivel de significancia predefinido (como \\(\\alpha = 0.05\\)).\nLa significancia estadística es otra forma de decir que los resultados son poco probables de haber ocurrido por azar si la hipótesis nula es verdadera.\nLa significancia estadística no es lo mismo que la importancia práctica o biológica. Un resultado puede ser estadísticamente significativo, pero no necesariamente importante desde un punto de vista práctico."
  },
  {
    "objectID": "docs/70-c-pruebas-hipotesis.html#por-qué-0.05",
    "href": "docs/70-c-pruebas-hipotesis.html#por-qué-0.05",
    "title": "Pruebas de Hipótesis Estadísticas",
    "section": "¿Por qué 0.05?",
    "text": "¿Por qué 0.05?\nConvención Histórica de \\(\\alpha = 0.05\\)\n\nEl nivel de significancia \\(\\alpha = 0.05\\) se ha convertido en un estándar en muchas disciplinas científicas debido a su uso temprano y adopción por estadísticos influyentes como Ronald Fisher.\nRepresenta un compromiso razonable entre el riesgo de cometer un error de Tipo I (rechazar \\(H_0\\) cuando es verdadera) y la necesidad de detectar un efecto verdadero.\n\nError tipo I: Rechazar la hipótesis nula cuando es verdadera. Por ejemplo, concluir que un tratamiento es efectivo cuando no lo es.\nError tipo II: No rechazar la hipótesis nula cuando es falsa. Por ejemplo, no detectar un tratamiento efectivo cuando realmente lo es.\n\nAunque \\(0.05\\) es común, no es un estándar rígido. Dependiendo del contexto, los investigadores pueden usar niveles de significancia más estrictos (como \\(0.01\\)) o más laxos (como $0.10), especialmente si las consecuencias de cometer errores son más o menos severas.\nUsar \\(\\alpha = 0.05\\) significa que aceptamos un 5% de probabilidad de cometer un error de Tipo I. Esto es considerado un nivel aceptable de riesgo en muchos campos, aunque siempre se debe considerar el contexto específico del estudio.\nEste \\(\\alpha = 0.05\\) puede distribuirse en dos colas (0.025 en cada cola) o en una cola (0.05 en una cola). Esto depende de la naturaleza de la hipótesis de investigación y el diseño del estudio. Normalmente, las pruebas de dos colas se utilizan cuando se espera una diferencia en cualquier dirección, mientras que las pruebas de una cola se utilizan cuando se espera una diferencia en una dirección específica (por ejemplo, un tratamiento va a producir un efecto positivo y no esperas que sea negativo)."
  },
  {
    "objectID": "docs/70-c-pruebas-hipotesis.html#ejemplo-en-r-prueba-de-hipótesis-prueba-t-de-dos-muestras",
    "href": "docs/70-c-pruebas-hipotesis.html#ejemplo-en-r-prueba-de-hipótesis-prueba-t-de-dos-muestras",
    "title": "Pruebas de Hipótesis Estadísticas",
    "section": "Ejemplo en R: Prueba de Hipótesis (Prueba t de dos muestras)",
    "text": "Ejemplo en R: Prueba de Hipótesis (Prueba t de dos muestras)\n\nPara que todo quede más claro, vamos a ver un ejemplo práctico de cómo realizar una prueba de hipótesis en R.\nSupongamos que queremos probar si existe una diferencia significativa entre las medias de dos grupos (por ejemplo, dos tratamientos diferentes en un experimento biológico). Utilizaremos una prueba t de dos muestras para este propósito.\n\n\n1. Generar los datos\n\n\n\n\n\n\n\n\nAquí, hemos generado dos grupos con medias diferentes (grupo A con media 5 y grupo B con media 6) y una desviación estándar de 1.\n\n\n2. Visualización preliminar de los datos\nAntes de realizar la prueba, es útil visualizar los datos para observar las diferencias entre los grupos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nel boxplot nos indica que el grupo B tiene 2 outliers (los puntos que se observan fuera de los límites de la caja), lo que puede afectar la prueba de hipótesis. En la práctica, es importante considerar cómo manejar los valores atípicos y si deben ser excluidos o tratados de manera diferente. Por el momento, los dejaremos tal como están para ilustrar el proceso de prueba de hipótesis.\n\n\n\n\n3. Realizar la prueba t de dos muestras\nAhora realizamos la prueba t de dos muestras para ver si la diferencia entre las medias es estadísticamente significativa.\n\n\n\n\n\n\n\n\nEl resultado de la prueba t incluye:\n\nEl valor t, que es el estadístico de prueba. Este valor se compara con una distribución t para determinar la significancia estadística. R hace esto automáticamente y proporciona el valor p asociado.\nEl valor p, que indica la probabilidad de observar una diferencia tan grande o mayor entre las medias bajo la hipótesis nula.\nEl intervalo de confianza para la diferencia de medias.\nLa decisión sobre si rechazar \\(H_0\\) o no, basada en el valor p y el nivel de significancia.\n\n\n\nInterpretación de los resultados\n\nSi el valor p es menor que el nivel de significancia (\\(\\alpha = 0.05\\)), rechazamos la hipótesis nula y concluimos que hay una diferencia significativa entre las medias de los dos grupos.\nSi el valor p es mayor que \\(\\alpha = 0.05\\), no tenemos suficiente evidencia para rechazar la hipótesis nula, lo que implica que no podemos concluir que existe una diferencia significativa entre los grupos.\n\n\n\nCómo reportar los resultados\n\nAl reportar los resultados de una prueba de hipótesis, es importante incluir el valor p, el estadístico de prueba y el intervalo de confianza. Después del estadístico de prueba, se ponen los grados de libertad entre paréntesis.\n\nt(grados.libertad) = estadístico, p = valor_p\n\nTambién es útil proporcionar una interpretación de los resultados en términos del problema de investigación y las implicaciones prácticas.\nPor ejemplo, podríamos decir: “Se encontró una diferencia significativa entre las medias de los grupos A y B (\\(t(97) = -6.0718, p &lt; 0.0001\\)), lo que sugiere que el tratamiento B es más efectivo que el tratamiento A”.\n\n\n\nValor p y Niveles de Significancia\n\nBasado en el ejemplo anterior, vamos a ver de dónde viene el valor p y cómo se relaciona con los niveles de significancia.\nComo ya viste, calculamos el valor p de la prueba sin mucho esfuerzo. vamos a calcularlo y visualizarlo manualmente para entenderlo mejor, aunque normalmente no es necesario hacerlo en la práctica.\nPrimero, a partir de la prueba t, obtenemos el valor p y los grados de libertad asociados.\nLa forma de la distribución t depende de los grados de libertad (df). A medida que df aumenta, la distribución t se aproxima a la distribución normal estándar.\n\n\n\n\n\n\n\n\n\n\nAhora, vamos a visualizar la distribución t con los grados de libertad obtenidos y marcar el estadístico t observado. También sombrearemos las áreas de las colas que corresponden al valor p.\n\nRecuerda en la clase de distribuciones de probabilidad que hablamos de distribuciones de probabilidad que se utilizan para distintos tipos de pruebas estadísticas. Una de ellas es la distribución t de Student.\n\n\nCrear un data frame para la distribución t - Primero, creamos una secuencia de valores de t y calculamos la densidad de la distribución t para cada valor de t. - Calculamos la densidad de la distribución t para cada uno de estos valores usando la función dt(), que es la función de densidad de la distribución t. - La función dt() toma dos argumentos: el valor de t y los grados de libertad (df) de la distribución t. - La función de densidad de probabilidad (PDF, por sus siglas en inglés) describe la probabilidad relativa de que una variable aleatoria continua tome un valor específico. - Recuerda que vimos un poco de las funciones de densidad de probabilidad en la clase de distribuciones de probabilidad. - Al graficar la función de densidad, podemos ver dónde se concentra la mayor parte de la probabilidad. - En el contexto de pruebas de hipótesis, nos ayuda a entender dónde se ubica nuestro estadístico de prueba en relación con la distribución nula.\n\n\n\n\n\n\nTip\n\n\n\nAnalogía: Piensa en la función de densidad como un mapa de elevación de una montaña.\n\nLas alturas (densidad) indican qué tan probable es encontrar valores de la variable aleatoria en ciertas regiones.\nLas áreas más altas representan valores más probables, y las áreas más bajas representan valores menos probables.\n\n\n\n\n\n\n\n\n\n\n\n\nCalcular el valor p manualmente\nPodemos calcular esta probabilidad usando la función pt() en R, que calcula la probabilidad acumulada de la distribución t.\n\n\n\n\n\n\n\nTip\n\n\n\n\nEl valor de densidad acumulada (o función de distribución acumulada, CDF por sus siglas en inglés) se usa para calcular probabilidades asociadas con nuestra variable aleatoria continua hasta un cierto punto.\nEn el contexto del cálculo del valor p, utilizamos la función de distribución acumulada para determinar la probabilidad de obtener un estadístico tan extremo como el observado bajo la hipótesis nula.\nMientras que la función de densidad nos muestra la forma de la distribución, la CDF nos proporciona probabilidades acumuladas.\n\n\n\n\n\n\n\n\n\n\n\n\nAhora, vamos a visualizar la distribución t con los grados de libertad obtenidos y marcar el estadístico t observado. También sombrearemos las áreas de las colas que corresponden al valor p.\n\n\n\n\n\n\n\n\n\n\nLa línea azul representa la densidad de la distribución t con los grados de libertad calculados.\nLas áreas sombreadas en naranja corresponden a las regiones de rechazo al nivel de significación \\(\\alpha = 0.05\\).\nLas líneas verticales punteadas en color naranja están en los valores críticos t críticos (los valores de t que marcan los límites de las regiones de rechazo).\nLas áreas sombreadas en rojo corresponden al valor p (las colas de la distribución más allá de \\(\\pm t_{\\text{observado}}\\)). ​- Las líneas verticales punteadas marcan los valores de \\(\\pm t_{\\text{observado}}\\)\n\nAl calcular el valor p manualmente y visualizarlo en el gráfico, podemos ver cómo el estadístico t observado se sitúa en las colas extremas de la distribución t, lo que indica que es poco probable obtener un valor tan extremo si la hipótesis nula es verdadera.\nPodemos ver rápidamente un caso donde el valor p es mayor que el nivel de significancia (0.05), lo que sugiere que no tenemos suficiente evidencia para rechazar la hipótesis nula. - Vamos a repetir los pasos pasados, solo cambiaremos la media del grupo B a 5.2 en lugar de 6. - Como las medias de los grupos son más cercanas, esperamos que el valor p sea mayor y no rechacemos la hipótesis nula."
  },
  {
    "objectID": "docs/70-c-pruebas-hipotesis.html#críticas-a-las-pruebas-de-hipótesis-clásicas",
    "href": "docs/70-c-pruebas-hipotesis.html#críticas-a-las-pruebas-de-hipótesis-clásicas",
    "title": "Pruebas de Hipótesis Estadísticas",
    "section": "Críticas a las pruebas de hipótesis clásicas",
    "text": "Críticas a las pruebas de hipótesis clásicas\nAunque las pruebas de hipótesis clásicas son ampliamente utilizadas, han sido objeto de crítica por varios motivos:\n\nDependencia del valor p: El valor p no mide la magnitud del efecto ni la importancia práctica de los resultados, solo indica si el efecto es estadísticamente significativo.\nDificultad en la interpretación: Rechazar \\(H_0\\) no implica necesariamente que la hipótesis de investigación sea verdadera. Puede haber muchas otras explicaciones para los resultados, y la verdadera corroboración de una hipótesis requiere más que una simple prueba de significancia.\nProblemas filosóficos: La idea de que rechazar la hipótesis nula confirma la hipótesis de investigación ha sido criticada por ser un razonamiento débil desde una perspectiva filosófica."
  },
  {
    "objectID": "docs/70-c-pruebas-hipotesis.html#conclusión",
    "href": "docs/70-c-pruebas-hipotesis.html#conclusión",
    "title": "Pruebas de Hipótesis Estadísticas",
    "section": "Conclusión",
    "text": "Conclusión\nLas pruebas de hipótesis estadísticas son una herramienta central en la inferencia estadística, especialmente en las ciencias biológicas. Sin embargo, es crucial entender tanto sus fortalezas como sus limitaciones. El enfoque clásico de pruebas de hipótesis, basado en el rechazo de la hipótesis nula, ha sido ampliamente utilizado, pero debe complementarse con una interpretación cuidadosa de los valores p, los intervalos de confianza y el contexto práctico de los resultados."
  },
  {
    "objectID": "docs/50-regresion-lineal-python.html",
    "href": "docs/50-regresion-lineal-python.html",
    "title": "Regresión Lineal Simple con Python",
    "section": "",
    "text": "La regresión lineal simple es una técnica estadística que modela la relación entre dos variables continuas mediante una ecuación lineal. Este método es útil para predecir los valores de una variable dependiente basada en los valores de una variable independiente.\nEs fundamental comprender que la mayoría de las pruebas estadísticas comunes (como la correlación, la prueba t y el ANOVA) son en realidad casos especiales de modelos lineales. Esta simplicidad subyacente significa que, en lugar de aprender muchas pruebas como herramientas independientes, podemos entenderlas a través de la ecuación fundamental ( y = _0 + _1x ). Este enfoque no solo simplifica el aprendizaje, sino que también fomenta una comprensión más profunda de las relaciones entre variables y los supuestos paramétricos que comparten estas pruebas."
  },
  {
    "objectID": "docs/50-regresion-lineal-python.html#introducción",
    "href": "docs/50-regresion-lineal-python.html#introducción",
    "title": "Regresión Lineal Simple con Python",
    "section": "",
    "text": "La regresión lineal simple es una técnica estadística que modela la relación entre dos variables continuas mediante una ecuación lineal. Este método es útil para predecir los valores de una variable dependiente basada en los valores de una variable independiente.\nEs fundamental comprender que la mayoría de las pruebas estadísticas comunes (como la correlación, la prueba t y el ANOVA) son en realidad casos especiales de modelos lineales. Esta simplicidad subyacente significa que, en lugar de aprender muchas pruebas como herramientas independientes, podemos entenderlas a través de la ecuación fundamental ( y = _0 + _1x ). Este enfoque no solo simplifica el aprendizaje, sino que también fomenta una comprensión más profunda de las relaciones entre variables y los supuestos paramétricos que comparten estas pruebas."
  },
  {
    "objectID": "docs/50-regresion-lineal-python.html#conceptos-clave",
    "href": "docs/50-regresion-lineal-python.html#conceptos-clave",
    "title": "Regresión Lineal Simple con Python",
    "section": "Conceptos Clave",
    "text": "Conceptos Clave\n\nModelo de Regresión Lineal Simple:\n\nRepresentado por la ecuación ( y = _0 + _1x + ), donde:\n( y ) es la variable dependiente (resultado).\n( x ) es la variable independiente (predictora).\n( _0 ) es la intersección (ordenada en el origen).\n( _1 ) es la pendiente del modelo.\n( ) es el término de error.\n\nInterpretación:\n\n( _1 ) indica el cambio en la variable dependiente por cada unidad de cambio en la variable independiente.\nEl objetivo es minimizar la suma de los cuadrados de las diferencias entre los valores observados y los valores predichos."
  },
  {
    "objectID": "docs/50-regresion-lineal-python.html#ejercicio-práctico-en-python",
    "href": "docs/50-regresion-lineal-python.html#ejercicio-práctico-en-python",
    "title": "Regresión Lineal Simple con Python",
    "section": "Ejercicio Práctico en Python",
    "text": "Ejercicio Práctico en Python\nVeamos cómo ajustar un modelo de regresión lineal simple utilizando un conjunto de datos simulado con numpy y statsmodels."
  },
  {
    "objectID": "docs/50-regresion-lineal-python.html#la-regresión-lineal-como-base-de-otras-pruebas-estadísticas",
    "href": "docs/50-regresion-lineal-python.html#la-regresión-lineal-como-base-de-otras-pruebas-estadísticas",
    "title": "Regresión Lineal Simple con Python",
    "section": "La Regresión Lineal como Base de Otras Pruebas Estadísticas",
    "text": "La Regresión Lineal como Base de Otras Pruebas Estadísticas\nLa belleza de los modelos lineales es que unifican muchos conceptos estadísticos que a menudo se enseñan por separado. Entender esto puede simplificar enormemente el aprendizaje de la estadística.\n\nPrueba t (t-test): Una prueba t se puede considerar un modelo lineal donde la variable independiente (x) es categórica con solo dos niveles (por ejemplo, “Grupo de Tratamiento” vs. “Grupo de Control”). El modelo predice la variable dependiente (y) basándose en el grupo al que pertenece cada observación.\nANOVA: De manera similar, un ANOVA es un modelo lineal donde la variable independiente (x) es categórica pero con más de dos niveles (o grupos). El modelo evalúa si las medias de la variable dependiente son diferentes entre estos grupos.\nCorrelación: La prueba de correlación de Pearson está directamente relacionada con la regresión lineal simple. El coeficiente de correlación (r) es una versión estandarizada de la pendiente (( _1 )) del modelo de regresión. Ambos miden la fuerza y la dirección de la relación lineal entre dos variables.\n\nAl ver estas pruebas como variantes de un modelo lineal, los supuestos subyacentes (como la normalidad de los residuos y la homogeneidad de las varianzas) se vuelven más fáciles de entender, ya que se derivan del propio modelo lineal."
  },
  {
    "objectID": "docs/50-regresion-lineal-python.html#reflexión-y-discusión",
    "href": "docs/50-regresion-lineal-python.html#reflexión-y-discusión",
    "title": "Regresión Lineal Simple con Python",
    "section": "Reflexión y Discusión",
    "text": "Reflexión y Discusión\n\nObserva la pendiente y el intercepto del modelo: ¿Qué te dicen sobre la relación entre las horas de estudio y las calificaciones?\nAnaliza cómo la línea de regresión se ajusta a los datos. ¿Qué sugiere este modelo sobre el poder predictivo de las horas de estudio respecto a las calificaciones de los estudiantes?\nPiensa en cómo podrías formular una prueba t o un ANOVA como un modelo lineal. ¿Cuál sería tu variable x y tu variable y en cada caso?\n\nEsta lección proporciona una comprensión práctica de la regresión lineal simple en Python, permitiendo a los estudiantes capturar y analizar relaciones lineales entre variables y utilizar estos modelos predictivos en escenarios del mundo real."
  },
  {
    "objectID": "docs/63-lineales-supuestos.html",
    "href": "docs/63-lineales-supuestos.html",
    "title": "Supuestos de los Modelos Lineales",
    "section": "",
    "text": "Un supuesto en estadística es una condición que debe cumplirse para que un modelo o método sea válido. Para que un modelo lineal funcione correctamente se deben cumplir estos supuestos:"
  },
  {
    "objectID": "docs/63-lineales-supuestos.html#linealidad",
    "href": "docs/63-lineales-supuestos.html#linealidad",
    "title": "Supuestos de los Modelos Lineales",
    "section": "Linealidad",
    "text": "Linealidad\nLa relación entre el predictor \\(x\\) y la variable respuesta \\(y\\) es lineal. Es decir, el cambio en \\(y\\) debido a un cambio en \\(x\\) es constante.\n\n\n\n\n\n\nLinealidad NO es lo mismo que recta\n\n\n\nLinealidad en el contexto de los modelos lineales no significa necesariamente que la relación entre las variables deba formar una línea recta en el gráfico. En lugar de referirse a la forma de la gráfica, la linealidad en los modelos lineales se refiere a cómo los parámetros (o coeficientes) del modelo se combinan con las variables predictoras. Por ejemplo, consider la siguiente ecuación de un modelo lineal:\n\\[\ny = \\beta_0 + \\beta_1 \\cdot x^4\n\\]\n\nAunque la relación entre \\(x\\) y \\(y\\) no es una línea recta, el modelo sigue siendo lineal porque los coeficientes \\(\\beta_0\\) y \\(\\beta_1\\) se combinan de manera lineal con \\(x\\).\n\n\n\n\n\n\n\n\n\n\n¿Cómo se vería una relación NO lineal? Si los coeficientes están involucrados en operaciones no lineales (exponenciales o elevados al cuadrado), perderíamos la linealidad del modelo. Por ejemplo:\n\n\\[\ny = e^{\\beta_0 + \\beta_1 \\cdot x}\n\\]"
  },
  {
    "objectID": "docs/63-lineales-supuestos.html#residuos",
    "href": "docs/63-lineales-supuestos.html#residuos",
    "title": "Supuestos de los Modelos Lineales",
    "section": "Residuos",
    "text": "Residuos\nLos residuos de un modelo lineal deben cumplir ciertos supuestos. Antes de verlos, vamos a definir qué son los residuos en un modelo lineal.\n\nLos residuos en un modelo lineal son las diferencias entre los valores observados (p. ej. los que obtenemos en nuestro experimento) y los valores predichos por el modelo.\nEstos residuos son una medida de cuánto se desvían los datos reales de la línea de regresión ajustada.\nLos residuos son una parte clave del modelo, ya que representan el error o la incertidumbre que no puede ser explicada por las variables predictoras. Un buen modelo de regresión tendrá residuos pequeños y distribuidos de manera aleatoria alrededor de la línea de regresión.\nVamos a ver esto con ejemplos para que quede más claro.\n\n\nEjemplo\n\nVamos a ver cómo se ven los residuos en un modelo lineal.\nPrimero, vamos a ajustar un modelo de regresión lineal simple con datos simulados.\nEn el siguiente gráfico, la línea roja representa la regresión lineal, los puntos naranjas son los datos observados (p.ej. los datos que obtuvimos en un experimento).\nLas líneas negras representan los residuos. Observa que los residuos son las distancias verticales entre los puntos observados y la línea de regresión.\n\n\n\n\n\n\n\nClick para ver el código usado en el gráfico\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegresemos al ejemplo de la relación entre la masa corporal y el largo de la aleta de los pingüinos.\nVamos a ajustar un modelo de regresión lineal y visualizar los residuos de todos los datos.\nLa línea roja representa la regresión lineal, los puntos naranjas son los datos observados y las líneas negras representan los residuos.\n\n\n\n\n\n\n\nClick para ver el código usado en el gráfico\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\n¿Cómo se ajusta la recta de regresión a los datos?\n\nLa recta de regresión se ajusta minimizando la suma de los cuadrados de los residuos. Es decir, la recta se ajusta de tal manera que la suma de las distancias verticales entre los puntos observados y la recta es la menor posible.\nEsto se conoce como el método de los mínimos cuadrados.\nObserva la siguiente figura para entender cómo se ajusta la recta de regresión a los datos:\n\n\n\n\n\nLa ssuma de cuadrados trata de minimizzar el área total de los cuadrados grises que se observan en la derecha\n\n\n\n\n\n\nSupuesto de residuos\nNormalidad\nLos residuos (diferencias entre los valores observados y los predichos por el modelo) deben seguir una distribución normal. Esto significa que los residuos deben estar distribuidos simétricamente alrededor de cero y seguir una forma de campana similar a la distribución normal, como en el siguiente gráfico:\n\nHomocedasticidad\nLa homocedadasticidad es la propiedad de los residuos de un modelo lineal de tener una varianza constante a lo largo de todos los niveles de los predictores. En otras palabras, la dispersión de los residuos debe ser constante en todos los valores de las variables predictoras. Lo contrario es llamado heterocedasticidad.\n\nLa varianza de los residuos es constante para todos los valores de las variables predictoras. En otras palabras, el ruido en las predicciones del modelo debe ser el mismo a lo largo de todos los niveles de los predictores.\n\n\n\n\n\n\n\nHomocedasticidad\n\n\n\n\n\n\n\nHeterocedasticidad. En valores bajos de X, hay poca varianza de los residuos, mientras que en valores altos, hay mucha más varianza. Esto se obsreva como un cono.\n\n\n\n\n\n\n\nVerificación de los supuestos de los residuos\n\nPara verificar la normalidad de los residuos, se pueden utilizar pruebas estadísticas como la prueba de Shapiro-Wilk o gráficos como el gráfico Q-Q o gráficos de residuos.\nVamos a ver los gráficos primero.\n\n\nPrimero, tenemos que ajustar el modelo lineal. Vamos a hacerlo con los datos de los pingüinos. En la lección pasada vimos la función lm() para ajustar un modelo lineal. Vamos a hacerlo de nuevo. Esta función tomará como argumentos la fórmula del modelo y los datos donde se encuentran las variables de la siguiente manera: lm(y ~ x, data = datos). En este caso, la variable respuesta es el largo de la aleta (largo_aleta_mm) y la variable predictora es la masa corporal (masa_corporal_g). Ajusta el modelo y guarda el resultado en una variable llamada modelo_pinguinos. Los datos pinguinos_clean ya están cargados y limpios (sin valores faltantes).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nRecuerda que la variable predictora es aquella que queremos usar para predecir la variable respuesta.\n\n\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\nmodelo_pinguinos &lt;- lm(largo_aleta_mm ~ masa_corporal_g, data = pinguinos_clean)\n\n\n\n\n\ngráfico de residuos\n\nAhora, para hacer el gráfico de residuos con ggplot, vamos a hacer un gráfico de dispersión con los valores ajustados de la variable predictora en el eje x (los valores predichos por el modelo = .fitted) y los residuos en el eje y (las diferencias entre los valores observados = .resid). El dataframe es el modelo que ajustamos en la celda anterior.\nEn el valor de cero en el eje x, los residuos deberían estar distribuidos aleatoriamente alrededor de la línea horizontal en 0. Esto indicaría que los residuos siguen una distribución normal y que el supuesto de normalidad se cumple.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCómo nos ayuda este gráfico a verificar los supuestos de los residuos?\n\nSi los residuos siguen una distribución normal, esperaríamos que los puntos estén distribuidos aleatoriamente alred y alrededor de la línea horizontal en 0.\nSi hay patrones en la distribución de los residuos (p.ej. forma de embudo, curvas, etc.), esto podría indicar que los residuos no siguen una distribución normal y que el supuesto de normalidad no se cumple.\nSi la varianza de los residuos cambia a lo largo de los valores ajustados, esto podría indicar que el supuesto de homocedasticidad no se cumple.\nEn el gráfico anterior, ¿qué observas sobre la normalidad y homocedasticidad de los residuos?\n\nObserva ejemplos de gráficos de residuos donde se cumplen y no se cumplen los supuestos de normalidad y homocedasticidad:\n\n\n\n\n\n\nLinearidad es válida porque la media de los residuos está cercana a 0 y la dispersión de los residuos es similar\n\n\n\n\n\n\n\nLinearidad es válida, pero la varianza no es constante: en valores altos de valores predichos, hay mucha más dispersión. La figura de cono que observamos es\n\n\n\n\n\n\n\n\n\nEl supuesto de linearidad no parece cumplirse porque la media de los residuos no está cercana a cero\n\n\n\n\n\n\n\ngráfico Q-Q\n\nOtra forma de verificar la normalidad de los residuos es mediante un gráfico Q-Q (cuantil-cuantil). Este gráfico compara los cuantiles de los residuos con los cuantiles de una distribución normal. Si los residuos siguen una distribución normal, los puntos en el gráfico Q-Q deberían seguir una línea diagonal.\nEn las siguientes figuras, el gráfico Q-Q de la izquierda muestra una distribución normal de los residuos, mientras que el de la derecha muestra una distribución no normal.\n\n\n\n\n\n\n\n\n\n\n\nAhora, para hacer el gráfico Q-Q de los residuos del modelo de los pingüinos, vamos a usar la función stat_qq() y stat_qq_line de ggplot.\n\n\n\n\n\n\n\n\n\n\nReflexión\n\n¿Son o no son normales los residuos del modelo de regresión lineal de los pingüinos?\nRegresaremos a esta discusión al final de este tema.\nPodemos contestar esta pregunta con una prueba estadística, como la prueba de Shapiro-Wilk, que evalúa si los residuos siguen una distribución normal, pero esto se verá después de que veamos qué son las pruebas de hipótesis.\nCuando los supuestos no se cumplen, el modelo puede proporcionar predicciones sesgadas o intervalos de confianza incorrectos, los cuales también veremos más adelante.\nSin embargo, existen técnicas para manejar o ajustar estos problemas, como transformaciones de los datos o el uso de modelos más robustos.\n\n\n\nEvaluación del Modelo\nVeremos esto en detalle en futuras lecciones, pero es importante mencionar que una vez que hemos ajustado un modelo lineal, es necesario evaluar su desempeño. Algunas de las métricas más comunes incluyen:\n\n\\(R^2\\) : También conocido como el coeficiente de determinación, mide la proporción de la variabilidad en \\(y\\) que es explicada por el modelo. Un valor de \\(R^2\\) cercano a 1 indica que el modelo explica bien los datos, mientras que un valor cercano a 0 sugiere que el modelo no captura mucha de la variabilidad en la variable respuesta.\nPruebas de hipótesis: Se utilizan para evaluar la significancia de los coeficientes del modelo. Un p-valor bajo para un coeficiente \\(\\beta_i\\) sugiere que la variable \\(x\\) tiene un impacto significativo sobre \\(y\\).\nAnálisis de residuos: Verificar si los residuos siguen una distribución normal y si su varianza es constante puede ayudar a diagnosticar problemas con el ajuste del modelo."
  },
  {
    "objectID": "docs/55-chic-cuadrada.html",
    "href": "docs/55-chic-cuadrada.html",
    "title": "Test Chi-cuadrado como Modelo Log-lineal",
    "section": "",
    "text": "Lección sobre Proporciones: El Test Chi-cuadrado como Modelo Log-lineal en Ciencias de la Salud y Biológicas\n\n\nIntroducción al Chi-cuadrado como Modelo Log-lineal\nEl test de chi-cuadrado es una herramienta estadística utilizada para analizar proporciones y tablas de contingencia. Aunque tradicionalmente se enseña como una prueba basada en frecuencias observadas y esperadas, el test de chi-cuadrado puede entenderse como un modelo log-lineal, lo que lo conecta directamente con los modelos lineales que hemos visto en ANOVA y ANCOVA.\nLa regresión log-lineal es una forma de modelar datos de conteo. Al aplicar un logaritmo a los conteos, podemos interpretar los coeficientes de un modelo lineal como aumentos porcentuales en las proporciones, lo que hace que los datos de conteo y las tablas de contingencia sean más fáciles de analizar e interpretar.\n\n\n\n\nPuntos clave a enseñar:\n\nTest de Chi-cuadrado como modelo log-lineal: El modelo log-lineal es una forma de analizar tablas de contingencia utilizando un enfoque basado en la regresión. El modelo básico para un test de chi-cuadrado es:\n\\([\n\\log(y) = \\beta_0 + \\beta_1 \\cdot X_1 + \\beta_2 \\cdot X_2 + \\cdots\\)]\nDonde \\((y\\)) es el conteo (frecuencia observada), y los coeficientes \\((\\beta_0, \\beta_1, \\dots\\)) representan los efectos de las variables categóricas que se están analizando.\nPrueba de bondad de ajuste: En la prueba de bondad de ajuste, estamos evaluando si los conteos observados en una tabla de frecuencias difieren significativamente de los conteos esperados bajo una distribución nula. Esto es equivalente a un ANOVA unidireccional para datos de conteo.\nTablas de contingencia: Las tablas de contingencia se utilizan para analizar la relación entre dos o más variables categóricas. Al introducir el modelo log-lineal, podemos ver las tablas de contingencia como un ANOVA de dos vías para datos de conteo, con los coeficientes logarítmicos representando las proporciones.\nModelo log-lineal en R: El modelo log-lineal se ajusta en R utilizando la función glm() con la familia Poisson, que ajusta una regresión log-lineal para datos de conteo.\n\n\n\n\nEjemplo en R: Test de Bondad de Ajuste y Tablas de Contingencia\nA continuación, realizamos un test de bondad de ajuste y analizamos una tabla de contingencia utilizando un modelo log-lineal en R.\n\nPaso 1: Prueba de bondad de ajuste - Datos de ejemplo\nPrimero, creamos un conjunto de datos que representa las frecuencias de diferentes estados de ánimo.\n\n\n\n\n\n\n\n\n\n\nPaso 2: R code: Prueba de bondad de ajuste\nRealizamos la prueba de bondad de ajuste utilizando el test de chi-cuadrado y también ajustamos un modelo log-lineal equivalente.\n\n\n\n\n\n\n\n\n\n\nPaso 3: Tablas de Contingencia - Datos de ejemplo\nCreamos un conjunto de datos que representa una tabla de contingencia entre dos variables categóricas: mood (estado de ánimo) y sex (sexo).\n\n\n\n\n\n\n\n\n\n\nPaso 4: R code: Test de Chi-cuadrado para Tablas de Contingencia\nRealizamos el test de chi-cuadrado en la tabla de contingencia y ajustamos un modelo log-lineal para analizar la interacción entre mood y sex.\n\n\n\n\n\n\n\n\n\n\n\n\nEjercicio Práctico\n\nEjercicio 1: Usa el conjunto de datos mtcars para realizar un test de chi-cuadrado que evalúe la relación entre el número de cilindros (cyl) y el tipo de transmisión (am).\n\n\n\n\n\n\n\n\nEjercicio 2: Ajusta un modelo log-lineal para analizar la interacción entre cyl y am en el conjunto de datos mtcars.\n\n\n\n\n\n\n\n\n\n\n\n\nConclusión\nEl test de chi-cuadrado, cuando se interpreta como un modelo log-lineal, proporciona una forma más intuitiva de analizar proporciones y tablas de contingencia. Al aplicar un enfoque de regresión log-lineal, podemos interpretar los coeficientes como aumentos porcentuales en los conteos, lo que nos permite analizar de manera más clara las relaciones entre variables categóricas en estudios de ciencias de la salud y biológicas.\nCon este enfoque, los estudiantes pueden conectar el test de chi-cuadrado con los modelos lineales que ya han aprendido, facilitando su comprensión e interpretación en estudios de proporciones y datos de conteo."
  },
  {
    "objectID": "docs/77-anova-medidas-repetidas-python.html",
    "href": "docs/77-anova-medidas-repetidas-python.html",
    "title": "ANOVA de Medidas Repetidas en Python",
    "section": "",
    "text": "El ANOVA de medidas repetidas se utiliza para analizar datos donde los mismos sujetos se miden más de una vez. Esta prueba también se conoce como ANOVA intra-sujetos. El término “intra-sujetos” significa que los mismos individuos son medidos en la misma variable de resultado bajo diferentes puntos de tiempo o condiciones.\nPor ejemplo, podrías haber medido la puntuación de autoestima (la variable de resultado) de 10 individuos en tres momentos durante un programa de intervención para determinar si su autoestima mejoró.\n\n\n\nANOVA de una vía de medidas repetidas: Una extensión de la prueba t de muestras pareadas para comparar las medias de tres o más niveles de una variable intra-sujetos (por ejemplo, tiempo).\nANOVA de dos vías de medidas repetidas: Se utiliza para evaluar simultáneamente el efecto de dos factores intra-sujetos sobre una variable de resultado continua."
  },
  {
    "objectID": "docs/77-anova-medidas-repetidas-python.html#qué-es-el-anova-de-medidas-repetidas",
    "href": "docs/77-anova-medidas-repetidas-python.html#qué-es-el-anova-de-medidas-repetidas",
    "title": "ANOVA de Medidas Repetidas en Python",
    "section": "",
    "text": "El ANOVA de medidas repetidas se utiliza para analizar datos donde los mismos sujetos se miden más de una vez. Esta prueba también se conoce como ANOVA intra-sujetos. El término “intra-sujetos” significa que los mismos individuos son medidos en la misma variable de resultado bajo diferentes puntos de tiempo o condiciones.\nPor ejemplo, podrías haber medido la puntuación de autoestima (la variable de resultado) de 10 individuos en tres momentos durante un programa de intervención para determinar si su autoestima mejoró.\n\n\n\nANOVA de una vía de medidas repetidas: Una extensión de la prueba t de muestras pareadas para comparar las medias de tres o más niveles de una variable intra-sujetos (por ejemplo, tiempo).\nANOVA de dos vías de medidas repetidas: Se utiliza para evaluar simultáneamente el efecto de dos factores intra-sujetos sobre una variable de resultado continua."
  },
  {
    "objectID": "docs/77-anova-medidas-repetidas-python.html#anova-de-una-vía-de-medidas-repetidas-en-python",
    "href": "docs/77-anova-medidas-repetidas-python.html#anova-de-una-vía-de-medidas-repetidas-en-python",
    "title": "ANOVA de Medidas Repetidas en Python",
    "section": "ANOVA de una vía de Medidas Repetidas en Python",
    "text": "ANOVA de una vía de Medidas Repetidas en Python\nVamos a realizar un ANOVA de una vía de medidas repetidas utilizando un conjunto de datos similar al de selfesteem de R.\n\n1. Cargar librerías y datos\nPrimero, instalamos y cargamos las librerías necesarias.\n\n\n\n\n\n\n\n\nUsaremos pingouin para obtener un conjunto de datos de medidas repetidas.\n\n\n\n\n\n\n\n\nEste conjunto de datos ya está en formato “largo”, que es el adecuado para el análisis. Tenemos: - Subject: El identificador del sujeto. - Time: La variable intra-sujetos (por ejemplo, “pre”, “post”). - Performance: La variable dependiente o de resultado.\n\n\n2. Visualización de los datos\nUn gráfico de cajas o de puntos puede ayudar a visualizar los cambios a lo largo del tiempo.\n\n\n\n\n\n\n\n\nLos gráficos sugieren un aumento en el rendimiento a lo largo del tiempo.\n\n\n3. Realizar el ANOVA de Medidas Repetidas\nUsaremos la función rm_anova() de la librería pingouin. Necesitamos especificar: - dv: La variable dependiente (Performance). - within: La variable intra-sujetos (Time). - subject: El identificador del sujeto (Subject).\n\n\n\n\n\n\n\n\n\n\n4. Interpretación de los resultados\nLa tabla de resultados nos muestra:\n\nSource: La fuente de variación, en este caso, Time.\np-unc: El valor p no corregido. En nuestro ejemplo, es muy bajo (&lt; 0.001), lo que indica que hay un cambio estadísticamente significativo en el Performance a lo largo del Time.\n\nConclusión: El tiempo tiene un efecto significativo en el rendimiento.\n\n\n5. Supuesto de Esfericidad\nEl ANOVA de medidas repetidas tiene un supuesto adicional llamado esfericidad. Este supuesto se aplica cuando tienes 3 o más niveles en tu factor intra-sujetos y se refiere a que las varianzas de las diferencias entre todas las combinaciones de niveles son iguales.\npingouin automáticamente realiza la prueba de esfericidad de Mauchly:\n\nW: El estadístico de la prueba.\np-val: El valor p de la prueba de Mauchly.\nsphericity: Un booleano que indica si se cumple el supuesto (si p-val &gt; 0.05).\n\nEn nuestro resultado, sphericity es True y el p-val es 0.393, lo que significa que se cumple el supuesto de esfericidad y podemos confiar en el valor p no corregido (p-unc).\nSi no se cumpliera la esfericidad (sphericity fuera False), deberíamos usar los valores p corregidos, como el de Greenhouse-Geisser (gg-corr) o el de Huynh-Feldt (hf-corr). pingouin los proporciona en la misma tabla.\n\n\n6. Pruebas Post-Hoc\nDado que el ANOVA nos dijo que hay una diferencia, pero no dónde, podemos realizar pruebas post-hoc (como comparaciones por pares con corrección de Bonferroni) para ver qué momentos son diferentes entre sí.\n\n\n\n\n\n\n\n\nLa tabla de post-hoc nos muestra las comparaciones entre cada par de niveles de Time: - Time A vs Time B: Los niveles que se comparan. - p-corr: El valor p corregido.\nTodas las comparaciones (pre vs post, pre vs fup, post vs fup) tienen un p-corr muy bajo, lo que indica que el rendimiento fue significativamente diferente en todos los momentos medidos."
  },
  {
    "objectID": "docs/20-funciones-estadistica.html#introducción",
    "href": "docs/20-funciones-estadistica.html#introducción",
    "title": "Estadísticas Descriptivas en R",
    "section": "Introducción",
    "text": "Introducción\n\nLas estadísticas descriptivas son herramientas cruciales en el análisis de datos, ya que nos permiten resumir y describir las características principales de un conjunto de datos.\nEn R, disponemos de funciones básicas que nos ayudan a calcular medidas como la media, la mediana, la desviación estándar, entre otras. - Estas medidas ofrecen una visión general del comportamiento de los datos y son fundamentales para cualquier análisis cuantitativo.\nVeremos la teoría más adelante, pero"
  },
  {
    "objectID": "docs/20-funciones-estadistica.html#funciones-básicas-para-resumen-estadístico",
    "href": "docs/20-funciones-estadistica.html#funciones-básicas-para-resumen-estadístico",
    "title": "Estadísticas Descriptivas en R",
    "section": "Funciones Básicas para Resumen Estadístico",
    "text": "Funciones Básicas para Resumen Estadístico\nA continuación, se presentan algunas de las funciones más utilizadas en R para calcular estadísticas descriptivas:\nMedia (`mean()`):"
  },
  {
    "objectID": "docs/20-funciones-estadistica.html#section",
    "href": "docs/20-funciones-estadistica.html#section",
    "title": "Estadísticas Descriptivas en R",
    "section": "",
    "text": "Mediana (median()):\nDetermina el valor central de un conjunto de datos ordenados.\n\nmedian(c(1, 3, 3, 6, 7, 8, 9))  # Devuelve 6\nDesviación Estándar (sd()):\nMide la cantidad de variación o dispersión de un conjunto de datos.\n\nsd(c(1, 2, 3, 4, 5))  # Calcula la desviación estándar\nVarianza (var()):\nRepresenta la media de las desviaciones al cuadrado respecto a la media.\n\nvar(c(1, 2, 3, 4, 5))  # Calcula la varianza\nMáximo y Mínimo (max(), min()):\nIdentifican los valores más alto y más bajo de un conjunto de datos.\n\nmax(c(1, 2, 3, 4, 5))  # Devuelve 5\nmin(c(1, 2, 3, 4, 5))  # Devuelve 1\ncount (length()):\nCuenta el número de elementos en un vector.\n\nlength(c(1, 2, 3, 4, 5))  # Devuelve 5\nResumen (summary()):\nProporciona un resumen estadístico completo, incluyendo mínimo, mediana, media, máximo y cuartiles.\n\nsummary(c(1, 2, 3, 4, 5))"
  },
  {
    "objectID": "docs/20-funciones-estadistica.html#aplicación-en-un-conjunto-de-datos",
    "href": "docs/20-funciones-estadistica.html#aplicación-en-un-conjunto-de-datos",
    "title": "Estadísticas Descriptivas en R",
    "section": "Aplicación en un Conjunto de Datos",
    "text": "Aplicación en un Conjunto de Datos\nPara entender mejor estas funciones, utilizarémos el conjunto de datos mtcars, que está incorporado en R:"
  },
  {
    "objectID": "docs/20-funciones-estadistica.html#ejercicio",
    "href": "docs/20-funciones-estadistica.html#ejercicio",
    "title": "Estadísticas Descriptivas en R",
    "section": "Ejercicio",
    "text": "Ejercicio\nEjercicio: Cálculo de Estadísticas Descriptivas\nCalcula la media y mediana del número de cilindros (cyl) en mtcars.\nDetermina la desviación estándar del consumo de gasolina (mpg).\nEncuentra el valor máximo y mínimo de relaciones de transmisión (gear).\nProporciona un resumen completo para el desplazamiento del motor (disp).\nCódigo del Ejercicio:"
  },
  {
    "objectID": "docs/20-funciones-estadistica.html#reflexión",
    "href": "docs/20-funciones-estadistica.html#reflexión",
    "title": "Estadísticas Descriptivas en R",
    "section": "Reflexión",
    "text": "Reflexión\n¿Cómo te ayudan estas medidas a entender mejor tu conjunto de datos?\nPiensa en cómo podrías utilizar estas herramientas para analizar otros conjuntos de datos con los que trabajes en el futuro.\nEsta lección introductoria sobre estadísticas descriptivas en R te prepara para abordar el análisis cuantitativo con confianza, dándote las herramientas necesarias para obtener rápidamente conclusiones significativas de tus datos."
  },
  {
    "objectID": "docs/73-anova-2vias.html",
    "href": "docs/73-anova-2vias.html",
    "title": "ANOVA de dos vías en R",
    "section": "",
    "text": "La prueba de ANOVA de dos vías se utiliza para evaluar simultáneamente el efecto de dos variables (A y B) de agrupamiento sobre una variable de respuesta.\nLas variables de agrupamiento también se conocen como factores. Las diferentes categorías (grupos) de un factor se denominan niveles. El número de niveles puede variar entre factores. Las combinaciones de niveles de factores se llaman celdas.\nSupongamos que tenemos un experimento con dos factores: Tipo de Suplemento (con niveles “OJ” para jugo de naranja y “VC” para vitamina C) y Dosis (con niveles 0.5, 1 y 2). La variable de respuesta es la Longitud del Diente. Aquí está cómo se vería una tabla que muestra las celdas formadas por las combinaciones de niveles de estos factores:\n\n\n\nTipo de Suplemento\nDosis\nLongitud del Diente (ejemplo)\n\n\n\n\nOJ\n0.5\n13.2\n\n\nOJ\n1.0\n22.7\n\n\nOJ\n2.0\n26.4\n\n\nVC\n0.5\n8.2\n\n\nVC\n1.0\n15.5\n\n\nVC\n2.0\n23.3\n\n\n\n\nFactores: En este ejemplo, tenemos dos factores: “Tipo de Suplemento” y “Dosis”.\nNiveles: Cada factor tiene varios niveles. “Tipo de Suplemento” tiene dos niveles (“OJ” y “VC”), mientras que “Dosis” tiene tres niveles (0.5, 1 y 2).\nCeldas: Cada combinación de niveles de los factores forma una celda. Por ejemplo, “OJ con dosis 0.5” es una celda.\n\n\n\n\n\n\n\n\nCuando los tamaños de muestra dentro de las celdas son iguales, tenemos el llamado diseño equilibrado. En este caso, se puede aplicar el test ANOVA estándar de dos vías.\nCuando los tamaños de muestra dentro de cada nivel de las variables independientes no son los mismos (caso de diseños no equilibrados), el test ANOVA debe manejarse de manera diferente.\n\n\n\n\n\n\n\nNo hay diferencia en las medias del factor A.\nNo hay diferencia en las medias del factor B.\nNo hay interacción entre los factores A y B.\n\nLa hipótesis alternativa para los casos 1 y 2 es: las medias no son iguales.\nLa hipótesis alternativa para el caso 3 es: hay una interacción entre A y B.\n\n\n\n\n\n\n¿Qué son las Interacciones?\n\n\n\nEn el contexto del análisis de varianza (ANOVA), una interacción se refiere a una situación donde el efecto de un factor en la variable de respuesta depende del nivel de otro factor. Esto significa que los efectos de los factores no son simplemente aditivos, sino que la combinación de los factores tiene un efecto distinto que no se puede predecir solo a partir de los efectos individuales de cada factor.\nPor ejemplo, si estamos analizando el efecto de dos factores, como el tipo de suplemento y la dosis de vitamina C en la longitud del diente de cobayas, una interacción indicaría que el efecto de la dosis puede cambiar dependiendo del tipo de suplemento. Es decir, la diferencia en la longitud del diente entre dosis altas y bajas podría ser diferente para el jugo de naranja comparado con la vitamina C pura.\n\n\nEl ANOVA de dos vías se utiliza para:\n\nEvaluar los efectos individuales de cada factor (llamados efectos principales). Esto nos permite determinar si cada factor (tipo de suplemento o dosis) tiene un efecto significativo en la variable de respuesta.\nDetectar interacciones entre los factores. Esto nos permite determinar si los efectos de los factores son independientes entre sí o si interactúan de alguna manera.\n\nLas interacciones son cruciales porque pueden revelar relaciones complejas entre los factores que no serían evidentes si solo se examinaran los efectos principales. Ignorar una interacción significativa podría llevar a conclusiones incorrectas sobre cómo los factores afectan la variable de respuesta.\n\n\n\n\nPrueba de T: Se utiliza para comparar las medias de dos grupos. Solo puede manejar un factor con dos niveles (esencialmente una comparación entre dos grupos). No puede evaluar interacciones porque no maneja múltiples factores.\nANOVA de Una Vía: Este tipo de análisis se usa cuando hay un solo factor con varios niveles. No considera interacciones porque solo hay un factor. El ANOVA de una vía evalúa si hay diferencias significativas en las medias de la variable de respuesta entre los niveles de un único factor.\nANOVA de Dos Vías: Se diferencia de las anteriores porque se utiliza para analizar dos factores simultáneamente, permitiendo evaluar tanto los efectos principales de cada factor como la interacción entre ellos. Esto proporciona una visión más completa de cómo los factores afectan la variable de respuesta.\n\n\n\n\nImagina un estudio donde evaluamos el efecto de dos tratamientos diferentes (A y B) y dos métodos de administración (oral e inyectado) sobre una medida de salud. Sin interacción, podríamos decir que el tratamiento A siempre es mejor que el B, independientemente del método de administración. Sin embargo, si hay una interacción, el tratamiento A podría ser mejor solo cuando se administra oralmente, mientras que el tratamiento B podría ser más efectivo cuando se administra inyectado.\n\n\n\nConsideremos un ejemplo donde evaluamos cómo la temperatura y la precipitación (lluvia) influyen en la probabilidad de que las personas usen paraguas. Este ejemplo ayudará a ilustrar el concepto de interacción entre estos dos factores.\nFactores y Niveles\n\nFactor 1: Temperatura\n\nNiveles: Baja, Media, Alta\n\nFactor 2: Precipitación\n\nNiveles: No Llueve, Llueve\n\n\nVariable de Respuesta - Uso de Paraguas: Medido como la proporción de personas que usan paraguas.\nPosible Interacción: Supongamos que realizamos un estudio y encontramos los siguientes patrones:\nTemperatura Baja\n\nNo Llueve: Pocas personas usan paraguas.\nLlueve: Muchas personas usan paraguas. Temperatura Media\n\nTemperatura Media\n\nNo Llueve: Muy pocas personas usan paraguas.\nLlueve: Muchas personas usan paraguas.\n\nTemperatura Alta\n\nNo Llueve: Casi nadie usa paraguas.\nLlueve: Algunas personas usan paraguas, pero menos que en temperaturas bajas o medias.\n\nInterpretación de la Interacción\nEn este contexto, la interacción entre temperatura y precipitación podría observarse de la siguiente manera:\n\nSin Interacción: Podríamos esperar que la lluvia siempre aumente el uso de paraguas, independientemente de la temperatura. Igualmente, podríamos esperar que la temperatura no afecte el uso de paraguas cuando no llueve.\nCon Interacción: La interacción sugiere que el efecto de la lluvia sobre el uso de paraguas depende de la temperatura. Por ejemplo, aunque la lluvia generalmente aumenta el uso de paraguas, este efecto es más pronunciado en temperaturas bajas y medias. En temperaturas altas, aunque llueva, algunas personas podrían optar por no usar paraguas debido a que el calor hace que prefieran mojarse un poco que sentirse más incómodos bajo un paraguas.\n\nGráfico para ilustrar la interacción entre temperatura y precipitación en el uso de paraguas:"
  },
  {
    "objectID": "docs/73-anova-2vias.html#hipótesis-del-test-anova-de-dos-vías",
    "href": "docs/73-anova-2vias.html#hipótesis-del-test-anova-de-dos-vías",
    "title": "ANOVA de dos vías en R",
    "section": "",
    "text": "No hay diferencia en las medias del factor A.\nNo hay diferencia en las medias del factor B.\nNo hay interacción entre los factores A y B.\n\nLa hipótesis alternativa para los casos 1 y 2 es: las medias no son iguales.\nLa hipótesis alternativa para el caso 3 es: hay una interacción entre A y B.\n\n\n\n\n\n\n¿Qué son las Interacciones?\n\n\n\nEn el contexto del análisis de varianza (ANOVA), una interacción se refiere a una situación donde el efecto de un factor en la variable de respuesta depende del nivel de otro factor. Esto significa que los efectos de los factores no son simplemente aditivos, sino que la combinación de los factores tiene un efecto distinto que no se puede predecir solo a partir de los efectos individuales de cada factor.\nPor ejemplo, si estamos analizando el efecto de dos factores, como el tipo de suplemento y la dosis de vitamina C en la longitud del diente de cobayas, una interacción indicaría que el efecto de la dosis puede cambiar dependiendo del tipo de suplemento. Es decir, la diferencia en la longitud del diente entre dosis altas y bajas podría ser diferente para el jugo de naranja comparado con la vitamina C pura.\n\n\nEl ANOVA de dos vías se utiliza para:\n\nEvaluar los efectos individuales de cada factor (llamados efectos principales). Esto nos permite determinar si cada factor (tipo de suplemento o dosis) tiene un efecto significativo en la variable de respuesta.\nDetectar interacciones entre los factores. Esto nos permite determinar si los efectos de los factores son independientes entre sí o si interactúan de alguna manera.\n\nLas interacciones son cruciales porque pueden revelar relaciones complejas entre los factores que no serían evidentes si solo se examinaran los efectos principales. Ignorar una interacción significativa podría llevar a conclusiones incorrectas sobre cómo los factores afectan la variable de respuesta.\n\n\n\n\nPrueba de T: Se utiliza para comparar las medias de dos grupos. Solo puede manejar un factor con dos niveles (esencialmente una comparación entre dos grupos). No puede evaluar interacciones porque no maneja múltiples factores.\nANOVA de Una Vía: Este tipo de análisis se usa cuando hay un solo factor con varios niveles. No considera interacciones porque solo hay un factor. El ANOVA de una vía evalúa si hay diferencias significativas en las medias de la variable de respuesta entre los niveles de un único factor.\nANOVA de Dos Vías: Se diferencia de las anteriores porque se utiliza para analizar dos factores simultáneamente, permitiendo evaluar tanto los efectos principales de cada factor como la interacción entre ellos. Esto proporciona una visión más completa de cómo los factores afectan la variable de respuesta.\n\n\n\n\nImagina un estudio donde evaluamos el efecto de dos tratamientos diferentes (A y B) y dos métodos de administración (oral e inyectado) sobre una medida de salud. Sin interacción, podríamos decir que el tratamiento A siempre es mejor que el B, independientemente del método de administración. Sin embargo, si hay una interacción, el tratamiento A podría ser mejor solo cuando se administra oralmente, mientras que el tratamiento B podría ser más efectivo cuando se administra inyectado.\n\n\n\nConsideremos un ejemplo donde evaluamos cómo la temperatura y la precipitación (lluvia) influyen en la probabilidad de que las personas usen paraguas. Este ejemplo ayudará a ilustrar el concepto de interacción entre estos dos factores.\nFactores y Niveles\n\nFactor 1: Temperatura\n\nNiveles: Baja, Media, Alta\n\nFactor 2: Precipitación\n\nNiveles: No Llueve, Llueve\n\n\nVariable de Respuesta - Uso de Paraguas: Medido como la proporción de personas que usan paraguas.\nPosible Interacción: Supongamos que realizamos un estudio y encontramos los siguientes patrones:\nTemperatura Baja\n\nNo Llueve: Pocas personas usan paraguas.\nLlueve: Muchas personas usan paraguas. Temperatura Media\n\nTemperatura Media\n\nNo Llueve: Muy pocas personas usan paraguas.\nLlueve: Muchas personas usan paraguas.\n\nTemperatura Alta\n\nNo Llueve: Casi nadie usa paraguas.\nLlueve: Algunas personas usan paraguas, pero menos que en temperaturas bajas o medias.\n\nInterpretación de la Interacción\nEn este contexto, la interacción entre temperatura y precipitación podría observarse de la siguiente manera:\n\nSin Interacción: Podríamos esperar que la lluvia siempre aumente el uso de paraguas, independientemente de la temperatura. Igualmente, podríamos esperar que la temperatura no afecte el uso de paraguas cuando no llueve.\nCon Interacción: La interacción sugiere que el efecto de la lluvia sobre el uso de paraguas depende de la temperatura. Por ejemplo, aunque la lluvia generalmente aumenta el uso de paraguas, este efecto es más pronunciado en temperaturas bajas y medias. En temperaturas altas, aunque llueva, algunas personas podrían optar por no usar paraguas debido a que el calor hace que prefieran mojarse un poco que sentirse más incómodos bajo un paraguas.\n\nGráfico para ilustrar la interacción entre temperatura y precipitación en el uso de paraguas:"
  },
  {
    "objectID": "docs/73-anova-2vias.html#por-qué-se-usan-las-interacciones-en-el-anova-de-dos-vías",
    "href": "docs/73-anova-2vias.html#por-qué-se-usan-las-interacciones-en-el-anova-de-dos-vías",
    "title": "ANOVA de dos vías en R",
    "section": "",
    "text": "El ANOVA de dos vías se utiliza para:\n\nEvaluar los efectos individuales de cada factor (llamados efectos principales). Esto nos permite determinar si cada factor (tipo de suplemento o dosis) tiene un efecto significativo en la variable de respuesta.\nDetectar interacciones entre los factores. Esto nos permite determinar si los efectos de los factores son independientes entre sí o si interactúan de alguna manera.\n\nLas interacciones son cruciales porque pueden revelar relaciones complejas entre los factores que no serían evidentes si solo se examinaran los efectos principales. Ignorar una interacción significativa podría llevar a conclusiones incorrectas sobre cómo los factores afectan la variable de respuesta."
  },
  {
    "objectID": "docs/73-anova-2vias.html#diferencias-con-el-anova-de-una-vía-y-la-prueba-de-t",
    "href": "docs/73-anova-2vias.html#diferencias-con-el-anova-de-una-vía-y-la-prueba-de-t",
    "title": "ANOVA de dos vías en R",
    "section": "",
    "text": "Prueba de T: Se utiliza para comparar las medias de dos grupos. Solo puede manejar un factor con dos niveles (esencialmente una comparación entre dos grupos). No puede evaluar interacciones porque no maneja múltiples factores.\nANOVA de Una Vía: Este tipo de análisis se usa cuando hay un solo factor con varios niveles. No considera interacciones porque solo hay un factor. El ANOVA de una vía evalúa si hay diferencias significativas en las medias de la variable de respuesta entre los niveles de un único factor.\nANOVA de Dos Vías: Se diferencia de las anteriores porque se utiliza para analizar dos factores simultáneamente, permitiendo evaluar tanto los efectos principales de cada factor como la interacción entre ellos. Esto proporciona una visión más completa de cómo los factores afectan la variable de respuesta."
  },
  {
    "objectID": "docs/73-anova-2vias.html#ejemplo-ii-de-interacción",
    "href": "docs/73-anova-2vias.html#ejemplo-ii-de-interacción",
    "title": "ANOVA de dos vías en R",
    "section": "",
    "text": "Imagina un estudio donde evaluamos el efecto de dos tratamientos diferentes (A y B) y dos métodos de administración (oral e inyectado) sobre una medida de salud. Sin interacción, podríamos decir que el tratamiento A siempre es mejor que el B, independientemente del método de administración. Sin embargo, si hay una interacción, el tratamiento A podría ser mejor solo cuando se administra oralmente, mientras que el tratamiento B podría ser más efectivo cuando se administra inyectado."
  },
  {
    "objectID": "docs/73-anova-2vias.html#ejemplo-iii-de-interacción",
    "href": "docs/73-anova-2vias.html#ejemplo-iii-de-interacción",
    "title": "ANOVA de dos vías en R",
    "section": "",
    "text": "Consideremos un ejemplo donde evaluamos cómo la temperatura y la precipitación (lluvia) influyen en la probabilidad de que las personas usen paraguas. Este ejemplo ayudará a ilustrar el concepto de interacción entre estos dos factores.\nFactores y Niveles\n\nFactor 1: Temperatura\n\nNiveles: Baja, Media, Alta\n\nFactor 2: Precipitación\n\nNiveles: No Llueve, Llueve\n\n\nVariable de Respuesta - Uso de Paraguas: Medido como la proporción de personas que usan paraguas.\nPosible Interacción: Supongamos que realizamos un estudio y encontramos los siguientes patrones:\nTemperatura Baja\n\nNo Llueve: Pocas personas usan paraguas.\nLlueve: Muchas personas usan paraguas. Temperatura Media\n\nTemperatura Media\n\nNo Llueve: Muy pocas personas usan paraguas.\nLlueve: Muchas personas usan paraguas.\n\nTemperatura Alta\n\nNo Llueve: Casi nadie usa paraguas.\nLlueve: Algunas personas usan paraguas, pero menos que en temperaturas bajas o medias.\n\nInterpretación de la Interacción\nEn este contexto, la interacción entre temperatura y precipitación podría observarse de la siguiente manera:\n\nSin Interacción: Podríamos esperar que la lluvia siempre aumente el uso de paraguas, independientemente de la temperatura. Igualmente, podríamos esperar que la temperatura no afecte el uso de paraguas cuando no llueve.\nCon Interacción: La interacción sugiere que el efecto de la lluvia sobre el uso de paraguas depende de la temperatura. Por ejemplo, aunque la lluvia generalmente aumenta el uso de paraguas, este efecto es más pronunciado en temperaturas bajas y medias. En temperaturas altas, aunque llueva, algunas personas podrían optar por no usar paraguas debido a que el calor hace que prefieran mojarse un poco que sentirse más incómodos bajo un paraguas.\n\nGráfico para ilustrar la interacción entre temperatura y precipitación en el uso de paraguas:"
  },
  {
    "objectID": "docs/73-anova-2vias.html#datos",
    "href": "docs/73-anova-2vias.html#datos",
    "title": "ANOVA de dos vías en R",
    "section": "Datos",
    "text": "Datos\nUsaremos el conjunto de datos incorporado en R llamado ToothGrowth. Contiene datos de un estudio que evalúa el efecto de la vitamina C en el crecimiento dental en cobayas. El experimento se ha realizado en 60 cobayas, donde cada animal recibió uno de tres niveles de dosis de vitamina C (0.5, 1 y 2 mg/día) mediante uno de dos métodos de administración (jugo de naranja o ácido ascórbico, y codificado como VC). Se midió la longitud del diente y se muestra una muestra de los datos a continuación."
  },
  {
    "objectID": "docs/73-anova-2vias.html#verifica-tus-datos",
    "href": "docs/73-anova-2vias.html#verifica-tus-datos",
    "title": "ANOVA de dos vías en R",
    "section": "Verifica tus datos",
    "text": "Verifica tus datos\nPara tener una idea de cómo se ven los datos, mostramos una muestra aleatoria de los datos usando la función sample_n() [en el paquete dplyr]. Primero, instala dplyr si no lo tienes:\n\n\n\n\n\n\n\n\nDel resultado anterior, R considera “dose” como una variable numérica. La convertiremos en una variable de factor (es decir, variable de agrupamiento) de la siguiente manera.\n\n\n\n\n\n\n\n\nPregunta: Queremos saber si la longitud del diente depende de supp y dose.\n\nGenera tablas de frecuencia:\n\n\n\n\n\n\n\n\nTenemos celdas de diseño 2X3 con los factores siendo supp y dose y 10 sujetos en cada celda. Aquí, tenemos un diseño equilibrado. En las siguientes secciones describiré cómo analizar datos de diseños equilibrados, ya que este es el caso más simple."
  },
  {
    "objectID": "docs/73-anova-2vias.html#visualiza-tus-datos",
    "href": "docs/73-anova-2vias.html#visualiza-tus-datos",
    "title": "ANOVA de dos vías en R",
    "section": "Visualiza tus datos",
    "text": "Visualiza tus datos\nLos diagramas de caja y los diagramas de línea se pueden usar para visualizar las diferencias de grupo:\n\nDiagrama de caja para graficar los datos agrupados por las combinaciones de los niveles de los dos factores.\nDiagrama de interacción de dos vías, que grafica la media (u otro resumen) de la respuesta para combinaciones de factores de dos vías, ilustrando así posibles interacciones.\n\nPara usar gráficos base de R lee esto: R base graphs. Aquí, usaremos el paquete R ggpubr para una fácil visualización de datos basada en ggplot2."
  },
  {
    "objectID": "docs/73-anova-2vias.html#calcular-el-test-anova-de-dos-vías",
    "href": "docs/73-anova-2vias.html#calcular-el-test-anova-de-dos-vías",
    "title": "ANOVA de dos vías en R",
    "section": "Calcular el test ANOVA de dos vías",
    "text": "Calcular el test ANOVA de dos vías\nQueremos saber si la longitud del diente depende de supp y dose.\nLa función R aov() se puede usar para responder esta pregunta. La función summary.aov() se utiliza para resumir el modelo de análisis de varianza.\n\n\n\n\n\n\n\n\nEl resultado incluye las columnas F value y Pr(&gt;F) correspondientes al valor p del test.\nDe la tabla ANOVA podemos concluir que tanto supp como dose son estadísticamente significativos. dose es la variable de factor más significativa. Estos resultados nos llevarían a creer que cambiar los métodos de administración (supp) o la dosis de vitamina C, impactará significativamente la longitud media del diente.\nEl modelo ajustado anterior se llama modelo aditivo. Hace una suposición de que las dos variables de factor son independientes. Si crees que estas dos variables podrían interactuar para crear un efecto sinérgico, reemplaza el símbolo de más (+) por un asterisco (*), de la siguiente manera.\n\n\n\n\n\n\n\n\nSe puede ver que los dos efectos principales (supp y dose) son estadísticamente significativos, así como su interacción (marcada como supp:dose).\nNota que, en la situación donde la interacción no es significativa deberías usar el modelo aditivo."
  },
  {
    "objectID": "docs/73-anova-2vias.html#interpretar-los-resultados",
    "href": "docs/73-anova-2vias.html#interpretar-los-resultados",
    "title": "ANOVA de dos vías en R",
    "section": "Interpretar los resultados",
    "text": "Interpretar los resultados\nDe los resultados del ANOVA, puedes concluir lo siguiente, basado en los valores p y un nivel de significancia de 0.05:\n\nEl valor p de supp es 0.000429 (significativo), lo que indica que los niveles de supp están asociados con una longitud del diente significativamente diferente.\nEl valor p de dose es &lt; 2e-16 (significativo), lo que indica que los niveles de dose están asociados con una longitud del diente significativamente diferente.\nEl valor p para la interacción entre supp*dose es 0.02 (significativo), lo que indica que las relaciones entre dose y la longitud del diente dependen del método supp."
  },
  {
    "objectID": "docs/73-anova-2vias.html#calcular-algunas-estadísticas-resumidas",
    "href": "docs/73-anova-2vias.html#calcular-algunas-estadísticas-resumidas",
    "title": "ANOVA de dos vías en R",
    "section": "Calcular algunas estadísticas resumidas",
    "text": "Calcular algunas estadísticas resumidas\nCalcula la media y la desviación estándar por grupos usando el paquete R dplyr:\n\n\n\n\n\n\n\n\nTambién es posible usar la función model.tables() de la siguiente manera:"
  },
  {
    "objectID": "docs/73-anova-2vias.html#comparaciones-múltiples-por-pares-entre-las-medias-de-grupos",
    "href": "docs/73-anova-2vias.html#comparaciones-múltiples-por-pares-entre-las-medias-de-grupos",
    "title": "ANOVA de dos vías en R",
    "section": "Comparaciones múltiples por pares entre las medias de grupos",
    "text": "Comparaciones múltiples por pares entre las medias de grupos\nEn el test ANOVA, un valor p significativo indica que algunas de las medias de grupo son diferentes, pero no sabemos qué pares de grupos son diferentes.\nEs posible realizar comparaciones múltiples por pares, para determinar si la diferencia de medias entre pares específicos de grupos es estadísticamente significativa.\n\nComparaciones múltiples de Tukey\nDado que el test ANOVA es significativo, podemos calcular Tukey HSD (Diferencias Significativas Honestamente de Tukey, función R: TukeyHSD()) para realizar comparaciones múltiples por pares entre las medias de grupos. La función TukeyHSD() toma el ANOVA ajustado como argumento.\nNo necesitamos realizar el test para la variable “supp” porque solo tiene dos niveles, los cuales ya se ha demostrado que son significativamente diferentes mediante el test ANOVA. Por lo tanto, el test Tukey HSD se realizará solo para la variable de factor “dose”.\n\n\n\n\n\n\n\n\nSe puede ver del resultado, que todas las comparaciones por pares son significativas con un valor p ajustado &lt; 0.05.\n\n\nComparaciones múltiples usando el paquete multcomp\nEs posible usar la función glht() [en el paquete multcomp] para realizar procedimientos de comparación múltiple para un ANOVA. glht significa pruebas de hipótesis lineales generales. El formato simplificado es el siguiente:\nglht(model, lincft)\n\nmodel: un modelo ajustado, por ejemplo, un objeto devuelto por aov().\nlincft(): una especificación de las hipótesis lineales a ser probadas. Las comparaciones múltiples en modelos ANOVA se especifican por objetos devueltos de la función mcp().\n\nUsa glht() para realizar comparaciones múltiples por pares:\n\n\n\n\n\n\n\n\n\n\nTest t por pares\nLa función pairwise.t.test() también se puede usar para calcular comparaciones por pares entre niveles de grupo con correcciones para pruebas múltiples.\nPuedes ver los métodos de ajuste disponibles en la documentación de R ?p.adjust.methods, los cuales incluyen: c(\"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"BY\", \"fdr\", \"none\")"
  },
  {
    "objectID": "docs/73-anova-2vias.html#visualizar-los-resultados-y-agregar-p-valores-a-los-gráficos",
    "href": "docs/73-anova-2vias.html#visualizar-los-resultados-y-agregar-p-valores-a-los-gráficos",
    "title": "ANOVA de dos vías en R",
    "section": "Visualizar los resultados y agregar p-valores a los gráficos",
    "text": "Visualizar los resultados y agregar p-valores a los gráficos\n\nPor último, podemos visualizar los resultados del ANOVA en un gráfico de caja y añadir los valores p calculados de las comparaciones múltiples por pares.\n\n\n\n\n\n\n\n\n\n\nGráfico de interacción\n\nPodemos usar la librería effects para visualizar la interacción entre los factores. El grafico de interacción muestra cómo los efectos de un factor varían en función de los niveles de otro factor.\nPara esto, le pasamos el modelo ANOVA con interacción (res.aov3) a la función allEffects() y luego lo graficamos con plot()."
  },
  {
    "objectID": "docs/61-lineales-correlacion.html",
    "href": "docs/61-lineales-correlacion.html",
    "title": "Introducción a Correlación de Pearson y Spearman",
    "section": "",
    "text": "Antes de comenzar con el tema, hay que introducir dos conceptos que estaremos revisando: Pruebas de Hipótesis y las Hipótesis Nula y Alternativa. Aunque todavía no vemos formalmente el tema de pruebas de hipótesis, es importante tener una idea general de estos conceptos para entender mejor la correlación como un modelo lineal."
  },
  {
    "objectID": "docs/61-lineales-correlacion.html#hipótesis-nula-y-alternativa",
    "href": "docs/61-lineales-correlacion.html#hipótesis-nula-y-alternativa",
    "title": "Introducción a Correlación de Pearson y Spearman",
    "section": "Hipótesis nula y alternativa",
    "text": "Hipótesis nula y alternativa\n\nEn estadística, hablamos mucho de “hipótesis”. Esta es una afirmación que se hace sobre un parámetro de una población.\nPor ejemplo, podemos tener la hipótesis que la correlación entre dos variables es cero (no hay relación entre ellas).\nTambién podemos tener la hipótesis de que la media de una población es igual a un valor específico.\nLas hipótesis se prueban con pruebas estadísticas, y se pueden aceptar o rechazar en función de la evidencia.\nEn las pruebas estadísticas, siempre se plantea una hipótesis nula (\\(H_0\\)) y una hipótesis alternativa (\\(H_1\\)).\nLa hipótesis nula (\\(H_0\\)) es la afirmación que se somete a prueba, mientras que la hipótesis alternativa (\\(H_1\\)) es la afirmación que se acepta si se rechaza la hipótesis nula. ¿uhhh 😢?\n\nLa hipótesis nula (denotada como \\(H_0\\)) es una afirmación general o un supuesto inicial que se considera verdadero hasta que se presente suficiente evidencia estadística en su contra. En el contexto de la correlación entre dos variables, la hipótesis nula usualmente establece que no hay efecto o relación entre las variables. Por ejemplo, si estás analizando la correlación entre el índice de masa corporal (IMC) y la presión arterial sistólica (PAS), la hipótesis nula podría ser:\n\n\\(H_0\\): No hay correlación entre IMC y PAS\n\nLa hipótesis alternativa (\\(H_a\\) o \\(H_1\\)) es la afirmación que se acepta si los datos proporcionan evidencia suficiente para rechazar la hipótesis nula. En el mismo ejemplo del IMC y la PAS, la hipótesis alternativa podría ser:\n\n\\(H_a\\): Existe una correlación entre IMC y PAS. Esto significa que creemos que hay alguna relación entre las dos variables."
  },
  {
    "objectID": "docs/61-lineales-correlacion.html#introducción-a-la-correlación-como-un-modelo-lineal",
    "href": "docs/61-lineales-correlacion.html#introducción-a-la-correlación-como-un-modelo-lineal",
    "title": "Introducción a Correlación de Pearson y Spearman",
    "section": "Introducción a la Correlación como un Modelo Lineal",
    "text": "Introducción a la Correlación como un Modelo Lineal\n\nLa correlación de Pearson y Spearman son herramientas estadísticas fundamentales en el análisis de datos.\nAmbas correlaciones pueden interpretarse como casos especiales de modelos lineales simple, donde el objetivo es analizar la relación entre dos variables (como lo hicimos en el ejercicio pasado).\nEl concepto central de estas correlaciones se basa en un modelo de regresión lineal simple:\n\n\\[\ny = \\beta_0 + \\beta_1 \\cdot x\n\\]\nEn este modelo, \\(y\\) es la variable dependiente, \\(x\\) es la variable independiente, \\(\\beta_0\\) es el intercepto (valor de \\(y\\) cuando \\(x = 0\\)) y \\(\\beta_1\\) es la pendiente de la relación entre \\(x\\) e \\(y\\).\n\nCorrelación de Pearson: Mide la relación lineal entre dos variables continuas.\n\n\\(y = \\beta_0 + \\beta_1 \\cdot x\\)\nLa correlación de Pearson evalúa qué tan fuerte es la relación lineal entre dos variables continuas. Es sensible a valores atípicos y requiere que las variables sigan una distribución normal.\n\nCorrelación de Spearman: Mide la relación entre los rangos de dos variables, lo que la hace adecuada para datos no paramétricos o no lineales.\n\nEvalúa la relación entre los rangos de las dos variables, lo que la hace robusta frente a datos no normales y valores atípicos. Se basa en la correlación de Pearson, pero aplicada a los rangos de las variables.\nTambién es útil para datos ordinales: Cuando tratas con variables ordinales (datos que representan categorías con un orden natural), Spearman es más adecuado que Pearson.\n\n\nEn ambas correlaciones, la hipótesis nula \\(H_0\\) es que no hay relación entre las variables \\(\\beta_1 = 0\\).\n\n\n\n\n\n\n\nRangos, pruebas no paramétricas y la correlación de Spearman\n\n\n\nLa correlación de Spearman es una medida no paramétrica de la asociación entre dos variables.\nRango\n\nEn el contexto de la correlación de Spearman, el rango se refiere a la posición de un dato en una secuencia ordenada.\nPor ejemplo, si tienes un conjunto de datos, primero los ordenarías de menor a mayor y luego asignarías un número a su posición en esta secuencia, es decir, su “rango”. Así, el dato más pequeño tendría un rango de 1, el siguiente más pequeño un rango de 2, y así sucesivamente.\nEn la siguiente lección veremos más sobre los rangos.\n\nDatos No Paramétricos - Estos son datos que no necesariamente cumplen con los supuestos necesarios para métodos paramétricos (como la distribución normal). - Las pruebas no paramétricas no asumen que los datos sigan una distribución normal, lo cual es un requisito para muchas pruebas paramétricas. - En lugar de basarse en los valores reales de los datos, las pruebas no paramétricas se basan en los rangos, lo que les permite ser más flexibles y aplicables a una variedad más amplia de tipos de datos.\nPruebas paramétricas\nSe basan en asunciones específicas sobre la distribución de los datos de la población. Estas pruebas típicamente asumen que los datos son continuos, intervalos o métricos y siguen una distribución normal (gaussiana). Ejemplos de pruebas paramétricas incluyen:\n** Resumen**\nMientras que las pruebas paramétricas se sustentan en asunciones sobre la distribución de los datos y utilizan valores absolutos, las pruebas no paramétricas son más flexibles y suelen basarse en rangos para evaluar la evidencia en los datos sin asumir una distribución específica. Esto hace que las pruebas no paramétricas sean más adecuadas para datos ordinales, para datos con distribuciones no normales, o cuando los supuestos de las pruebas paramétricas no se cumplen."
  },
  {
    "objectID": "docs/61-lineales-correlacion.html#ejemplo-en-r-correlación-de-pearson-y-spearman",
    "href": "docs/61-lineales-correlacion.html#ejemplo-en-r-correlación-de-pearson-y-spearman",
    "title": "Introducción a Correlación de Pearson y Spearman",
    "section": "Ejemplo en R: Correlación de Pearson y Spearman",
    "text": "Ejemplo en R: Correlación de Pearson y Spearman\nUtilizaremos un ejemplo práctico para ilustrar cómo calcular e interpretar las correlaciones de Pearson y Spearman utilizando R y paquetes del tidyverse.\n\nPaso 1: Preparar el entorno y los datos\nPrimero, cargamos las librerías necesarias y generamos datos simulados para dos variables correlacionadas.\n\n\n\n\n\n\n\n\n\n\nPaso 2: Visualización de la Relación Lineal (Correlación de Pearson)\nAntes de calcular la correlación de Pearson, visualizamos la relación entre las dos variables con un gráfico de dispersión y ajustamos una línea de regresión.\n\n\n\n\n\n\n\n\n\n\nPaso 3: Cálculo de la Correlación de Pearson\nAhora, calculamos el coeficiente de correlación de Pearson y lo interpretamos.\n\nPara calcular la correlación de Pearson, usamos la función cor() con el argumento method = \"pearson\".\n\nEsta función toma los siguientes argumentos: x y y, que son las dos variables a comparar, y method, que especifica el tipo de correlación a calcular. Podemos usar \"pearson\" para la correlación de Pearson y \"spearman\" para la correlación de Spearman.\nNota que estamos usando una notación diferente para nombrar las variables x y y. En esta notación (que se utiliza en muchas funciones de R, aunque no en el tidyverse), se usa nombre_del_data_frame$nombre_de_la_variable para referirse a una variable en un data frame.\n\nEl coeficiente de correlación de Pearson varía entre -1 y 1, donde 1 indica una correlación positiva perfecta, -1 una correlación negativa perfecta y 0 no hay correlación.\n\n\n\n\n\n\n\n\n\n\n\nPaso 4: Cálculo de la Correlación de Spearman\nPara calcular la correlación de Spearman, simplemente usamos los rangos de los datos en lugar de los valores originales.\n\n\n\n\n\n\n\n\n\n\nPaso 5: Interpretación de los Resultados\n\nCorrelación de Pearson: El coeficiente nos dice qué tan fuerte es la relación lineal entre dos variables. Un valor cercano a 1 indica una fuerte relación positiva.\nCorrelación de Spearman: Nos indica qué tan fuerte es la relación entre los rangos de las dos variables. Es útil cuando los datos no siguen una distribución normal o tienen relaciones no lineales.\n\n\n\n\nEjercicio Práctico\n\nEjercicio 1: Correlación entre Peso y Altura\n\nUsa el conjunto de datos mtcars y calcula la correlación de Pearson entre el peso del vehículo (wt) y el consumo de combustible (mpg).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\n# Cargar los datos mtcars\ndata(mtcars)\n\n# Calcular la correlación de Pearson entre peso (wt) y mpg\ncor_mpg_wt_pearson &lt;- cor(mtcars$wt, mtcars$mpg, method = \"pearson\")\n\n# Calcular la correlación de Spearman entre peso (wt) y mpg\ncor_mpg_wt_spearman &lt;- cor(mtcars$wt, mtcars$mpg, method = \"spearman\")\n\n# Mostrar los resultados de las correlaciones\ncor_mpg_wt_pearson\ncor_mpg_wt_spearman\n\n\n\n\n\nEjercicio 2: Visualización de la Relación entre Peso y Consumo de Combustible\n\nCrea un gráfico de dispersión para visualizar la relación entre el peso y el consumo de combustible, e incluye una línea de regresión.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\n# Graficar la relación entre peso y mpg\nggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  labs(title = \"Relación entre Peso y Consumo de Combustible\", x = \"Peso (wt)\", y = \"Consumo de Combustible (mpg)\")"
  },
  {
    "objectID": "docs/61-lineales-correlacion.html#conclusión",
    "href": "docs/61-lineales-correlacion.html#conclusión",
    "title": "Introducción a Correlación de Pearson y Spearman",
    "section": "Conclusión",
    "text": "Conclusión\nLa correlación de Pearson y Spearman son métodos poderosos para evaluar relaciones entre variables. La correlación de Pearson es ideal para relaciones lineales en datos continuos y normalmente distribuidos, mientras que la correlación de Spearman es más robusta frente a datos no normales o relaciones no lineales. Ambos métodos pueden interpretarse como casos especiales de un modelo lineal simple, lo que unifica el concepto de correlación dentro del contexto más amplio de la regresión lineal."
  },
  {
    "objectID": "docs/51-ancova.html",
    "href": "docs/51-ancova.html",
    "title": "ANCOVA: Análisis de Covarianza",
    "section": "",
    "text": "Lección sobre ANCOVA: Análisis de Covarianza en Ciencias de la Salud y Biológicas\n\n\nIntroducción al ANCOVA\nEl Análisis de Covarianza (ANCOVA) es una extensión del ANOVA que incluye predictores continuos (covariables) junto con los predictores categóricos (que ya hemos visto en ANOVA). ANCOVA permite ajustar las diferencias entre grupos teniendo en cuenta una covariable continua, como la edad, el peso, o cualquier otra medida continua que pueda influir en la variable dependiente.\nEn un ANCOVA, el modelo lineal incluye tanto las variables categóricas (codificadas como dummy) como una o más variables continuas. Este análisis es útil cuando queremos ajustar los efectos de las variables categóricas por una covariable, mejorando la precisión de nuestras estimaciones.\n\n\n\n\nPuntos clave a enseñar:\n\nANCOVA como modelo lineal: El modelo lineal en un ANCOVA es similar a los que usamos en ANOVA, pero con la adición de un término que representa la covariable continua. Por ejemplo, en un ANCOVA unidireccional, el modelo sería:\n\\([\ny = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_3 \\cdot \\text{age}\\)]\n\n\\((\\beta_0\\)) es la intersección (la media para el primer grupo cuando la covariable es 0).\n\\((\\beta_1\\)), \\((\\beta_2\\)), etc. son los efectos de los grupos categóricos (codificados como dummy).\n\\((\\beta_3\\)) es el efecto de la covariable continua (en este caso, la edad).\n\nAjuste por covariables: El objetivo principal del ANCOVA es ajustar las diferencias entre los grupos teniendo en cuenta la influencia de una covariable. Esto permite estimar los efectos de los grupos categóricos de manera más precisa, controlando por la covariable.\nCodificación dummy: Al igual que en los ANOVAs anteriores, se utiliza la codificación dummy para representar los grupos categóricos, mientras que la covariable continua se incluye sin transformación.\nInterpretación: En un ANCOVA, se pueden interpretar tanto los efectos principales de los grupos categóricos como el efecto de la covariable continua. También es posible evaluar si la covariable tiene un efecto significativo en la variable dependiente.\n\n\n\n\nEjemplo en R: ANCOVA\nA continuación, realizamos un ANCOVA utilizando R y visualizamos los resultados.\n\nPaso 1: Generar los datos\nUtilizamos el conjunto de datos del ejemplo anterior (ANOVA unidireccional) y añadimos una covariable continua (age), que está correlacionada con la variable dependiente value.\n\n\n\n\n\n\n\n\n\n\nPaso 2: Codificación dummy para el ANCOVA\nCodificamos de manera explícita los grupos utilizando variables indicadoras (dummy variables), como en los ejemplos anteriores, y conservamos la covariable continua age.\n\n\n\n\n\n\n\n\n\n\nPaso 3: Visualización del ANCOVA\nCreamos una gráfica que muestra la relación entre la covariable age y la variable dependiente value, utilizando diferentes colores para los grupos.\n\n\n\n\n\n\n\n\n\n\nPaso 4: Códigos en R: ANCOVA\nPodemos realizar el ANCOVA utilizando la función aov() o el paquete car::Anova(). También podemos obtener el mismo resultado mediante un modelo lineal explícito que incluya tanto los grupos categóricos como la covariable continua.\n\n\n\n\n\n\n\n\n\n\nPaso 5: Interpretación de los resultados\nEn el resultado del ANCOVA, podemos examinar los efectos principales de los grupos y de la covariable age. La prueba de razón de verosimilitud nos permite verificar si la covariable age tiene un efecto significativo en la variable dependiente, y también si los grupos categóricos tienen un efecto significativo después de ajustar por age.\n\n\n\n\nEjercicio Práctico\n\nEjercicio 1: Usa el conjunto de datos mtcars para realizar un ANCOVA, comparando el consumo de combustible (mpg) según el número de cilindros (cyl), ajustando por el peso del automóvil (wt).\n\n\n\n\n\n\n\n\nEjercicio 2: Realiza un análisis de la significancia de la covariable wt y el factor cyl en el consumo de combustible (mpg) utilizando pruebas de razón de verosimilitud.\n\n\n\n\n\n\n\n\n\n\n\n\nConclusión\nEl ANCOVA es una herramienta estadística poderosa que combina los efectos de factores categóricos y covariables continuas en un solo modelo. Este análisis permite ajustar por covariables, proporcionando estimaciones más precisas de los efectos de los grupos categóricos. Al entender cómo integrar covariables en un modelo lineal, los estudiantes pueden aplicar ANCOVA para analizar datos más complejos en ciencias de la salud y biológicas, ajustando sus análisis por factores continuos importantes como la edad, el peso, o cualquier otra variable relevante."
  },
  {
    "objectID": "docs/34-medidas-dispersion-python.html",
    "href": "docs/34-medidas-dispersion-python.html",
    "title": "Medidas de Dispersión con Python",
    "section": "",
    "text": "Las medidas de dispersión nos informan sobre la variabilidad de un conjunto de datos.\n\nRango: Diferencia entre el valor máximo y mínimo.\nVarianza: Mide la dispersión promedio de los datos respecto a la media.\nDesviación estándar: Raíz cuadrada de la varianza; mide la dispersión en las mismas unidades que los datos.\nRango Intercuartílico (IQR): Diferencia entre el tercer y primer cuartil; mide la dispersión en la mitad central de los datos."
  },
  {
    "objectID": "docs/34-medidas-dispersion-python.html#medidas-de-dispersión",
    "href": "docs/34-medidas-dispersion-python.html#medidas-de-dispersión",
    "title": "Medidas de Dispersión con Python",
    "section": "",
    "text": "Las medidas de dispersión nos informan sobre la variabilidad de un conjunto de datos.\n\nRango: Diferencia entre el valor máximo y mínimo.\nVarianza: Mide la dispersión promedio de los datos respecto a la media.\nDesviación estándar: Raíz cuadrada de la varianza; mide la dispersión en las mismas unidades que los datos.\nRango Intercuartílico (IQR): Diferencia entre el tercer y primer cuartil; mide la dispersión en la mitad central de los datos."
  },
  {
    "objectID": "docs/34-medidas-dispersion-python.html#ejercicio-práctico-en-python",
    "href": "docs/34-medidas-dispersion-python.html#ejercicio-práctico-en-python",
    "title": "Medidas de Dispersión con Python",
    "section": "Ejercicio Práctico en Python",
    "text": "Ejercicio Práctico en Python\nUsarás un conjunto de datos simulado para calcular estas medidas y visualizar resultados."
  },
  {
    "objectID": "docs/34-medidas-dispersion-python.html#reflexión-y-discusión",
    "href": "docs/34-medidas-dispersion-python.html#reflexión-y-discusión",
    "title": "Medidas de Dispersión con Python",
    "section": "Reflexión y Discusión",
    "text": "Reflexión y Discusión\n\nAnaliza las medidas calculadas: ¿Cómo se comparan la media y la mediana en tus datos simulados? ¿Qué sugiere esto sobre la simetría de la distribución?\nConsidera el rango, la varianza y la desviación estándar: ¿Qué te indican estas medidas sobre la dispersión de los datos?\n\nEsta lección interactiva te ofrece una comprensión práctica de cómo las medidas de tendencia central y dispersión describen y resumen las características esenciales de un conjunto de datos. Estas herramientas son críticas para cualquier análisis estadístico, permitiendo una comprensión profunda y fundamentada de los datos bajo estudio."
  },
  {
    "objectID": "docs/31-visualizacion-datos.html#introducción",
    "href": "docs/31-visualizacion-datos.html#introducción",
    "title": "Ejercicio I Visualización y Distribución de Datos",
    "section": "Introducción",
    "text": "Introducción\n\nEn este ejercicio vamos a realizar gráficos utilizando ggplot.\n\nRecordemos lo siguiente:\n\nUn gráfico es un mapeo de variables de datos a atributos estéticos de objetos geométricos.\n\nTiene tres componentes principales:\n\nDatos (data, en inglés): el conjunto de datos compuesto por variables que mapeamos.\nGeometría (geom, por geometry en inglés): el objeto geométrico en cuestión. Se refiere al tipo de objeto que compone el gráfico, por ejemplo: puntos, líneas y barras.\nEstética (aes, por aesthetic en inglés): atributos estéticos del objeto geométrico. Por ejemplo, posición x, y, color, forma y tamaño. Cada atributo estético se puede asignar a una variable en nuestro conjunto de datos."
  },
  {
    "objectID": "docs/31-visualizacion-datos.html#ejemplo-de-la-gramática-en-un-gráfico",
    "href": "docs/31-visualizacion-datos.html#ejemplo-de-la-gramática-en-un-gráfico",
    "title": "Ejercicio I Visualización y Distribución de Datos",
    "section": "Ejemplo de la gramática en un gráfico",
    "text": "Ejemplo de la gramática en un gráfico\nVamos a ver un ejemplo de estos componentes en un gráfico, para ello vamos a utilizar el paquete gapminder que ya instalamos y cargamos por ti en este ejercicio.\nPara ver los datos de gapminder, escribe gapminder en el bloque de código que aparece abajo y luego haz click en el botón “Run Code”. También puedes usar la función head() para ver los primeros registros de los datos, o summary() para obtener un resumen de los datos, o str() para ver la estructura de los datos.\n\n\n\n\n\n\n\n\nComo ver, los datos de gapminder contienen información sobre la esperanza de vida (lifeExp), el PIB per cápita (gdpPercap) y la población de varios países a lo largo del tiempo. pop es la población, continent es el continente al que pertenece el país y year es el año de la observación.\n\nVeamos un gráfico a través de la gramática de los gráficos.\nEl siguiente gráfico está realizado con los datos de gapminder, intentemos reconocer que variables y secciones corresponden a la gramática de gráficos:\n\n\n\n\n\n\n\n\nMirando el código y el gráfico, podemos indentificar que:\n\nDatos: el nombre del conjunto de datos (gapminder) se asigna al atributo data\nEstética: el eje x representa la variable gdpPercap, el eje y representa la variable lifeExp, el color (o colour) representa la variable continent y el tamaño (size) representa la variable población.\nGeometría: generamos un gráfico de puntos, como indica la función geom_point()\n\n\n\nCambiemos algunas propiedades\nSupongamos que queremos cambiar los ejes del gráfico, ¿cómo cambiarías el código anterior para lograr ese cambio? Por ejemplo, ¿cómo cambiarías los ejes para que el eje x represente ela esperanza de vida y el eje y el PIB per capita?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nRecuerda que los ejes están representados por las letras x (horizontal) e y (vertical)\n\n\n\n\n\n\n\n\n\n\n\nSolucion:\n\n\n\n\n\nggplot(data = gapminder, \n       aes(x = lifeExp, y = gdpPercap, \n                     color = continent, \n                     size = gdpPercap)) +\n    geom_point()\n\n\n\n\nBien hecho!\nAdemás del gráfico de puntos, indicado en el código anterior por geom_point(), tenemos otros tipos de gráficos, por ejemplo gráficos de líneas, de barras, de áreas o histogramas.\n¿Cómo te parece que pueden llamarse las geometrías para los gráficos de lineas y de barras?\n\n\n\n\n\n\n\n\n\nviewof respuesta = Inputs.radio(\n  [ \"geom_line() y geom_bar()\", \"geom_linea(), geom_sup()\", \"geom_area(), geom_histogram()\", \"geom_line(), geom_area()\", \"Ninguna de las anteriores\"],\n  { value: \"Ninguna de las anteriores\", label: \"Marca tu respuesta\", class: \"vertical-radio\" }\n);\n\nhtml`${await do_respuesta(respuesta)}`"
  },
  {
    "objectID": "docs/31-visualizacion-datos.html#gráfico-de-lineas",
    "href": "docs/31-visualizacion-datos.html#gráfico-de-lineas",
    "title": "Ejercicio I Visualización y Distribución de Datos",
    "section": "Gráfico de lineas",
    "text": "Gráfico de lineas\nVamos a realizar otros gráficos utilizando los datos en gapminder. Para generar el gráfico de lineas, vamos a ver la evolución de la población de México en la serie de datos disponible. Los gráficos de líneas son útiles para mostrar la evolución de una variable a lo largo del tiempo.\nPrimero, filtra los datos de gapminder para obtener solo los datos de México y guárdalos en un nuevo dataset llamado Mex. Utiliza la función head() para ver los primeros registros de Mex. Para filtrar adecuadamente a México, NO utilices acentos en el nombre del país, pero si el nombre en mayúsculas (Mexico).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nRecuerda que el nombre del país es Mexico y que la variable que contiene el nombre del país es country.\nTambién recuerda la función filter()\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nMex &lt;- gapminder %&gt;%\n  filter(country == 'Mexico')\n\nhead(Mex)\n\n\n\n\nAhora, a partir de los datos de México, cre un gráfico de recta (geom_line()) donde se muestre en el eje x los años y en el y la población.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\n\nEl dataset se llama Mex\nLa variable que contiene los años se llama year\nLa variable que contiene la población se llama pop\n\n\n\n\n\n\n\n\n\n\n\n\nSolucion:\n\n\n\n\n\n1ggplot(data = Mex,\n2       mapping = aes(x = year, y = pop)) +\n    geom_line()\n\n1\n\nPasa el conjunto de datos Mex a la capa de datos (data).\n\n2\n\nMapea las variables year a al eje x y pop al eje y.\n\n\n\n\n\n\n\nHagamos un gráfico de barras\nHay dos formas de hacer un gráfico de barras en ggplot2, una forma es utilizando geom_bar() y otra es utilizando geom_col().\n\ngeom_bar() : utilizamos esta geometría cuando no tenemos una variable que contenga el cálculo de la cantidad o frecuencia de la variable categórica que queremos gráficar. Solo asignameros la variable categorica al eje x y ggplot realizará cálculo del valor del eje y por nosotros.\ngeom_col() : utilizamos esta geometría cuando tenemos en nuestro set de datos una variable con el cálculo de la cantidad o frecuencia de la variable categórica que queremos graficar. Vamos a usar la estética del eje y y le asignaremos la variable que tiene esa cantidad.\n\nVamos a transformar el gráfico anterior a barras. ¿Cómo realizarias este cambio?, ¿cuál de las dos opciones de geometrías utilizarías?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nLa variable pop ya contiene la cantidad de la población calculada.\nRecuerda que geom_bar solo asigna una variable categórica, mientras que geom_col podemos asignar otra variable al eje y.\n\n\n\n\n\n\n\n\n\n\n\nSolucion:\n\n\n\n\n\n\n1ggplot(data = Mex,\n2       mapping = aes(x = year, y = pop)) +.\n3    geom_col()\n    \n\n1\n\nPasa el conjunto de datos Mex a la capa de datos (data).\n\n2\n\nMapea las variables year a al eje x y pop al eje y.\n\n3\n\nUtilizamos geom_col() porque ya contamos con una variable que tiene calculada la cantidad que queremos representar\n\n\n\n\n\n\n\n\nHagamos un gráfico de área\nVamos a transformar el gráfico anterior a áreas.\nModifica el siguiente código para generar un gráfico de áreas que nos muestre los años en el eje x y la población en el eje y.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nRecuerda que el nombre de la geometría es la palabra en inglés, en linea es geom_line(), en barras es geom_bar(), para área es geom_ …\n\n\n\n\n\n\n\n\n\n\n\nSolucion:\n\n\n\n\n\nggplot(data = Mex, \n       mapping = aes(x = year, y = pop)) +\n1    geom_area()\n\n1\n\nUtilizamos geom_area() para generar el gráfico de áreas."
  },
  {
    "objectID": "docs/31-visualizacion-datos.html#visualizar-distribución-normal",
    "href": "docs/31-visualizacion-datos.html#visualizar-distribución-normal",
    "title": "Ejercicio I Visualización y Distribución de Datos",
    "section": "Visualizar Distribución Normal",
    "text": "Visualizar Distribución Normal\n\nRecuerda que la distribución normal tiene 2 parámetros, la media \\(\\mu\\) y la desviación estándar \\(\\sigma\\).\n\nPara una distribución normal estandarizada, la media es 0, \\(\\mu =\\)  y la desviación estándar es 1, \\(\\sigma =\\) , como se observa en el siguiente gráfico de densidad:\n\nimport {Tangle} from \"@mbostock/tangle\"\n\n// Setup Tangle reactive inputs\nviewof mean = Inputs.input(0);\nviewof sd = Inputs.input(1);\nmeanTgl = Inputs.bind(Tangle({min: -5, max: 5, minWidth: \"1em\", step: 0.1}), viewof mean);\nsdTgl = Inputs.bind(Tangle({min: 0, minWidth: \"1em\", step: 0.01}), viewof sd);\n\n// draw plot in R\ndraw_plot(mean, sd)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEscribe el código de R necesario para simular los valores de la distribución normal estandarizada (arriba) usando la función dnorm(). Cuando estés listo, haz click en el botón “Run Code” para ver el gráfico. Recuerda que dnorm() toma como argumentos el vector de valores (en este caso, x) y los parámetros que definen a la distribución normal.\n\n\n\n\n\n\n\n\n\nSolution:\n\n\nx &lt;- seq(-5, 5, length = 100)                                 # &lt;1&gt;\ny &lt;- dnorm(x, mean = ${mean}, sd = ${sd})                     # &lt;2&gt;\nplot(x, y, type = \"l\", lwd = 2, ylim = c(0,1))                # &lt;3&gt;\n1x &lt;- seq(-5, 5, length = 100)\n2y &lt;- dnorm(x, mean = ${mean}, sd = ${sd})\n3plot(x, y, type = \"l\", lwd = 2, ylim = c(0,1))\n\n\n\n1\n\nGenerar valores para el eje x.\n\n2\n\nGenera valores para y con distribución normal usando la función dnorm(), con media  y desviación estándar .\n\n3\n\nlos valores se grafican como una línea (type = \"l\")."
  },
  {
    "objectID": "docs/31-visualizacion-datos.html#fuentes",
    "href": "docs/31-visualizacion-datos.html#fuentes",
    "title": "Ejercicio I Visualización y Distribución de Datos",
    "section": "Fuentes",
    "text": "Fuentes\nEsperamos que esta pequeña introducción a los gráficos en R te sea de utilidad. A continuación te dejamos una serie de materiales que pueden resultar muy útiles para continuar aprendiendo y en los cuales basamos este tutorial.\n\nGuía rápida en Español de ggplot2\nRStudio primers en visualización de datos (en Inglés)\nCapítulo de Visualización de A ModernDive into R and the tidyverse. Chester Ismay and Albert Y. Kim, Foreword by Kelly S. McConville. November 25, 2019 (en Inglés)\nThe R Graph Gallery"
  },
  {
    "objectID": "docs/31-visualizacion-datos.html#licencia",
    "href": "docs/31-visualizacion-datos.html#licencia",
    "title": "Ejercicio I Visualización y Distribución de Datos",
    "section": "Licencia",
    "text": "Licencia\nEste curso se comparte bajo la licencia Creative Commons Attribution-ShareAlike 4.0 International License y fue realizado por Yanina Bellini Saibene y modificado por Santiago Garcia."
  },
  {
    "objectID": "docs/31.1-visualizacion-datos-python.html",
    "href": "docs/31.1-visualizacion-datos-python.html",
    "title": "Ejercicio I Visualización y Distribución de Datos con Python",
    "section": "",
    "text": "En este ejercicio vamos a realizar gráficos utilizando seaborn y matplotlib.\n\nRecordemos lo siguiente:\n\nUn gráfico es un mapeo de variables de datos a atributos estéticos de objetos geométricos.\n\nAunque la “gramática de los gráficos” es una conceptualización de ggplot2 en R, sus principios son útiles para construir visualizaciones de forma estructurada en cualquier lenguaje. Tiene tres componentes principales:\n\nDatos (data): el DataFrame de pandas que contiene las variables que queremos graficar.\nGeometría (geometry): el tipo de objeto que compone el gráfico. Por ejemplo: puntos, líneas y barras. En seaborn, esto se elige con la función de trazado (ej. scatterplot(), lineplot()).\nEstética (aesthetic): atributos de la geometría. Por ejemplo, la posición en los ejes x e y, el color, la forma y el tamaño. Cada atributo se puede asignar a una columna de nuestro DataFrame."
  },
  {
    "objectID": "docs/31.1-visualizacion-datos-python.html#introducción",
    "href": "docs/31.1-visualizacion-datos-python.html#introducción",
    "title": "Ejercicio I Visualización y Distribución de Datos con Python",
    "section": "",
    "text": "En este ejercicio vamos a realizar gráficos utilizando seaborn y matplotlib.\n\nRecordemos lo siguiente:\n\nUn gráfico es un mapeo de variables de datos a atributos estéticos de objetos geométricos.\n\nAunque la “gramática de los gráficos” es una conceptualización de ggplot2 en R, sus principios son útiles para construir visualizaciones de forma estructurada en cualquier lenguaje. Tiene tres componentes principales:\n\nDatos (data): el DataFrame de pandas que contiene las variables que queremos graficar.\nGeometría (geometry): el tipo de objeto que compone el gráfico. Por ejemplo: puntos, líneas y barras. En seaborn, esto se elige con la función de trazado (ej. scatterplot(), lineplot()).\nEstética (aesthetic): atributos de la geometría. Por ejemplo, la posición en los ejes x e y, el color, la forma y el tamaño. Cada atributo se puede asignar a una columna de nuestro DataFrame."
  },
  {
    "objectID": "docs/31.1-visualizacion-datos-python.html#ejemplo-de-la-gramática-en-un-gráfico",
    "href": "docs/31.1-visualizacion-datos-python.html#ejemplo-de-la-gramática-en-un-gráfico",
    "title": "Ejercicio I Visualización y Distribución de Datos con Python",
    "section": "Ejemplo de la gramática en un gráfico",
    "text": "Ejemplo de la gramática en un gráfico\nVamos a ver un ejemplo de estos componentes en un gráfico. Para ello, vamos a utilizar el paquete gapminder, que contiene datos de desarrollo mundial.\nPrimero, necesitamos instalar las librerías necesarias.\n# | echo: true\npip install pandas gapminder seaborn matplotlib\nAhora, carguemos los datos y veámoslos. Para ver los datos de gapminder, carga los datos en un DataFrame y luego utiliza el método .head() para ver los primeros registros, .describe() para un resumen estadístico, o .info() para ver la estructura.\n\n\n\n\n\n\n\n\nComo puedes ver, los datos de gapminder contienen información sobre la esperanza de vida (lifeExp), el PIB per cápita (gdpPercap) y la población (pop) de varios países a lo largo del tiempo.\n\nVeamos un gráfico a través de la gramática de los gráficos.\nEl siguiente gráfico está realizado con los datos de gapminder. Intentemos reconocer qué variables y secciones corresponden a la gramática de gráficos:\n\n\n\n\n\n\n\n\nMirando el código y el gráfico, podemos identificar que:\n\nDatos: el DataFrame df se asigna al parámetro data.\nEstética: el eje x representa la variable gdpPercap, el eje y representa lifeExp, el color (o hue) representa continent y el tamaño (size) representa la población (pop).\nGeometría: generamos un gráfico de puntos, como indica la función scatterplot().\n\n\n\nCambiemos algunas propiedades\nSupongamos que queremos cambiar los ejes del gráfico. ¿Cómo cambiarías el código anterior para que el eje x represente la esperanza de vida y el eje y el PIB per cápita?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nRecuerda que los ejes están representados por los parámetros x (horizontal) e y (vertical). Los valores deben ser los nombres de las columnas como cadenas de texto.\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¡Bien hecho!\nAdemás del gráfico de puntos (scatterplot), seaborn ofrece otros tipos de gráficos, como gráficos de líneas, de barras o histogramas.\n¿Cómo te parece que pueden llamarse las funciones para los gráficos de líneas y de barras en seaborn?\n\n\nRespuesta\n\n¡Buen trabajo si pensaste en lineplot() y barplot()! Esas son las funciones para gráficos de líneas y de barras, respectivamente."
  },
  {
    "objectID": "docs/31.1-visualizacion-datos-python.html#gráfico-de-líneas",
    "href": "docs/31.1-visualizacion-datos-python.html#gráfico-de-líneas",
    "title": "Ejercicio I Visualización y Distribución de Datos con Python",
    "section": "Gráfico de líneas",
    "text": "Gráfico de líneas\nVamos a realizar otros gráficos utilizando los datos en gapminder. Para generar el gráfico de líneas, vamos a ver la evolución de la población de México. Los gráficos de líneas son útiles para mostrar la evolución de una variable a lo largo del tiempo.\nPrimero, filtra los datos de gapminder para obtener solo los datos de México y guárdalos en un nuevo DataFrame llamado mex_df. Utiliza el método .head() para ver los primeros registros.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nRecuerda que el nombre del país es Mexico y que la columna que contiene el nombre del país es country.\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAhora, a partir de los datos de México, crea un gráfico de línea (lineplot()) donde se muestre en el eje x los años y en el y la población.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nEl DataFrame se llama mex_df.\nLa variable que contiene los años se llama year.\nLa variable que contiene la población se llama pop.\n\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHagamos un gráfico de barras\nEn seaborn, barplot() es ideal cuando tienes una variable para el eje x (categórica) y otra para la altura de la barra en el eje y (numérica). Esto es similar a geom_col() de ggplot2.\nSi solo tuvieras una variable categórica y quisieras contar sus ocurrencias, usarías countplot(), que es similar a geom_bar().\nVamos a transformar el gráfico anterior a barras. Ya que tenemos la población (pop) para cada año (year), usaremos barplot().\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nLos parámetros son los mismos que en el lineplot anterior.\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHagamos un gráfico de área\nSeaborn no tiene una función directa para gráficos de área como geom_area(), pero podemos usar matplotlib para esto con la función fill_between().\nModifica el siguiente código para generar un gráfico de áreas que nos muestre los años en el eje x y la población en el eje y.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nNecesitas pasar la columna year como el primer argumento (eje x) y la columna pop como el segundo (eje y).\n\n\n\n\n\n\n\n\n\nSolución"
  },
  {
    "objectID": "docs/31.1-visualizacion-datos-python.html#visualizar-distribución-normal",
    "href": "docs/31.1-visualizacion-datos-python.html#visualizar-distribución-normal",
    "title": "Ejercicio I Visualización y Distribución de Datos con Python",
    "section": "Visualizar Distribución Normal",
    "text": "Visualizar Distribución Normal\n\nRecuerda que la distribución normal tiene 2 parámetros: la media (\\(mu\\)) y la desviación estándar (\\(sigma\\)).\n\nPara visualizarla en Python, usamos numpy para generar los datos y seaborn o matplotlib para graficar.\nEscribe el código de Python necesario para simular y graficar los valores de una distribución normal estándar (media=0, desviación estándar=1) usando numpy.random.normal() y seaborn.histplot.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nLa media se especifica con el parámetro loc y la desviación estándar con scale. Para una distribución normal estándar, ambos son 0 y 1 respectivamente.\n\n\n\n\n\n\n\n\n\nSolución"
  },
  {
    "objectID": "docs/31.1-visualizacion-datos-python.html#fuentes",
    "href": "docs/31.1-visualizacion-datos-python.html#fuentes",
    "title": "Ejercicio I Visualización y Distribución de Datos con Python",
    "section": "Fuentes",
    "text": "Fuentes\nEsperamos que esta pequeña introducción a los gráficos en Python te sea de utilidad. A continuación te dejamos una serie de materiales que pueden resultar muy útiles para continuar aprendiendo:\n\nGalería de ejemplos de Seaborn\nTutorial de visualización de datos de Seaborn\nGalería de Matplotlib\nGuía de uso de Pandas"
  },
  {
    "objectID": "docs/31.1-visualizacion-datos-python.html#licencia",
    "href": "docs/31.1-visualizacion-datos-python.html#licencia",
    "title": "Ejercicio I Visualización y Distribución de Datos con Python",
    "section": "Licencia",
    "text": "Licencia\nEste curso se comparte bajo la licencia Creative Commons Attribution-ShareAlike 4.0 International License y fue realizado por Yanina Bellini Saibene, modificado por Santiago Garcia y traducido a Python por un asistente de IA."
  },
  {
    "objectID": "docs/23-tendencia-central-dispersion-python.html",
    "href": "docs/23-tendencia-central-dispersion-python.html",
    "title": "Tendencia Central y Dispersión en Python",
    "section": "",
    "text": "Las medidas de tendencia central y dispersión son fundamentales para describir y entender la distribución de los datos.\nEn Python, puedes calcularlas fácilmente con pandas y numpy."
  },
  {
    "objectID": "docs/23-tendencia-central-dispersion-python.html#introducción",
    "href": "docs/23-tendencia-central-dispersion-python.html#introducción",
    "title": "Tendencia Central y Dispersión en Python",
    "section": "",
    "text": "Las medidas de tendencia central y dispersión son fundamentales para describir y entender la distribución de los datos.\nEn Python, puedes calcularlas fácilmente con pandas y numpy."
  },
  {
    "objectID": "docs/23-tendencia-central-dispersion-python.html#simulación-de-datos-de-alturas-de-jirafas",
    "href": "docs/23-tendencia-central-dispersion-python.html#simulación-de-datos-de-alturas-de-jirafas",
    "title": "Tendencia Central y Dispersión en Python",
    "section": "Simulación de datos de alturas de jirafas",
    "text": "Simulación de datos de alturas de jirafas\nSupongamos que tenemos dos grupos de jirafas de dos islas diferentes:"
  },
  {
    "objectID": "docs/23-tendencia-central-dispersion-python.html#medidas-de-tendencia-central",
    "href": "docs/23-tendencia-central-dispersion-python.html#medidas-de-tendencia-central",
    "title": "Tendencia Central y Dispersión en Python",
    "section": "Medidas de tendencia central",
    "text": "Medidas de tendencia central"
  },
  {
    "objectID": "docs/23-tendencia-central-dispersion-python.html#medidas-de-dispersión",
    "href": "docs/23-tendencia-central-dispersion-python.html#medidas-de-dispersión",
    "title": "Tendencia Central y Dispersión en Python",
    "section": "Medidas de dispersión",
    "text": "Medidas de dispersión"
  },
  {
    "objectID": "docs/23-tendencia-central-dispersion-python.html#visualización-de-la-distribución-y-medidas",
    "href": "docs/23-tendencia-central-dispersion-python.html#visualización-de-la-distribución-y-medidas",
    "title": "Tendencia Central y Dispersión en Python",
    "section": "Visualización de la distribución y medidas",
    "text": "Visualización de la distribución y medidas"
  },
  {
    "objectID": "docs/23-tendencia-central-dispersion-python.html#reflexión",
    "href": "docs/23-tendencia-central-dispersion-python.html#reflexión",
    "title": "Tendencia Central y Dispersión en Python",
    "section": "Reflexión",
    "text": "Reflexión\n\n¿Qué diferencias observas entre los grupos?\n¿Cómo se relacionan la media, mediana y moda en cada grupo?\n¿Qué nos dice la dispersión sobre la variabilidad de las alturas?\n\nEstas herramientas te permiten describir y visualizar la estructura de tus datos en Python."
  },
  {
    "objectID": "docs/31.r-visualizacion-datosll.html",
    "href": "docs/31.r-visualizacion-datosll.html",
    "title": "Visualización de Datos II",
    "section": "",
    "text": "Además de los histogramas, los cuales representan la distribución de una variable continua dividiendo los datos en intervalos, existen otras formas de visualizar la distribución de datos. Dependiendo de la naturaleza de los datos y el objetivo de la visualización, es posible utilizar distintos gráficos para explorar y comunicar patrones en los datos."
  },
  {
    "objectID": "docs/31.r-visualizacion-datosll.html#introducción",
    "href": "docs/31.r-visualizacion-datosll.html#introducción",
    "title": "Visualización de Datos II",
    "section": "Introducción",
    "text": "Introducción\n\nPara esta lección, seguiremos utilizando el paquete ggplot2 en R para crear visualizaciones avanzadas de datos.\nUsaremos el juego de datos pinguinos que utilizamos en el módulo pasado, que contiene información sobre tres especies de pingüinos: Adelia, Papúa y Barbijo.\nPrimero, carguemos las librerías necesarias y exploremos el conjunto de datos.\n\n\n\n\n\n\n\n\n\nEl conjunto de datos pinguinos contiene las siguientes variables:\n\n\n\nVariable Name\nDescription\n\n\n\n\nespecie\nEspecie de pingüino\n\n\nisla\nIsla donde se encontró el pingüino\n\n\nlargo_pico_mm\nLongitud del pico en milímetros\n\n\nalto_pico_mm\nProfundidad del pico en milímetros\n\n\nlargo_aleta_mm\nLongitud de la aleta en milímetros\n\n\nmasa_corporal_g\nMasa corporal en gramos\n\n\nsexo\nSexo del pingüino\n\n\nanio\nAño de la medición\n\n\n\n\n\n\n\n\n\nDefinir un tema global para ggplot\n\n\n\n\nComo ya vimos, podemos usar temas de ggplot para personalizar la apariencia de nuestros gráficos.\nPara no tener que estar especificando el tema en cada gráfico, podemos definir un tema global que se aplique a todos los gráficos que creemos.\nAdemás, esto nos permite mantener la consistencia en la apariencia de nuestros gráficos.\nPara esto, usamos la función theme_set() y especificamos el tema que queremos aplicar. Por ejemplo, vamos a aplicar el tema clásico a todos nuestros gráficos con este código (el código se ejecuta automáticamente al cargar esta página):\n\n\n\n\n\n\n\n\n\n\nPuedes conocer más sobre los temas de ggplot en la este enlace."
  },
  {
    "objectID": "docs/31.r-visualizacion-datosll.html#histogramas-y-gráficos-de-densidad",
    "href": "docs/31.r-visualizacion-datosll.html#histogramas-y-gráficos-de-densidad",
    "title": "Visualización de Datos II",
    "section": "Histogramas y gráficos de densidad",
    "text": "Histogramas y gráficos de densidad\n\nRecordemos cómo hacer un histogramas, los cuales son una forma común de visualizar la distribución de una variable continua.\nA continuación, crearemos un histograma de la masa corporal de los pingüinos.\n\n\n\n\n\n\n\n\n\n\nLa mayoría de las veces, nos interesa ver cómo se distribuyen los datos en función de una variable categórica.\nPor ejemplo, podemos querer comparar la distribución de la masa corporal de los pingüinos en cada una de las 3 especies del juego de datos.\nPara esto, podemos usar la función de ggplot facet_grid() para dividir el gráfico en paneles según la variable categórica especie. Observa que utilizamos el operador ~ para indicar que queremos dividir el gráfico por la variable especie.\n\n\n\n\n\n\n\n\n\n\nOtra forma de visualizar la distribución de una variable continua es mediante un gráfico de densidad.\nEstos gráficos son similares a los histogramas, pero en lugar de dividir los datos en intervalos, muestran la distribución de los datos como una curva suave.\nEn estos gráficos, en lugar de representar la frecuencia de los datos, se muestra la densidad de probabilidad de los datos. El área bajo la curva es igual a 1 ya que representa la probabilidad total de los datos.\nAhora, en lugar de usar la función geom_histogram(), usaremos la función geom_density() para crear un gráfico de densidad de la masa corporal de los pingüinos.\n\n\n\n\n\n\n\n\n\n\nEn este tipo de gráficos, podemos decirle a ggplot que divida los datos en función de una variable categórica, de manera similar a lo que hicimos con los histogramas.\nPodríamos usar de nuevo la función facet_grid() para dividir el gráfico en paneles según la variable categórica especie. Sin embargo, en este caso, usaremos la función fill para colorear las curvas de densidad según la variable categórica especie.\nEn este caso, no vamos a dividir el gráfico en paneles, sino que vamos a superponer las curvas de densidad de las tres especies de pingüinos en un solo gráfico para compararlas facilmente. Para facilitar la comparación, observa que pasamos el argumento alpha = 0.5 a la función geom_density() para hacer las curvas semitransparentes. alpha controla la transparencia de los elementos del gráfico, con 0 siendo completamente transparente y 1 siendo completamente opaco.\n\n\n\n\n\n\n\n\n\nComparación entre geom_histogram() y geom_density()\n\n\n\n\n\n\n\n\nCaracterística\ngeom_histogram()\ngeom_density()\n\n\n\n\nTipo de gráfico\nBarras que muestran la frecuencia de los datos en intervalos\nCurva suave de densidad de probabilidad\n\n\nRepresentación\nFrecuencia absoluta (o densidad si se normaliza) por intervalo\nDensidad de probabilidad continua\n\n\nAjuste o suavizado\nDepende del número de bins o del ancho de los bins\nEstimador de densidad kernel (KDE)\n\n\nFlexibilidad\nDepende de la elección de los bins\nMás flexible y suave, no depende de intervalos\n\n\nInterpretación\nFrecuencia de los datos en grupos específicos\nTendencia general de la distribución de los datos\n\n\n\n\nTips para graficar histogramas y densidades\n\nSobreponer histograma y densidad\n\nEn ocasiones, es útil superponer un histograma y una gráfica de densidad para comparar la distribución de los datos de manera más efectiva.\nEsto puede ayudarte a visualizar la forma de la distribución y cómo se ajusta la densidad a los datos observados en el histograma.\nPara hacer esto, simplemente agregamos las dos capas al gráfico utilizando geom_histogram() y geom_density().\nObserva que usamos el argumento aes(y = ..density..) en geom_histogram(). Esto es para normalizar el histograma, de manera que su altura sea comparable con la curva de densidad generada por geom_density(). Es decir, en lugar de mostrar la frecuencia absoluta (número de observaciones en cada intervalo), normalizamos el histograma para que la suma de las alturas de las barras sea igual a 1, lo que permite comparar la forma de la distribución con la curva de densidad.\nOtro argumento nuevo que aparece en este código es position = \"identity dentro de geom_histogram(). Este argumento especifica cómo se deben posicionar los elementos gráficos (como barras, puntos, líneas, etc.) cuando hay superposición de datos. El argumento position = “identity” le dice a ggplot2 que no ajuste la posición de los elementos gráficos y que los dibuje en su ubicación original, es decir, en el mismo lugar donde los datos pertenecen. Esto es especialmente útil cuando quieres superponer varias capas de gráficos, como un histograma y una curva de densidad, o cuando estás comparando varias categorías en un mismo gráfico. Cuando tienes múltiples grupos o categorías, por defecto, ggplot2 trata de ajustar la posición de los elementos gráficos para que no se superpongan completamente.\nOtros argumentos de posición son: “stack” (apila los elementos), “dodge” (distribuye los elementos uno al lado del otro), “fill” (apila los elementos y los rellena), “jitter” (agrega un poco de ruido a los elementos para evitar la superposición), entre otros. Algunos de estos ejemplos irán apareciendo en lecciones futuras.\n\n\n\n\n\n\n\n\n\n\n\nVisualizar la media en un histograma\n\nEn ocasiones, es útil visualizar la media de una variable en un histograma para tener una idea de la ubicación central de los datos.\nPara hacer esto, podemos agregar una línea vertical al histograma que represente la media de los datos.\nEn el siguiente código, calculamos la media de la masa corporal de los pingüinos y la agregamos al histograma utilizando la función geom_vline().\nObserva que geom_vline() tiene los siguientes argumentos: xintercept (la posición en el eje x donde se dibujará la línea vertical), color (el color de la línea), linetype (el tipo de línea, puede ser “solid”, “dashed”, “dotted”, entre otros) y size (el grosor de la línea).\nEl argumento aes(xintercept = mean(masa_corporal_g, na.rm = TRUE)) calcula directamente la media de masa_corporal_g dentro de ggplot. El parámetro na.rm = TRUE asegura que se ignoren los valores faltantes (NA)."
  },
  {
    "objectID": "docs/31.r-visualizacion-datosll.html#boxplots-y-violin-plots",
    "href": "docs/31.r-visualizacion-datosll.html#boxplots-y-violin-plots",
    "title": "Visualización de Datos II",
    "section": "Boxplots y Violin Plots",
    "text": "Boxplots y Violin Plots\n\nBoxplots\n\nLos boxplots y los violin plots son gráficos que permiten visualizar la distribución de una variable continua en función de una variable categórica.\nLos boxplots son gráficos que muestran la distribución de los datos a través de sus cuartiles y resaltan valores atípicos.\nCuartil: Un cuartil es un valor que divide un conjunto de datos ordenados en cuatro partes iguales. El primer cuartil (Q1) es el valor que deja el 25% de los datos por debajo, el segundo cuartil (Q2) es la mediana y el tercer cuartil (Q3) es el valor que deja el 75% de los datos por debajo. En una distribución normal, la mediana es igual a Q2.\nValor atípico: Un valor atípico es un valor que es significativamente diferente del resto de los datos en un conjunto. En un boxplot, los valores atípicos se representan como puntos individuales fuera de los “bigotes” del gráfico. Estos puntos, también llamados outliers, son valores que caen fuera de 1.5 veces el rango intercuartílico (IQR) por encima del tercer cuartil o por debajo del primer cuartil y pueden ser indicativos de errores en los datos o de fenómenos inusuales. Dependiendo del contexto, los valores atípicos pueden ser eliminados, transformados o analizados en detalle.\n\n\n\nMediana: La línea dentro de la caja representa la mediana de la distribución.\nCuartiles: Los extremos de la caja muestran el primer cuartil (Q1) y el tercer cuartil (Q3), es decir, el 25% y el 75% de los datos.\nRango intercuartílico (IQR): Es el rango entre Q1 y Q3, y la longitud de la caja representa este rango.\nBigotes (whiskers): Se extienden hasta 1.5 veces el IQR desde los cuartiles. Más allá de estos bigotes, los puntos se consideran valores atípicos.\nValores atípicos (outliers): Los puntos individuales que caen fuera de los bigotes se consideran atípicos y se muestran como puntos.\nPara crear un boxplot en ggplot, usamos la función geom_boxplot().\nComo vamos a ver la distribución de una variable contínua (masa_corporal_g) en función de una variable categórica (en este caso especie), usaremos aes(x = especie, y = masa_corporal_g) para mapear las variables al gráfico.\n\n\n\n\n\n\n\n\n\n\nObserva que la caja de nuestro boxplot se ve dividida en tres partes: la línea en el medio de la caja representa la mediana. Como nuestros datos están distribuídos aproximadamente de manera normal, la mediana divide los datos en dos partes iguales. Si los datos no están distribuídos de manera normal, la mediana no necesariamente divide los datos en dos partes iguales.\nAdemás, podemos ver la dispersión de las masas en las 3 especies. Esta dispersión se observa en la extensión del del boxplot, que representan el rango de los datos. Por lo tanto, una variable con alta dispersión tendrá un boxplot más largo.\nObserva que la especie “Barbijo” tiene 2 valores atípicos, representados como puntos individuales fuera de los “bigotes” del gráfico.\nRápidamente podemos ver que la especie Papua tiene una mediana de masa más alta que las otras dos especies. Sin embargo, esta no es una comparación formal de las medias. Para esto, necesitaríamos realizar un análisis estadístico como una prueba t o un análisis de varianza (ANOVA) que se verán más adelante en el curso.\n\n\n\nViolín\n\nAhora, un gráfico de violín es una forma de visualizar la distribución de los datos que combina aspectos del boxplot y el gráfico de densidad.\nLa forma del “violín” muestra la densidad de los datos en varios puntos a lo largo del eje y, lo que permite ver dónde se encuentran la mayoría de los datos (zonas más anchas) y las zonas menos densas (zonas más estrechas).\nTambién podemos ver la simetría de nuestros datos: si el gráfico de violín es simétrico, significa que tenemos aproximadamente la misma densidad en ambos lados.\nA diferencia del boxplot, que solo muestra un resumen de los datos, el gráfico de violín te permite ver la forma completa de la distribución.\n\nPuedes pensar en un gráfico de violín como un histograma girado 90 grados y reflejado a lo largo del eje y, por ejemplo:\n\n\n\n\n\n\n\n\n\n\nAdicionalmente, es una forma más visual de comparar la distribución de los datos entre diferentes categorías cuando tenemos muchos datos.\nPor ejemplo, observa que es más fácil comparar la distribución de la masa corporal entre las diferentes especies de pingüinos divididos por isla y sexo en un solo gráfico. En este caso, usamos facet_grid(~ isla) para dividir el gráfico en paneles según la variable categórica isla y fill = sexo para colorear los violines según la variable categórica sexo.\n\n\n\n\n\n\n\n\n\n\n\nResumen\nComparación entre geom_boxplot() y geom_violin()\n\n\n\n\n\n\n\n\nCaracterística\ngeom_boxplot()\ngeom_violin()\n\n\n\n\nResumen de datos\nMediana, cuartiles, valores atípicos\nDensidad de los datos, opcionalmente mediana y cuartiles\n\n\nDistribución completa\nNo muestra la distribución completa, solo un resumen\nMuestra la distribución completa, incluyendo densidades\n\n\nValores atípicos\nLos muestra explícitamente\nNo se muestran explícitamente, pero puedes añadir un boxplot\n\n\nVentajas\nSencillo, compacto, destaca valores atípicos\nMuestra la forma completa de la distribución, útil para datos complejos\n\n\nCuándo usar\nComparaciones simples entre grupos, detección de outliers\nComparación de la distribución general, especialmente si es multimodal\n\n\n\n¿Cuándo usar cada uno?\nUsar geom_boxplot(): - Cuando necesitas un resumen claro y conciso de la distribución que incluya la mediana, los cuartiles y los valores atípicos. - Cuando quieres comparar varios grupos de manera rápida y eficiente. - Cuando estás interesado en la variabilidad y los valores atípicos, porque los boxplots destacan los outliers de forma clara.\nUsar geom_violin(): - Cuando te interesa la forma general de la distribución de los datos, no solo un resumen. - Cuando sospechas que los datos tienen una distribución compleja, por ejemplo, si es multimodal (con varios picos) o asimétrica. - Cuando quieres comparar densidades entre grupos y ver dónde se concentra la mayor parte de los datos. - Si prefieres una visualización más detallada y estética que muestre la forma completa de los datos."
  },
  {
    "objectID": "docs/31.r-visualizacion-datosll.html#ver-asociaciones-entre-2-variables-continuas",
    "href": "docs/31.r-visualizacion-datosll.html#ver-asociaciones-entre-2-variables-continuas",
    "title": "Visualización de Datos II",
    "section": "Ver asociaciones entre 2 variables continuas",
    "text": "Ver asociaciones entre 2 variables continuas\n\nHasta ahora, hemos visto cómo visualizar la distribución de una variable continua en función de una variable categórica.\nAhora, vamos a explorar cómo visualizar la relación entre dos variables continuas, como la masa corporal y la longitud de la aleta de los pingüinos.\nUn gráfico de dispersión es una herramienta útil para visualizar la relación entre dos variables cuantitativas. En este tipo de gráfico, cada punto representa una observación, con una variable en el eje x y otra en el eje y. Por ejemplo, si tenemos datos de animales, como altura y peso, podemos usar un gráfico de dispersión para explorar si existe una relación entre estas dos variables.\nPara crear un gráfico de dispersión en ggplot, usamos la función geom_point() y mapeamos las variables al eje x y y. Toma el argumento de size para controlar el tamaño de los puntos y el argumento alpha para controlar la transparencia de los puntos.\nVamos a explora la relación entre el largo de la aleta y la masa corporal de los pinguinos.\n\n\n\n\n\n\n\n\n\n\nEste gráfico te permite explorar si existe alguna relación entre la masa corporal y la longitud de aleta de los pingüinos.\nPodemos ver muy claramente que en todas las especies, la masa corporal y la longitud de aleta están positivamente correlacionadas: a medida que la masa corporal aumenta, también lo hace la longitud de aleta.\nEste concepto será importante cuando exploremos correlaciones y regresiones en lecciones futuras ya que nos permitirá entender cómo dos variables se relacionan entre sí.\n\n\n\n\n\n\n\nTip\n\n\n\n\nUna forma fácil de explorar todas las relaciones entre variables continuas en un conjunto de datos es mediante un gráfico de pares.\nEn un gráfico de pares, se muestran todas las combinaciones posibles de gráficos de dispersión entre las variables continuas en un conjunto de datos.\nEsto puede ser útil para identificar patrones y asociaciones entre las variables, en especial si tienes muchas variables continuas en tus datos.\nPara esto vamos a usar la función ggpairs() del paquete GGally. Especificamos las columnas que queremos incluir en el gráfico de pares con el argumento columns.\nPor el momento no te preocupes por el código ni los valores de correlación, simplemente observa cómo se ven las relaciones entre las variables en el gráfico de pares. En lecciones futuras, profundizaremos en cómo interpretar estos gráficos y cómo calcular correlaciones y regresiones.\nA simple vista, ¿puedes identificar alguna relación entre las variables en el gráfico de pares? Observa cómo masa corporal y largo de aleta siguen un patrón muy claro, donde a medida que una variable aumenta, la otra también lo hace. También pon atención en la relación de alto_pico y largo_aleta, donde se observan dos grupos claramente diferenciados: uno con pinguinos de menor largo de aleta y mayor alto de pico (Adelia y Barbijo) y otro con pinguinos de mayor largo de aleta y menor alto de pico (Papúa). Otras relaciones como masa corporal y alto de pico no parecen tener una relación tan clara. Sin embargo, recuerda que estas son solo observaciones visuales y no análisis formales de correlación, las cuales veremos más adelante.\n\n\n\n\n\n\n\n\n\n\nNOTA 1: Observa que en este gráfico especificamos un nuevo tema con + theme_bw(). A pesar de que al inicio especificamos un tema global, podemos cambiar el tema de un gráfico específico de esta forma. En este caso, usamos theme_bw() porque incorpora una cuadrícula de fondo que facilita la visualización de los gráficos de dispersión.\nNOTA 2: En este gráfico de pares, cada celda muestra un gráfico de dispersión entre dos variables. La diagonal principal muestra un histograma de cada variable. Los valores en la parte inferior de cada celda son los coeficientes de correlación de Pearson entre las dos variables. Estos valores varían entre -1 y 1, donde -1 indica una correlación negativa perfecta, 1 indica una correlación positiva perfecta y 0 indica que no hay correlación. En lecciones futuras, veremos cómo interpretar estos valores y cómo calcular correlaciones y regresiones de manera más formal."
  },
  {
    "objectID": "docs/31.r-visualizacion-datosll.html#conteos",
    "href": "docs/31.r-visualizacion-datosll.html#conteos",
    "title": "Visualización de Datos II",
    "section": "Conteos",
    "text": "Conteos\n\nCuando estamos interesados en visualizar magnitudes asociadas a diferentes categorías (por ejemplo, las ventas de distintas marcas de autos o las poblaciones de diferentes ciudades), el gráfico más común es el gráfico de barras.\nEste tipo de gráfico es ideal para mostrar cantidades asociadas a categorías, donde el enfoque principal es la magnitud de los valores numéricos.\nEn un gráfico de barras estándar, las alturas de las barras representan la cantidad, como el número de observaciones en cada categoría.\nExisten varias variaciones de gráficos de barras, como las barras apiladas o agrupadas o el heatmap (mapa de calor) que se verán al final del curso.\nEn ggplot2, el gráfico de barras básico se puede crear con geom_bar(), que cuenta automáticamente las observaciones en cada categoría.\nNOTA: Si quieres que las alturas de las barras representen un valor numérico específico (en lugar de contar observaciones), puedes usar geom_col(). geom_col() lo veremos más adelante ya que es un gráfico muy utilizado en pruebas estadísticas que comparan medias. Aquí nos enfocaremos en geom_bar() que solo cuenta observaciones.\n\n\n\n\n\n\n\n\n\n\nConteo automático en el eje Y: geom_bar() cuenta automáticamente el número de observaciones (pingüinos) en cada categoría.\n\n\n\n\n\n\n\nNote\n\n\n\nSolo como nota, si en lugar de contar las observaciones, quisieras mostrar un valor numérico específico (por ejemplo, el promedio de la masa corporal por especie), usaríamos geom_col(), que mapea explícitamente la altura de las barras a un valor numérico del dataset. Como se mencionó, esto se verá más adelante, pero aquí tienes un ejemplo de cómo se vería:\n\n\n\n\n\n\n\n\nComparación entre geom_bar() y geom_col(): - geom_bar(): Útil para mostrar el conteo de observaciones en cada categoría. Las barras representan el número de veces que ocurre cada categoría. Úsala cuando simplemente quieras contar cuántas observaciones pertenecen a cada categoría. - geom_col(): Se usa cuando quieres que las alturas de las barras representen un valor numérico específico, como una suma, un promedio u otra medida. Úsala cuando ya tienes valores calculados (por ejemplo, promedios, sumas) y quieres representarlos con barras."
  },
  {
    "objectID": "docs/31.r-visualizacion-datosll.html#extra-explora-las-variables-de-los-pingüinos",
    "href": "docs/31.r-visualizacion-datosll.html#extra-explora-las-variables-de-los-pingüinos",
    "title": "Visualización de Datos II",
    "section": "EXTRA: Explora las variables de los pingüinos",
    "text": "EXTRA: Explora las variables de los pingüinos\nPuedes continuar explorando la distribución de las distintas variables en las diferentes especies de pingüinos con este gráfico interactivo. Simplemente selecciona la variable que te interesa y las especie de pingüino que quieres explorar.\n\n\n\n\n\n\n\n\n\nviewof species = Inputs.checkbox(\n  [ \"Adelia\", \"Barbijo\", \"Papúa\" ],\n  { value: [\"Adelia\", \"Barbijo\"], label: \"Especies\" }\n);\nviewof measure = Inputs.select(\n  [ \"largo_aleta_mm\", \"largo_pico_mm\", \"alto_pico_mm\", \"masa_corporal_g\" ],\n  { label: \"Variables\" }\n);\ndo_penguins_density(measure, species);\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nEl gráfico anterior es interactivo y está construido con una serie de funciones y programación condicional. En este caso, usamos la función do_penguins_density para crear un gráfico de densidad de una variable seleccionada en función de una especie de pingüino seleccionada. Este tipo de gráficos es más complejo y no se verá en el curso, pero sirve como muestra del poder de R en la visualización de datos. Les dejo el código aquí por si les interesa explorar más sobre cómo se construyó este gráfico. Aunque ahora puede que no lo entiendan del todo, verán que a medida que avancen en el curso, podrán entender y crear gráficos más complejos como este. Esta es la base de cómo se construyen aplicaciones de análisis de datos con R. En un futuro, habrá un curso de desarrollo de aplicaciones con R.\ndo_penguins_density &lt;- function(measure, sp) {\n  filtered &lt;- pinguinos |&gt; filter(especie == sp)\n  ggplot(data = filtered, aes(x = .data[[measure]])) +\n  geom_density(aes(fill = especie), alpha = 0.8, position = \"identity\") +\n  labs(title = \"Penguins 🐧\")\n}\n//| echo: false\nviewof species = Inputs.checkbox(\n  [ \"Adelia\", \"Barbijo\", \"Papúa\" ],\n  { value: [\"Adelia\", \"Barbijo\"], label: \"Especies\" }\n);\nviewof measure = Inputs.select(\n  [ \"largo_aleta_mm\", \"largo_pico_mm\", \"alto_pico_mm\", \"masa_corporal_g\" ],\n  { label: \"Variables\" }\n);\ndo_penguins_density(measure, species);"
  },
  {
    "objectID": "docs/40-datos-no-parametricos.html#introducción",
    "href": "docs/40-datos-no-parametricos.html#introducción",
    "title": "Análisis de Datos No Paramétricos",
    "section": "Introducción",
    "text": "Introducción\nLos métodos estadísticos no paramétricos son útiles cuando los datos no cumplen con los supuestos necesarios para los análisis paramétricos. A menudo se utilizan cuando los datos no siguen una distribución normal, tienen sesgos, o son medidas ordinales o rangos."
  },
  {
    "objectID": "docs/40-datos-no-parametricos.html#cuándo-usar-métodos-no-paramétricos",
    "href": "docs/40-datos-no-parametricos.html#cuándo-usar-métodos-no-paramétricos",
    "title": "Análisis de Datos No Paramétricos",
    "section": "Cuándo Usar Métodos No Paramétricos",
    "text": "Cuándo Usar Métodos No Paramétricos\nDistribuciones No Normales: Los datos no tienen una distribución normal o son extremadamente sesgados.\nVariables Ordinales: Los datos son ordinales y no se pueden asumir intervalos iguales entre mediciones.\nPequeño Tamaño de Muestra: Las muestras pequeñas hacen que los métodos paramétricos sean menos fiables.\nEjemplos de Pruebas No Paramétricas\nPrueba de Mann-Whitney U:\n    Usada para comparar dos grupos independientes cuando no se puede asumir la normalidad.\n    Es una alternativa no paramétrica a la prueba t para muestras independientes.\n\nPrueba de Wilcoxon para Muestras Pares:\n    Usada para comparar dos muestras relacionadas o dependientes.\n    Es una alternativa no paramétrica a la prueba t para muestras relacionadas."
  },
  {
    "objectID": "docs/40-datos-no-parametricos.html#reflexión-y-discusión",
    "href": "docs/40-datos-no-parametricos.html#reflexión-y-discusión",
    "title": "Análisis de Datos No Paramétricos",
    "section": "Reflexión y Discusión",
    "text": "Reflexión y Discusión\nRevisa los resultados de las pruebas: ¿Qué puedes concluir sobre las diferencias entre los grupos en cada prueba?\nDiscute las ventajas y limitaciones del uso de métodos no paramétricos en comparación con los métodos paramétricos. ¿En qué situaciones encuentras que los métodos no paramétricos son más apropiados?\nEsta lección interactiva te proporciona una introducción práctica a los análisis de datos no paramétricos en R, mostrando cómo estos métodos son herramientas valiosas cuando se enfrentan a datos que violan los supuestos de los métodos paramétricos tradicionales."
  },
  {
    "objectID": "docs/72-anova-1.html",
    "href": "docs/72-anova-1.html",
    "title": "Fundamentos del ANOVA",
    "section": "",
    "text": "El Análisis de Varianza (ANOVA, por sus siglas en inglés) es una técnica estadística utilizada para comparar las medias de tres o más grupos o muestras. Fue desarrollado por Ronald A. Fisher en la década de 1920. La prueba de ANOVA permite determinar si existen diferencias estadísticamente significativas entre las medias de diferentes grupos, basándose en la variabilidad dentro de los grupos y entre los grupos. Sin embargo, ANOVA no indica cuáles grupos son diferentes entre sí; para ello, se utilizan pruebas post-hoc.\nEn esta lección, vamos a ver los fundamentos del ANOVA, incluyendo los conceptos clave, los supuestos, los tipos de ANOVA y cómo realizar un ANOVA paso a paso en R. Además, veremos cómo interpretar los resultados y cómo verificar los supuestos del ANOVA. En las próximas lecciones, veremos cómo realizar ANOVA en R de forma sencilla y cómo visualizar los resultados con ggpubr de manera directa."
  },
  {
    "objectID": "docs/72-anova-1.html#introducción-al-análisis-de-varianza-anova",
    "href": "docs/72-anova-1.html#introducción-al-análisis-de-varianza-anova",
    "title": "Fundamentos del ANOVA",
    "section": "",
    "text": "El Análisis de Varianza (ANOVA, por sus siglas en inglés) es una técnica estadística utilizada para comparar las medias de tres o más grupos o muestras. Fue desarrollado por Ronald A. Fisher en la década de 1920. La prueba de ANOVA permite determinar si existen diferencias estadísticamente significativas entre las medias de diferentes grupos, basándose en la variabilidad dentro de los grupos y entre los grupos. Sin embargo, ANOVA no indica cuáles grupos son diferentes entre sí; para ello, se utilizan pruebas post-hoc.\nEn esta lección, vamos a ver los fundamentos del ANOVA, incluyendo los conceptos clave, los supuestos, los tipos de ANOVA y cómo realizar un ANOVA paso a paso en R. Además, veremos cómo interpretar los resultados y cómo verificar los supuestos del ANOVA. En las próximas lecciones, veremos cómo realizar ANOVA en R de forma sencilla y cómo visualizar los resultados con ggpubr de manera directa."
  },
  {
    "objectID": "docs/72-anova-1.html#por-qué-utilizamos-anova-para-probar-hipótesis",
    "href": "docs/72-anova-1.html#por-qué-utilizamos-anova-para-probar-hipótesis",
    "title": "Fundamentos del ANOVA",
    "section": "¿Por qué utilizamos ANOVA para probar hipótesis?",
    "text": "¿Por qué utilizamos ANOVA para probar hipótesis?\nCuando queremos comparar las medias de más de dos grupos, hacer múltiples pruebas t individuales aumenta el riesgo de cometer errores de Tipo I (falsos positivos). ANOVA ofrece una solución al proporcionar una prueba estadística única que evalúa si hay al menos una diferencia significativa entre las medias de los grupos, controlando adecuadamente la tasa de error de Tipo I."
  },
  {
    "objectID": "docs/72-anova-1.html#conceptos-clave-en-anova",
    "href": "docs/72-anova-1.html#conceptos-clave-en-anova",
    "title": "Fundamentos del ANOVA",
    "section": "Conceptos clave en ANOVA",
    "text": "Conceptos clave en ANOVA\n\nLa varianza es una medida de dispersión que indica cuánto varían los datos respecto a la media. En ANOVA, la varianza se utiliza para comparar la variabilidad dentro de los grupos y entre los grupos.\n\n\n\n\nEn la figura observamos que cada grupo tiene distintas medias y varianza. Además, hay grupos con medias más cercanas y otros, como el 1, con medias más alejadas de los otros grupos.\n\n\nSuma de cuadrados Entre-grupos y dentro de los grupos\n\nLa suma de cuadrados representa una medida de variación o desviación con respecto a la media. Se calcula como una suma de los cuadrados de las diferencias con respecto a la media.\nSe calcula elevando al cuadrado la diferencia entre cada punto de datos y la media de los datos, y luego sumando todas las diferencias al cuadrado.\nLa Suma de Cuadrados se puede dividir en dos partes: la Suma de Cuadrados dentro de grupos y la Suma de Cuadrados entre grupos.\n\nSuma de cuadrados entre grupos (SSB o SSTr): Mide la variabilidad de las medias de cada grupo respecto a la media general. es una medida de la variabilidad dentro de cada grupo. La suma de cuadrados dentro de grupos también se conoce como suma de cuadrados de error.\nSuma de cuadrados dentro de los grupos (SSW o SSE): Mide la variabilidad de las observaciones dentro de cada grupo respecto a las medias de sus respectivos grupos. Es una medida de la variabilidad entre los grupos. La Suma de Cuadrados entre grupos también se conoce como suma de cuadrados de tratamiento.\n\n\nRelación o razón F\n\nLa razón F es el estadístico utilizado en ANOVA para comparar la variabilidad entre los grupos con la variabilidad dentro de los grupos.\nLa razón F es la relación entre las medias cuadráticas entre los grupos y las medias cuadráticas dentro de los grupos.\nSe utiliza para probar la hipótesis nula en ANOVA.\n\n\\[\nF = \\frac{SSB / df_{entre}}{SSE / df_{dentro}}\n\\]\nDonde:\n\nSSB: Suma de cuadrados entre grupos.\nSSE: Suma de cuadrados dentro de los grupos.\ndf: Grados de libertad."
  },
  {
    "objectID": "docs/72-anova-1.html#la-lógica-de-anova",
    "href": "docs/72-anova-1.html#la-lógica-de-anova",
    "title": "Fundamentos del ANOVA",
    "section": "La lógica de ANOVA",
    "text": "La lógica de ANOVA\nANOVA se basa en comparar dos estimaciones de la varianza poblacional:\n\nVarianza entre grupos: Estima la varianza poblacional a partir de la variabilidad entre las medias de los grupos.\nVarianza dentro de los grupos: Estima la varianza poblacional a partir de la variabilidad dentro de cada grupo.\n\nSi todas las medias son iguales, esperamos que estas dos estimaciones de la varianza sean aproximadamente iguales.\nSi al menos una media es diferente, la varianza entre grupos será mayor que la varianza dentro de los grupos.\n\n\n\nEn este ejemplo, hay poca variación dentro de los grupos, pero mucha entre los grupos. En este caso, el valor F será alto. Esto se debe a que el numerador de la fórmula de F (variación entre los grupos) es grande, y el denominador (variación dentro de los grupos) es pequeño. Entonces, el valor p será bajo y probablemente, significativo. Esto indica que las diferencias entre los grupos son estadísticamente significativas.\n\n\n\n\n\nEn este ejemplo, hay más variación dentro de los grupos, pero poca entre los grupos. Valor F: Será bajo. La variación dentro de los grupos (denominador) es grande en comparación con la variación entre los grupos (numerador).Valor p: Será alto (probablemente no significativo). Esto indica que las diferencias observadas entre las medias de los grupos no son estadísticamente significativas.\n\n\n\nSi \\(F\\) es aproximadamente igual a 1: Indica que la variabilidad entre grupos es similar a la variabilidad dentro de los grupos; no hay evidencia para rechazar la hipótesis nula.\nSi \\(F\\) es significativamente mayor que 1: Sugiere que la variabilidad entre grupos es mayor de lo esperado bajo la hipótesis nula; hay evidencia para rechazar H₀.\n\nEl valor de \\(F\\) se compara con un valor crítico de la distribución F para obtener un valor p correspondiente."
  },
  {
    "objectID": "docs/72-anova-1.html#hipótesis-en-anova",
    "href": "docs/72-anova-1.html#hipótesis-en-anova",
    "title": "Fundamentos del ANOVA",
    "section": "Hipótesis en ANOVA",
    "text": "Hipótesis en ANOVA\n\nHipótesis nula H_0\nTodas las medias poblacionales son iguales:\n\\[\nH_0: \\mu_1 = \\mu_2 = \\dots = \\mu_k\n\\]\n\n\nHipótesis alternativa H_a\nAl menos una de las medias poblacionales es diferente:\n\\[\nH_a: \\text{Al menos una } \\mu_i \\text{ es diferente}\n\\]"
  },
  {
    "objectID": "docs/72-anova-1.html#tipos-de-anova",
    "href": "docs/72-anova-1.html#tipos-de-anova",
    "title": "Fundamentos del ANOVA",
    "section": "Tipos de ANOVA",
    "text": "Tipos de ANOVA\nVeamos algunos tipos comunes de ANOVA. Cada tipo se utiliza en diferentes situaciones y con diferentes diseños experimentales. Además, cada tipo de ANOVA tiene sus propios supuestos y consideraciones. Veremos en las siguientes lecciones que en R podemos hacer cualquier tipo de ANOVA de forma sencilla.\n\nANOVA de una vía (One-way ANOVA)\n\nCompara las medias de tres o más grupos independientes basados en un solo factor o variable independiente.\nEjemplo: Comparar el rendimiento académico entre estudiantes de tres métodos de enseñanza diferentes.\n\n\n\nANOVA de dos vías (Two-way ANOVA)\n\nCompara las medias considerando dos factores o variables independientes, y puede evaluar el efecto de cada factor y su interacción.\nEjemplo: Evaluar el efecto del método de enseñanza y el género en el rendimiento académico.\nEste análisis no solo permite probar los efectos individuales de cada factor (efectos principales), sino también la interacción entre los factores.\nUna interacción ocurre cuando el efecto de un factor depende del nivel del otro factor. Por ejemplo, en un estudio sobre el crecimiento de plantas, puede haber una interacción entre el tipo de suelo y el nivel de fertilizante. Si la interacción es significativa, la interpretación de los efectos principales se vuelve más compleja, ya que el efecto de un factor no es constante a través de los niveles del otro.\n\n\n\nANOVA de medidas repetidas (Repeated Measures ANOVA)\n\nUtilizado cuando las mismas unidades experimentales son medidas bajo diferentes condiciones o tiempos.\nEjemplo: Comparar el rendimiento de los estudiantes de 3 grupos al inicio, a mitad y al final del semestre."
  },
  {
    "objectID": "docs/72-anova-1.html#supuestos-de-anova",
    "href": "docs/72-anova-1.html#supuestos-de-anova",
    "title": "Fundamentos del ANOVA",
    "section": "Supuestos de ANOVA",
    "text": "Supuestos de ANOVA\nPara que los resultados del ANOVA sean válidos, se deben cumplir ciertos supuestos:\n\nIndependencia de las observaciones:\n\nLas observaciones son independientes entre los grupos y dentro de los grupos.\nAsegurado mediante un diseño adecuado y aleatorización.\n\nNormalidad:\n\nLas distribuciones de los residuos (diferencias entre las observaciones y las medias de los grupos) son aproximadamente normales.\nPuede verificarse mediante pruebas de normalidad y gráficos (histogramas, Q-Q plots).\n\nHomogeneidad de varianzas (homocedasticidad):\n\nLas varianzas dentro de los grupos son aproximadamente iguales.\nPuede evaluarse con pruebas como la de Levene o de Bartlett.\n\n\nSi estos supuestos no se cumplen, se pueden considerar transformaciones de datos o utilizar pruebas no paramétricas alternativas, como el test de Kruskal-Wallis."
  },
  {
    "objectID": "docs/72-anova-1.html#ejemplo-paso-por-paso",
    "href": "docs/72-anova-1.html#ejemplo-paso-por-paso",
    "title": "Fundamentos del ANOVA",
    "section": "Ejemplo, paso por paso",
    "text": "Ejemplo, paso por paso\nVamos a ver un ejemplo en R utilizando tidyverse que ejemplifica cada uno de los pasos del ANOVA. Utilizaremos un conjunto de datos simulado para representar las diferentes dietas y la presión arterial sistólica de los participantes. Al final, verás que todos estos pasos se pueden realizar de forma sencilla con la función aov() en R. Además, en las siguientes lecciones, veremos cómo hacer todos estos pasos y graficar los resultados con ggpubr.\n\n\n\n\n\n\n\n\n\nVisualización inicial de los datos\nEs útil visualizar los datos para tener una comprensión inicial.\n\n\n\n\n\n\n\n\n\n\nPlantear las hipótesis\n\nHipótesis nula \\(H_0\\): Las medias de la presión arterial sistólica son iguales para todas las dietas.\nHipótesis alternativa \\(H_a\\): Al menos una de las medias de la presión arterial sistólica es diferente.\n\n\n\nCalcular las sumas de cuadrados\n\nCalcular la media general\n\n\n\n\n\n\n\n\n\n\nCalcular las medias por grupo\n\n\n\n\n\n\n\n\n\n\n\nSuma total de cuadrados (SST)\n\\[\n\\text{SST} = \\sum_{i=1}^{N} (Y_i - \\bar{Y})^2\n\\]\n\n\n\n\n\n\n\n\n\n\nSuma de cuadrados entre grupos (SSB)\n\\[\n\\text{SSB} = \\sum_{j=1}^{k} n_j (\\bar{Y}_j - \\bar{Y})^2\n\\]\n\n\n\n\n\n\n\n\n\n\nSuma de cuadrados dentro de los grupos (SSW)\n\\[\n\\text{SSW} = \\sum_{j=1}^{k} \\sum_{i=1}^{n_j} (Y_{ij} - \\bar{Y}_j)^2\n\\]\n\n\n\n\n\n\n\n\nVerificación:\n\\[\n\\text{SST} = \\text{SSB} + \\text{SSW}\n\\]\n\n\n\n\n\n\n\n\n\n\nCalcular los grados de libertad\n\n\n\n\n\n\n\n\nCalcular las medias cuadráticas Media cuadrática entre grupos (MSB):\n\\[\n\\text{MSB} = \\frac{\\text{SSB}}{df_{\\text{entre}}}\n\\]\nMedia cuadrática dentro de los grupos (MSW):\n\\[\n\\text{MSW} = \\frac{\\text{SSW}}{df_{\\text{dentro}}}\n\\]\ndentro ​\n\n\n\n\n\n\n\n\nCalcular el estadístico F\n\\[\nF = \\frac{\\text{MSB}}{\\text{MSW}}\n\\]\n\n\n\n\n\n\n\n\nDeterminar el valor p o comparar con el valor crítico\nCalculamos el valor p asociado al estadístico F calculado.\n\n\n\n\n\n\n\n\nDecisión:\n\nNivel de significancia \\(\\alpha = 0.05\\)\nSi \\(\\text{valor p} &lt; \\alpha\\) , rechazamos \\(H_0\\)​\n\n\n\n\n\n\n\n\n\n\n\nVerificación con la función aov()\nPara confirmar nuestros cálculos, utilizamos la función aov().\n\n\n\n\n\n\n\n\nObservamos que los valores de Sum Sq, Mean Sq, F value y Pr(&gt;F) coinciden con nuestros cálculos manuales.\nConclusión: Hay diferencias significativas en la presión arterial sistólica promedio entre las dietas.\n\n\nPruebas Post-hoc\nComo encontramos diferencias significativas, podemos realizar pruebas post-hoc para identificar entre qué dietas existen diferencias.\nCuando ANOVA indica diferencias significativas, pero no especifica qué grupos difieren entre sí. Las pruebas post-hoc se utilizan para realizar comparaciones pares controlando el error de Tipo I.\n\nPrueba de Tukey HSD\nPrueba de Bonferroni\nPrueba de Scheffé\n\nUsaremos la prueba de Tukey HSD para controlar el error de Tipo I.\n\n\n\n\n\n\n\n\n\nDespués de realizar las pruebas post-hoc, podemos identificar específicamente entre qué dietas hay diferencias significativas en la presión arterial sistólica.\nObserva qué grupos tienen diferencias significativas y cuáles no. El valor de la p adj indica el valor p ajustado para controlar el error de Tipo I. Si este valor es menor que \\(\\alpha\\), se considera significativo.\n\nLa primera columna indica la comporación entre grupos.\n\n\n\n\nVisualización de los resultados Post-hoc\n\n\n\n\n\n\n\n\n\n\nVerificación de supuestos\nNormalidad de los residuos - podemos usar la prueba de Shapiro-Wilk y el gráfico Q-Q para verificar la normalidad de los residuos. - La prueba de Shapiro-Wilk evalúa si los residuos siguen una distribución normal. La hipótesis nula es que los residuos son normales.\n\n\n\n\n\n\n\n\nSi el valor p es mayor que 0.05, no rechazamos la normalidad de los residuos.\nGráfico Q-Q:\n\n\n\n\n\n\n\n\n\n\nHomogeneidad de varianzas\nUsamos la prueba de Levene.\n\nLa hipótesis nula es que las varianzas son iguales entre los grupos.\n\n\n\n\n\n\n\n\n\nSi el valor p es mayor que 0.05, no rechazamos la igualdad de varianzas.\n\n\nResumen final\n\nHipótesis nula rechazamos H_0: Hay diferencias significativas entre las dietas.\nPruebas post-hoc: Identifican específicamente entre qué dietas hay diferencias.\nSupuestos del ANOVA: Fueron verificados y cumplidos."
  },
  {
    "objectID": "docs/72-anova-1.html#resumen",
    "href": "docs/72-anova-1.html#resumen",
    "title": "Fundamentos del ANOVA",
    "section": "Resumen",
    "text": "Resumen\n\n¿Qué es ANOVA? Una técnica estadística para comparar las medias de tres o más grupos.\n¿Cómo funciona? Compara la variabilidad entre grupos con la variabilidad dentro de los grupos usando el estadístico F.\n¿Por qué se usa para probar hipótesis? Permite evaluar si hay diferencias significativas entre las medias de los grupos, controlando el error de Tipo I sin realizar múltiples pruebas t.\nSupuestos clave: Independencia, normalidad y homogeneidad de varianzas.\nTipos de ANOVA: Una vía, dos vías, factorial, medidas repetidas.\nCuando se rechaza \\(H_0\\): Indica que al menos una media es diferente y se deben utilizar pruebas post-hoc para identificar las diferencias específicas."
  },
  {
    "objectID": "docs/53-anova-kruska.html#introducción-a-los-anovas-y-el-test-de-kruskal-wallis",
    "href": "docs/53-anova-kruska.html#introducción-a-los-anovas-y-el-test-de-kruskal-wallis",
    "title": "Comparación de Tres o Más Medias: ANOVA y Test de Kruskal-Wallis",
    "section": "Introducción a los ANOVAs y el Test de Kruskal-Wallis",
    "text": "Introducción a los ANOVAs y el Test de Kruskal-Wallis\n\nEl análisis de varianza (ANOVA) es una herramienta estadística poderosa para comparar las medias de tres o más grupos.\nComo hemos visto en las pruebas t para dos grupos, ANOVA se basa en el concepto de modelos lineales, extendiendo la idea de la codificación dummy para incluir más de dos grupos.\nDebido a su importancia y extendido uso en la investigación (para bien o para mal), tendremos un módulo entero dedicado a este tema.\n\n\n\nANOVA unidireccional (One-way ANOVA): Evalúa si hay diferencias significativas entre las medias de tres o más grupos. Se basa en un modelo lineal que incluye términos de intersección (\\((\\beta_0\\))) y pendientes (\\((\\beta_1, \\beta_2, \\dots\\))) que representan las diferencias entre los grupos.\nTest de Kruskal-Wallis: Es una alternativa no paramétrica al ANOVA unidireccional, que compara las distribuciones de tres o más grupos utilizando los rangos de los valores en lugar de los valores originales.\n\nAmbas pruebas se basan en modelos lineales con codificación dummy, lo que nos permite analizar cómo las diferencias entre los grupos afectan la variable dependiente \\((y\\)).\n\n\nPuntos clave:\n\nANOVA unidireccional como modelo lineal: El modelo lineal en este caso predice la media de la variable dependiente (\\((y\\))) para cada grupo, utilizando variables indicadoras ($(x_0, x_1, x_2, \\(dots\\))) que toman el valor de 0 o 1, dependiendo del grupo al que pertenece cada observación.\n\\([\ny = \\beta_0 + \\beta_1 \\cdot x_1 + \\beta_2 \\cdot x_2 + \\dots\\)]\n\nSi \\((x_1 = 1\\)), el modelo predice la media del primer grupo (\\((\\beta_0\\))).\nSi \\((x_2 = 1\\)), el modelo predice la media del segundo grupo (\\((\\beta_0 + \\beta_1\\))), y así sucesivamente.\n\nTest de Kruskal-Wallis como modelo lineal: Similar al ANOVA, pero en lugar de los valores originales de \\((y\\)), se utilizan los rangos de \\((y\\)):\n\\([\n\\text{rango}(y) = \\beta_0 + \\beta_1 \\cdot x_1 + \\beta_2 \\cdot x_2 + \\dots\\)]\nEste test es útil cuando los datos no cumplen con los supuestos de normalidad o contienen valores atípicos.\nCodificación dummy: Al igual que en las pruebas t para dos grupos, la codificación dummy se utiliza para representar grupos categóricos como variables numéricas (0 o 1), lo que permite incluir múltiples grupos en un modelo lineal.\n\n\nObserva en el siguiente gráfico que el ANOVA es “más de lo mismo” que hemos estado viendo en las pruebas t para dos grupos, pero extendido a tres o más grupos. La idea es la misma: comparar las medias de los grupos y ver si hay diferencias significativas:\n\n\n\nANOVA"
  },
  {
    "objectID": "docs/53-anova-kruska.html#por-qué-anova-y-no-pruebas-t-múltiples",
    "href": "docs/53-anova-kruska.html#por-qué-anova-y-no-pruebas-t-múltiples",
    "title": "Comparación de Tres o Más Medias: ANOVA y Test de Kruskal-Wallis",
    "section": "¿Por qué ANOVA y no pruebas t múltiples?",
    "text": "¿Por qué ANOVA y no pruebas t múltiples?\n\nEl ANOVA se basa en comparar la varianza (o variación) entre los grupos con la variación dentro de cada grupo en particular.\nSi la variación “entre” es mucho mayor que la variación “dentro”, es más probable que concluyamos que las medias de los diferentes grupos no son iguales.\n\nentre o between se refiere a la variación entre los grupos, mientras que dentro o within se refiere a la variación dentro de cada grupo en particular.\n\nPor el contrario, si las variaciones “entre” y “dentro” son más similares, es menos probable que concluyamos que existe una diferencia significativa entre las medias de las muestras.\n\n¿Por qué no simplemente comparamos las medias de cada par posible de grupos para ver si existen diferencias estadísticamente significativas? - La razón es que al aumentar el número de grupos, es más probable que observemos diferencias que se deben únicamente al azar. - Esto significa que tenemos una mayor probabilidad de cometer un error Tipo I, es decir, rechazar la hipótesis nula (que no hay diferencia entre las medias) cuando, de hecho, la hipótesis nula es verdadera (siguiente tema del curso). - Un ANOVA controla este riesgo adicional de errores Tipo I, manteniendo la tasa de error global o del experimento, que típicamente es \\(\\alpha\\) = 0.05.\nEs importante señalar que el ANOVA de una vía es una estadística de prueba global y no puede indicar qué grupos específicos fueron significativamente diferentes entre sí, solo que al menos dos grupos fueron diferentes. Para determinar qué grupos específicos difieren unos de otros, necesitarías utilizar una prueba post hoc."
  },
  {
    "objectID": "docs/53-anova-kruska.html#anova-de-dos-vías",
    "href": "docs/53-anova-kruska.html#anova-de-dos-vías",
    "title": "Comparación de Tres o Más Medias: ANOVA y Test de Kruskal-Wallis",
    "section": "ANOVA de dos vías",
    "text": "ANOVA de dos vías\nEl ANOVA de dos vías compara las medias de grupos que se han dividido según dos variables independientes, o ‘factores’.\nPor ejemplo: ¿existe una interacción entre el género y el nivel educativo en la ansiedad ante los exámenes entre estudiantes universitarios? Aquí, el género (masculino / femenino) y el nivel educativo (secundaria / pregrado / posgrado) son tus variables independientes o factores.\nUn ANOVA de dos vías evalúa tres hipótesis:\n\nQue las medias poblacionales del primer factor (por ejemplo, cada género) son iguales.\nQue las medias poblacionales del segundo factor (por ejemplo, cada nivel educativo) son iguales.\nQue no hay interacción entre los dos factores, es decir, que la relación entre la ansiedad y el género no depende del nivel educativo, o que la relación entre la ansiedad y la educación no depende del género.\n\nLas dos primeras hipótesis se refieren a la relación entre cada factor y la variable dependiente, conocidas como ‘efectos principales’. Cada una de estas es similar a un ANOVA de una vía, pero en el contexto de un modelo más grande. La tercera hipótesis se refiere al ‘efecto de interacción’.\n\nNo complicaremos haciendo toda la demostración de nuevo. Si ya entendiste las pruebas t, entenderás el ANOVA. Y si ya entendiste la regresión lineal, entenderás el ANOVA. Es más de lo mismo, pero con más grupos. De nuevo, veremos ANOVA en detalle en un módulo posterior."
  },
  {
    "objectID": "docs/71-ttest-wilcoxon-python.html",
    "href": "docs/71-ttest-wilcoxon-python.html",
    "title": "Prueba t de Una Muestra y Test de Wilcoxon con Python",
    "section": "",
    "text": "La prueba t de una muestra y el test de rango con signo de Wilcoxon son herramientas estadísticas esenciales para determinar si la media (o mediana) de una única muestra es significativamente diferente de un valor de referencia conocido o hipotético. Ambos pueden ser entendidos como modelos lineales simples.\n\nPrueba t de una muestra: Compara la media de la muestra con un valor poblacional conocido. Requiere que los datos se distribuyan de forma aproximadamente normal.\nTest de Wilcoxon (de rango con signo): Es la alternativa no paramétrica. Compara la mediana de la muestra con un valor de referencia y no asume normalidad, ya que se basa en los rangos de las diferencias."
  },
  {
    "objectID": "docs/71-ttest-wilcoxon-python.html#introducción",
    "href": "docs/71-ttest-wilcoxon-python.html#introducción",
    "title": "Prueba t de Una Muestra y Test de Wilcoxon con Python",
    "section": "",
    "text": "La prueba t de una muestra y el test de rango con signo de Wilcoxon son herramientas estadísticas esenciales para determinar si la media (o mediana) de una única muestra es significativamente diferente de un valor de referencia conocido o hipotético. Ambos pueden ser entendidos como modelos lineales simples.\n\nPrueba t de una muestra: Compara la media de la muestra con un valor poblacional conocido. Requiere que los datos se distribuyan de forma aproximadamente normal.\nTest de Wilcoxon (de rango con signo): Es la alternativa no paramétrica. Compara la mediana de la muestra con un valor de referencia y no asume normalidad, ya que se basa en los rangos de las diferencias."
  },
  {
    "objectID": "docs/71-ttest-wilcoxon-python.html#puntos-clave",
    "href": "docs/71-ttest-wilcoxon-python.html#puntos-clave",
    "title": "Prueba t de Una Muestra y Test de Wilcoxon con Python",
    "section": "Puntos Clave",
    "text": "Puntos Clave\n\nPrueba t como Modelo Lineal: El modelo es el más simple posible, donde se estima la media de la muestra (el intercepto, β₀) y se compara con el valor de referencia (generalmente 0). [ y = _0 ] La hipótesis nula es que β₀ es igual al valor de referencia.\nTest de Wilcoxon como Modelo Lineal: El concepto es el mismo, pero el modelo se aplica a los rangos con signo de los datos, no a los valores originales. [ (y) = _0 ]\nRango con Signo: Es una transformación donde primero se calcula el rango de los valores absolutos de los datos y luego se les reasigna su signo original. Esto permite que la prueba de Wilcoxon sea sensible tanto a la magnitud como a la dirección de las desviaciones respecto al valor de referencia."
  },
  {
    "objectID": "docs/71-ttest-wilcoxon-python.html#ejemplo-en-python-prueba-t-y-test-de-wilcoxon",
    "href": "docs/71-ttest-wilcoxon-python.html#ejemplo-en-python-prueba-t-y-test-de-wilcoxon",
    "title": "Prueba t de Una Muestra y Test de Wilcoxon con Python",
    "section": "Ejemplo en Python: Prueba t y Test de Wilcoxon",
    "text": "Ejemplo en Python: Prueba t y Test de Wilcoxon\nRealicemos ambas pruebas para determinar si una muestra de mediciones de pH tiene una media significativamente diferente de 7.0 (neutralidad).\n\nPaso 1: Generar y Visualizar los Datos\nCreamos una muestra de datos y la visualizamos para tener una idea de su distribución y su media.\n\n\n\n\n\n\n\n\n\n\nPaso 2: Realizar las Pruebas Estadísticas\nAhora, aplicamos la prueba t y el test de Wilcoxon para comparar la media/mediana de la muestra con el valor de referencia de 7.0.\n\n\n\n\n\n\n\n\n\n\nInterpretación\n\nPrueba t: El valor p (0.018) es menor que 0.05, lo que sugiere que la media de la muestra (7.056) es estadísticamente diferente del valor de referencia de 7.0.\nTest de Wilcoxon: El valor p (0.015) también es menor que 0.05, lo que confirma la conclusión de la prueba t. La mediana de la muestra es significativamente diferente de 7.0.\n\nAmbas pruebas indican que el pH medido no es neutral. Dado que los datos son normales, la prueba t es apropiada, pero el test de Wilcoxon proporciona una confirmación robusta."
  },
  {
    "objectID": "docs/70-ttest-mann.html",
    "href": "docs/70-ttest-mann.html",
    "title": "Pruebas t para Muestras Independientes y el Test de Mann-Whitney",
    "section": "",
    "text": "Hasta ahora, hemos explorado cómo comparar medias que provienen de una misma muestra (prueba t de una muestra) o de dos muestras relacionadas (prueba t pareada). En esta lección, nos centraremos en comparar las medias de dos grupos independientes. Este tipo de comparación es común en estudios de investigación, donde queremos determinar si hay diferencias significativas entre dos grupos en una variable de interés.\nCuando comparamos las medias de dos grupos independientes (independientes significa que las observaciones en un grupo no están relacionadas con las observaciones en el otro grupo), podemos utilizar dos pruebas comunes:\n\nPrueba t para dos muestras independientes: Evalúa si las medias de dos grupos son significativamente diferentes.\nTest de Mann-Whitney U: Es una alternativa no paramétrica a la prueba t de dos muestras independientes, que compara las distribuciones de dos grupos basándose en los rangos de los datos.\n\nAmbas pruebas pueden entenderse como modelos lineales simples que predicen la diferencia entre las medias de los grupos. En el caso de la prueba t, se utiliza el valor original de la variable, mientras que en el test de Mann-Whitney, se utilizan los rangos de los valores."
  },
  {
    "objectID": "docs/70-ttest-mann.html#introducción-a-las-pruebas-para-comparar-dos-medias",
    "href": "docs/70-ttest-mann.html#introducción-a-las-pruebas-para-comparar-dos-medias",
    "title": "Pruebas t para Muestras Independientes y el Test de Mann-Whitney",
    "section": "",
    "text": "Hasta ahora, hemos explorado cómo comparar medias que provienen de una misma muestra (prueba t de una muestra) o de dos muestras relacionadas (prueba t pareada). En esta lección, nos centraremos en comparar las medias de dos grupos independientes. Este tipo de comparación es común en estudios de investigación, donde queremos determinar si hay diferencias significativas entre dos grupos en una variable de interés.\nCuando comparamos las medias de dos grupos independientes (independientes significa que las observaciones en un grupo no están relacionadas con las observaciones en el otro grupo), podemos utilizar dos pruebas comunes:\n\nPrueba t para dos muestras independientes: Evalúa si las medias de dos grupos son significativamente diferentes.\nTest de Mann-Whitney U: Es una alternativa no paramétrica a la prueba t de dos muestras independientes, que compara las distribuciones de dos grupos basándose en los rangos de los datos.\n\nAmbas pruebas pueden entenderse como modelos lineales simples que predicen la diferencia entre las medias de los grupos. En el caso de la prueba t, se utiliza el valor original de la variable, mientras que en el test de Mann-Whitney, se utilizan los rangos de los valores."
  },
  {
    "objectID": "docs/70-ttest-mann.html#puntos-clave",
    "href": "docs/70-ttest-mann.html#puntos-clave",
    "title": "Pruebas t para Muestras Independientes y el Test de Mann-Whitney",
    "section": "Puntos clave",
    "text": "Puntos clave\n\nPrueba t para dos muestras independientes como modelo lineal: El modelo lineal en este caso predice la media de la variable dependiente (\\((y\\))) para cada grupo. La variable independiente (\\((x\\))) es un indicador que toma el valor de 0 o 1 dependiendo de a qué grupo pertenece la observación. Esto se conoce como codificación dummy y se refiere a la conversión de variables categóricas en variables numéricas. Por ejemplo, si tenemos una variable sexo con dos categorías (masculino y femenino), podemos codificarla como 0 y 1 para usarla en un modelo lineal, donde 0 representa masculino y 1 representa femenino.\n\nEcuación lineal del modelo de la prueba t para muestras independientes: \\[\n   y_i = \\beta_0 + \\beta_1 \\cdot x_i\n   \\]\n\nSi \\((x_i = 0\\)), entonces \\((y_i = \\beta_0\\)), es decir, la media del primer grupo.\nSi \\((x_i = 1\\)), entonces \\((y_i = \\beta_0 + \\beta_1\\)), que es la media del segundo grupo.\n\nLa hipótesis nula (\\((H_0\\))) es que no hay diferencia entre las medias de los grupos (\\((\\beta_1 = 0\\))).\n\nTest de Mann-Whitney U como modelo lineal: Similar a la prueba t, pero en lugar de los valores originales de \\((y\\)), se utilizan los rangos de \\((y\\)):\n\\[\n\\text{rango}(y_i) = \\beta_0 + \\beta_1 \\cdot x_i\n\\]\nCodificación dummy: Es una técnica que se utiliza para convertir variables categóricas en variables numéricas para que puedan ser utilizadas en modelos lineales. Por lo general, no tenemos que preocuparnos por la codificación dummy ya que R y otros programas estadísticos la realizan automáticamente cuando ajustamos modelos lineales con variables categóricas. Sin embargo, a continuación se proporciona una explicación más detallada sobre la codificación dummy para una mejor comprensión.\n\n\n\n\n\n\n\nMás sobre codificación dummy\n\n\n\nLa codificación dummy es una técnica que se utiliza en los modelos lineales (como la regresión lineal, ANOVA, etc.) cuando tienes variables categóricas y necesitas convertirlas en una forma que el modelo pueda entender. Los modelos lineales solo pueden trabajar con variables numéricas, por lo que las variables categóricas (como colores, tipos de tratamiento, géneros, etc.) deben ser transformadas en números.\n\n¿Qué es una variable categórica?\nUna variable categórica es aquella que tiene diferentes categorías o niveles, pero no tiene un orden numérico natural. Por ejemplo, piensa en una variable llamada tratamiento que tiene tres niveles:\n\ntratamiento = A\ntratamiento = B\ntratamiento = C\n\nLa ecuación del modelo lineal no puede trabajar directamente con estas categorías porque no son números. Es aquí donde entra la codificación dummy.\n\n\n¿Qué es la codificación dummy?\nLa codificación dummy convierte una variable categórica en una serie de variables binarias (0 o 1). Cada nueva variable dummy indica la presencia o ausencia de una categoría específica. Esto permite al modelo lineal hacer los cálculos necesarios para entender la influencia de las diferentes categorías.\n\n\nEjemplo sencillo de codificación dummy\nSupongamos que tienes una variable categórica llamada tratamiento con tres niveles: A, B y C. Al aplicar la codificación dummy, se crean dos nuevas variables (porque el tercer nivel se usa como referencia), por ejemplo:\n\ntratamientoB: Será 1 si el tratamiento es B, y 0 si no lo es.\ntratamientoC: Será 1 si el tratamiento es C, y 0 si no lo es.\n\nLa categoría A será la categoría de referencia (o categoría base), es decir, cuando ambas variables dummy (tratamientoB y tratamientoC) sean 0, eso implicará que el tratamiento es A.\nLa codificación se vería así:\n\n\n\ntratamiento\ntratamientoB\ntratamientoC\n\n\n\n\nA\n0\n0\n\n\nB\n1\n0\n\n\nC\n0\n1\n\n\nA\n0\n0\n\n\nC\n0\n1\n\n\nB\n1\n0\n\n\n\n\n\n¿Cómo se interpreta en un modelo lineal?\nSi usas esta codificación dummy en una regresión lineal, el modelo ajustará una ecuación lineal que incluirá estas variables dummy. Supongamos que el modelo ajustado es algo así:\n\\[\ny = \\beta_0 + \\beta_1 \\cdot tratamientoB + \\beta_2 \\cdot tratamientoC\n\\]\nDonde:\n\n\\((\\beta_0\\)) es el valor esperado de \\((y\\)) cuando el tratamiento es A (la categoría de referencia).\n\\((\\beta_1\\)) es el cambio en \\((Y\\)) cuando el tratamiento es B en comparación con el tratamiento A.\n\\((\\beta_2\\)) es el cambio en \\((Y\\)) cuando el tratamiento es C en comparación con el tratamiento A.\n\n\n\nEjemplo de interpretación:\n\nSi \\((\\beta_1 = 5\\)), entonces el valor esperado de \\((y\\)) es 5 unidades mayor cuando el tratamiento es B en comparación con el tratamiento A.\nSi \\((\\beta_2 = -3\\)), entonces el valor esperado de \\((y\\)) es 3 unidades menor cuando el tratamiento es C en comparación con el tratamiento A.\n\n\n\n¿Por qué se necesita una categoría de referencia?\nLa categoría de referencia (en este ejemplo, el tratamiento A) actúa como un punto de comparación. El modelo estima los efectos de las demás categorías (B y C) en relación con la categoría de referencia. Si no se fijara una categoría de referencia, habría redundancia en los datos (colinealidad), lo que haría imposible ajustar el modelo.\n\n\nResumen:\n\nLa codificación dummy transforma una variable categórica en varias variables binarias (0 o 1).\nSe necesita una categoría de referencia para evitar redundancia en el modelo.\nLos coeficientes asociados a las variables dummy indican la diferencia entre cada categoría y la categoría de referencia en términos de la variable de respuesta.\n\n\n\nEjemplo en R:\nSupongamos que tienes una variable categórica tratamiento con niveles A, B, y C. En R, si ajustas un modelo lineal:\n# Datos de ejemplo\ntratamiento &lt;- factor(c(\"A\", \"B\", \"C\", \"A\", \"C\", \"B\"))\ny &lt;- c(10, 15, 7, 12, 9, 14)\n\n# Ajustar el modelo lineal\nmodelo &lt;- lm(y ~ tratamiento)\n\n# Ver los coeficientes\nsummary(modelo)\nEn el output, verás algo como:\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   11.000      2.000   5.500  0.0123 *  \ntratamientoB   4.000      2.828   1.414  0.2165    \ntratamientoC  -3.000      2.828  -1.061  0.3660  \nAquí:\n\nEl Intercept (11.000) es la media de y para la categoría de referencia (A).\nEl coeficiente de tratamientoB (4.000) indica que el valor promedio de y es 4 unidades mayor para el tratamiento B en comparación con el tratamiento A.\nEl coeficiente de tratamientoC (-3.000) indica que el valor promedio de y es 3 unidades menor para el tratamiento C en comparación con el tratamiento A.\n\n\n\nConclusión:\nLa codificación dummy es una forma sencilla de incluir variables categóricas en un modelo lineal. Te permite evaluar cómo cambian las respuestas en relación con una categoría de referencia, proporcionando una forma clara de interpretar el efecto de cada categoría en el resultado del modelo."
  },
  {
    "objectID": "docs/70-ttest-mann.html#ejemplo-en-r-comparación-de-dos-medias",
    "href": "docs/70-ttest-mann.html#ejemplo-en-r-comparación-de-dos-medias",
    "title": "Pruebas t para Muestras Independientes y el Test de Mann-Whitney",
    "section": "Ejemplo en R: Comparación de Dos Medias",
    "text": "Ejemplo en R: Comparación de Dos Medias\nRegresando a nuestro tema principal, vamos a realizar una comparación de dos medias utilizando la prueba t para dos muestras independientes y el test de Mann-Whitney U.\n\nPaso 1: Datos\nTenemos el siguiente conjunto de datos con dos grupos independientes (en la variable grupo), donde queremos comparar las medias de y entre los dos grupos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaso 2: Visualización de la Prueba t para Dos Muestras Independientes\n\nCreamos una gráfica que muestra las medias de los dos grupos.\nEn este gráfico, observamos la media del grupo 1 (x = 0) y grupo 2 (x = 1). La línea roja representa la diferencia entre las medias de los dos grupos y corresponde a la pendiente del modelo lineal.\n\n\n\n\n\n\n\n\n\n\n\nPaso 3: Prueba t\nPodemos realizar la prueba t de dos muestras independientes utilizando la función t.test(). También podemos obtener el mismo resultado utilizando un modelo lineal con codificación dummy. De nuevo, no te preocupes por el código, lo importante es entender que la prueba t y el modelo lineal son lo mismo.\n\nAhora, el output de la prueba t nos da dos medias (grupo 0=x=0.32 y grupo 1=y=1.30). El modelo lineal nos da la pendiente (diferencia entre las medias), que es 0.98 (1.30 - 0.32).\nEl valor p de la prueba t es 3.494e-12, lo que indica que la diferencia entre las medias es significativa. El valor p de la pendiente en el modelo lineal es el mismo y también indica significancia.\nNOTA: el modelo lineal también nos da el coeficiente del intercepto. Muchas veces, este coeficiente no es relevante ya que solo indica la media del grupo de referencia (la mayoría de las veces nos interesa la diferencia entre las medias). El valor p del intercepto también se ignora en muchos casos ya que no es relevante para la comparación de medias.\n\n\n\n\n\n\n\n\n\n\n\nPaso 4: Test de Mann-Whitney U\nEl test de Mann-Whitney U se puede realizar con la función wilcox.test(), y nuevamente podemos obtener el mismo resultado con un modelo lineal aplicado a los rangos de los valores. - De nuevo, en este caso los valores p no son idénticos, pero ambos indican significancia en la diferencia entre los grupos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nLa razón por la que se usa la función wilcox.test() para realizar un test de Mann-Whitney U es porque ambos tests están relacionados, y la función wilcox.test() en R puede realizar dos tipos de pruebas:\n\nPrueba de Wilcoxon de rangos con signo (Wilcoxon signed-rank test): Se utiliza para comparar muestras pareadas o una sola muestra contra un valor hipotético.\nPrueba de Mann-Whitney U (Mann-Whitney-Wilcoxon test): Se utiliza para comparar dos grupos independientes.\n\nLa función wilcox.test() es versátil y puede realizar ambas pruebas (Wilcoxon signed-rank y Mann-Whitney U). Cuando se le proporcionan dos conjuntos de datos independientes, la función automáticamente realiza el test de Mann-Whitney U.\n\nEjemplo de uso de wilcox.test() para Mann-Whitney U:\n\n\n\n\n\n\n\n\nEn este ejemplo, como estás comparando dos grupos independientes (grupo1 y grupo2), R interpretará que deseas realizar el test de Mann-Whitney U y no el test de Wilcoxon de rangos con signo.\n\n\n¿Cómo sabe R cuándo hacer un test de Wilcoxon o un test de Mann-Whitney?\n\nSi proporcionas una sola muestra o especificas el argumento paired = TRUE, entonces wilcox.test() realizará el Wilcoxon signed-rank test (para muestras pareadas o una muestra contra un valor).\nSi proporcionas dos muestras independientes, wilcox.test() realizará el test de Mann-Whitney U.\n\n\n\nEjemplo de Wilcoxon signed-rank test (muestras pareadas):\n\n\n\n\n\n\n\n\nAquí, al usar el argumento paired = TRUE, le indicas a R que realice el Wilcoxon signed-rank test para comparar muestras pareadas."
  },
  {
    "objectID": "docs/50-regresion-lineal.html#introducción",
    "href": "docs/50-regresion-lineal.html#introducción",
    "title": "Regresión Lineal Simple",
    "section": "Introducción",
    "text": "Introducción\nLa regresión lineal simple es una técnica estadística que modela la relación entre dos variables continuas mediante una ecuación lineal. Este método es útil para predecir los valores de una variable dependiente basada en los valores de una variable independiente."
  },
  {
    "objectID": "docs/50-regresion-lineal.html#conceptos-clave",
    "href": "docs/50-regresion-lineal.html#conceptos-clave",
    "title": "Regresión Lineal Simple",
    "section": "Conceptos Clave",
    "text": "Conceptos Clave\nModelo de Regresión Lineal Simple:\n    Representado por la ecuación ( y = \\beta_0 + \\beta_1x + \\epsilon ), donde:\n    ( y ) es la variable dependiente (resultado).\n    ( x ) es la variable independiente (predictora).\n    ( \\beta_0 ) es la intersección (ordenada en el origen).\n    ( \\beta_1 ) es la pendiente del modelo.\n    ( \\epsilon ) es el término de error.\n\nInterpretación:\n    ( \\beta_1 ) indica el cambio en la variable dependiente por cada unidad de cambio en la variable independiente.\n    El objetivo es minimizar la suma de los cuadrados de las diferencias entre los valores observados y los valores predichos."
  },
  {
    "objectID": "docs/50-regresion-lineal.html#ejercicio-práctico-en-r",
    "href": "docs/50-regresion-lineal.html#ejercicio-práctico-en-r",
    "title": "Regresión Lineal Simple",
    "section": "Ejercicio Práctico en R",
    "text": "Ejercicio Práctico en R\nVeamos cómo ajustar un modelo de regresión lineal simple utilizando un conjunto de datos simulado."
  },
  {
    "objectID": "docs/50-regresion-lineal.html#reflexión-y-discusión",
    "href": "docs/50-regresion-lineal.html#reflexión-y-discusión",
    "title": "Regresión Lineal Simple",
    "section": "Reflexión y Discusión",
    "text": "Reflexión y Discusión\nObserva la pendiente y el intercepto del modelo: ¿Qué te dicen sobre la relación entre las horas de estudio y las calificaciones?\nAnaliza cómo la línea de regresión se ajusta a los datos. ¿Qué sugiere este modelo sobre el poder predictivo de las horas de estudio respecto a las calificaciones de los estudiantes?\nEsta lección proporciona una comprensión práctica de la regresión lineal simple en R, permitiendo a los estudiantes capturar y analizar relaciones lineales entre variables y utilizar estos modelos predictivos en escenarios del mundo real."
  },
  {
    "objectID": "docs/24.1-histogramas-python.html",
    "href": "docs/24.1-histogramas-python.html",
    "title": "Graficar Distribuciones de Probabilidad en Python",
    "section": "",
    "text": "Antes de seguir con el tema de distribuciones de probabilidad, vamos a aprender a graficar en Python.\nEn esta lección, aprenderás a graficar distribuciones de probabilidad en Python con las bibliotecas matplotlib y seaborn.\nComenzaremos graficando un histograma, que es una forma común de visualizar la distribución de una variable continua.\nEstas bibliotecas siguen una estructura lógica y consistente que facilita la creación de gráficos complejos."
  },
  {
    "objectID": "docs/24.1-histogramas-python.html#introducción-y-objetivos",
    "href": "docs/24.1-histogramas-python.html#introducción-y-objetivos",
    "title": "Graficar Distribuciones de Probabilidad en Python",
    "section": "",
    "text": "Antes de seguir con el tema de distribuciones de probabilidad, vamos a aprender a graficar en Python.\nEn esta lección, aprenderás a graficar distribuciones de probabilidad en Python con las bibliotecas matplotlib y seaborn.\nComenzaremos graficando un histograma, que es una forma común de visualizar la distribución de una variable continua.\nEstas bibliotecas siguen una estructura lógica y consistente que facilita la creación de gráficos complejos."
  },
  {
    "objectID": "docs/24.1-histogramas-python.html#paso-1.-cargar-las-librerías",
    "href": "docs/24.1-histogramas-python.html#paso-1.-cargar-las-librerías",
    "title": "Graficar Distribuciones de Probabilidad en Python",
    "section": "Paso 1. Cargar las librerías",
    "text": "Paso 1. Cargar las librerías"
  },
  {
    "objectID": "docs/24.1-histogramas-python.html#paso-2.-generar-datos",
    "href": "docs/24.1-histogramas-python.html#paso-2.-generar-datos",
    "title": "Graficar Distribuciones de Probabilidad en Python",
    "section": "Paso 2. Generar datos",
    "text": "Paso 2. Generar datos\n\nVamos a crear un dataset de ejemplo con 1000 datos que siguen una distribución normal."
  },
  {
    "objectID": "docs/24.1-histogramas-python.html#paso-3.-crear-un-histograma-básico",
    "href": "docs/24.1-histogramas-python.html#paso-3.-crear-un-histograma-básico",
    "title": "Graficar Distribuciones de Probabilidad en Python",
    "section": "Paso 3. Crear un histograma básico",
    "text": "Paso 3. Crear un histograma básico"
  },
  {
    "objectID": "docs/24.1-histogramas-python.html#cómo-afecta-el-número-de-contenedores-bins",
    "href": "docs/24.1-histogramas-python.html#cómo-afecta-el-número-de-contenedores-bins",
    "title": "Graficar Distribuciones de Probabilidad en Python",
    "section": "¿Cómo afecta el número de contenedores (bins)?",
    "text": "¿Cómo afecta el número de contenedores (bins)?\n\nCambia el número de bins y observa cómo se modifica el gráfico."
  },
  {
    "objectID": "docs/24.1-histogramas-python.html#guardar-el-gráfico-en-un-objeto-y-personalizarlo",
    "href": "docs/24.1-histogramas-python.html#guardar-el-gráfico-en-un-objeto-y-personalizarlo",
    "title": "Graficar Distribuciones de Probabilidad en Python",
    "section": "Guardar el gráfico en un objeto y personalizarlo",
    "text": "Guardar el gráfico en un objeto y personalizarlo"
  },
  {
    "objectID": "docs/24.1-histogramas-python.html#guardar-el-gráfico-como-imagen",
    "href": "docs/24.1-histogramas-python.html#guardar-el-gráfico-como-imagen",
    "title": "Graficar Distribuciones de Probabilidad en Python",
    "section": "Guardar el gráfico como imagen",
    "text": "Guardar el gráfico como imagen"
  },
  {
    "objectID": "docs/24.1-histogramas-python.html#ejemplo-práctico-alturas-de-jirafas",
    "href": "docs/24.1-histogramas-python.html#ejemplo-práctico-alturas-de-jirafas",
    "title": "Graficar Distribuciones de Probabilidad en Python",
    "section": "Ejemplo Práctico: Alturas de Jirafas",
    "text": "Ejemplo Práctico: Alturas de Jirafas\n\nSimulamos datos de alturas de jirafas en dos islas diferentes."
  },
  {
    "objectID": "docs/24.1-histogramas-python.html#histograma-de-alturas-de-jirafas",
    "href": "docs/24.1-histogramas-python.html#histograma-de-alturas-de-jirafas",
    "title": "Graficar Distribuciones de Probabilidad en Python",
    "section": "Histograma de alturas de jirafas",
    "text": "Histograma de alturas de jirafas"
  },
  {
    "objectID": "docs/24.1-histogramas-python.html#personalizar-colores-y-temas",
    "href": "docs/24.1-histogramas-python.html#personalizar-colores-y-temas",
    "title": "Graficar Distribuciones de Probabilidad en Python",
    "section": "Personalizar colores y temas",
    "text": "Personalizar colores y temas"
  },
  {
    "objectID": "docs/24.1-histogramas-python.html#guardar-el-gráfico-de-jirafas",
    "href": "docs/24.1-histogramas-python.html#guardar-el-gráfico-de-jirafas",
    "title": "Graficar Distribuciones de Probabilidad en Python",
    "section": "Guardar el gráfico de jirafas",
    "text": "Guardar el gráfico de jirafas"
  },
  {
    "objectID": "docs/24.1-histogramas-python.html#reflexión",
    "href": "docs/24.1-histogramas-python.html#reflexión",
    "title": "Graficar Distribuciones de Probabilidad en Python",
    "section": "Reflexión",
    "text": "Reflexión\n\n¿Cómo ayuda la visualización a entender mejor los datos?\n¿Qué diferencias observas entre los grupos?\n¿Cómo puedes personalizar tus gráficos para comunicar mejor tus hallazgos?\n\nEstas herramientas te permiten visualizar y comunicar la estructura de tus datos en Python."
  },
  {
    "objectID": "docs/70-ttest-mann-python.html",
    "href": "docs/70-ttest-mann-python.html",
    "title": "Pruebas t para Muestras Independientes y Test de Mann-Whitney con Python",
    "section": "",
    "text": "En esta lección, nos enfocamos en comparar las medias de dos grupos independientes, una tarea común en la investigación para determinar si existen diferencias significativas entre dos poblaciones distintas (por ejemplo, un grupo de tratamiento y un grupo de control).\nPara esto, utilizamos dos pruebas principales:\n\nPrueba t para dos muestras independientes: Evalúa si las medias de dos grupos son significativamente diferentes. Asume que los datos se distribuyen normalmente.\nTest de Mann-Whitney U (o de Wilcoxon-Mann-Whitney): Es la alternativa no paramétrica a la prueba t. Compara las medianas de dos grupos y no requiere normalidad en los datos, ya que trabaja con los rangos.\n\nAmbas pruebas pueden ser vistas como modelos lineales simples que buscan determinar si la pertenencia a un grupo tiene un efecto significativo en la variable de resultado."
  },
  {
    "objectID": "docs/70-ttest-mann-python.html#introducción-a-la-comparación-de-dos-medias",
    "href": "docs/70-ttest-mann-python.html#introducción-a-la-comparación-de-dos-medias",
    "title": "Pruebas t para Muestras Independientes y Test de Mann-Whitney con Python",
    "section": "",
    "text": "En esta lección, nos enfocamos en comparar las medias de dos grupos independientes, una tarea común en la investigación para determinar si existen diferencias significativas entre dos poblaciones distintas (por ejemplo, un grupo de tratamiento y un grupo de control).\nPara esto, utilizamos dos pruebas principales:\n\nPrueba t para dos muestras independientes: Evalúa si las medias de dos grupos son significativamente diferentes. Asume que los datos se distribuyen normalmente.\nTest de Mann-Whitney U (o de Wilcoxon-Mann-Whitney): Es la alternativa no paramétrica a la prueba t. Compara las medianas de dos grupos y no requiere normalidad en los datos, ya que trabaja con los rangos.\n\nAmbas pruebas pueden ser vistas como modelos lineales simples que buscan determinar si la pertenencia a un grupo tiene un efecto significativo en la variable de resultado."
  },
  {
    "objectID": "docs/70-ttest-mann-python.html#puntos-clave",
    "href": "docs/70-ttest-mann-python.html#puntos-clave",
    "title": "Pruebas t para Muestras Independientes y Test de Mann-Whitney con Python",
    "section": "Puntos Clave",
    "text": "Puntos Clave\n\nPrueba t como Modelo Lineal: El modelo predice el resultado (y) basándose en la pertenencia a un grupo. La variable de grupo se codifica numéricamente (ej. 0 y 1), una técnica conocida como codificación dummy. [ y = _0 + _1 ] Donde β₁ representa la diferencia media entre los dos grupos.\nTest de Mann-Whitney U como Modelo Lineal: El concepto es similar, pero el modelo se aplica a los rangos de la variable de resultado en lugar de a sus valores originales. [ (y) = _0 + _1 ]\nCodificación Dummy: Es el proceso de convertir variables categóricas (como los nombres de los grupos) en variables numéricas (0 y 1) para que puedan ser utilizadas en modelos lineales. Las librerías de Python como statsmodels manejan esto automáticamente."
  },
  {
    "objectID": "docs/70-ttest-mann-python.html#ejemplo-en-python-comparación-de-dos-medias",
    "href": "docs/70-ttest-mann-python.html#ejemplo-en-python-comparación-de-dos-medias",
    "title": "Pruebas t para Muestras Independientes y Test de Mann-Whitney con Python",
    "section": "Ejemplo en Python: Comparación de Dos Medias",
    "text": "Ejemplo en Python: Comparación de Dos Medias\nRealicemos una comparación de dos grupos independientes utilizando la prueba t y el test de Mann-Whitney U en Python.\n\nPaso 1: Generar y Visualizar los Datos\nCreamos un conjunto de datos con dos grupos (A y B) y visualizamos sus distribuciones.\n\n\n\n\n\n\n\n\n\n\nPaso 2: Realizar las Pruebas Estadísticas\nAhora, aplicamos las pruebas para comparar las medias de los dos grupos.\n\n\n\n\n\n\n\n\n\n\nInterpretación\n\nPrueba t y Modelo Lineal: El valor p del coeficiente del grupo en el modelo lineal es idéntico al de la prueba t. El coeficiente para grupo[T.B] (5.59) representa la diferencia media entre el grupo B y el grupo A (el de referencia).\nTest de Mann-Whitney U: Proporciona un valor p similar, confirmando que hay una diferencia significativa entre los grupos. Esta prueba es preferible si los datos no son normales.\n\nAmbos enfoques nos llevan a la misma conclusión: existe una diferencia estadísticamente significativa entre los grupos A y B."
  },
  {
    "objectID": "docs/27-pruebas-hipotesis.html",
    "href": "docs/27-pruebas-hipotesis.html",
    "title": "Pruebas de Hipótesis",
    "section": "",
    "text": "Las pruebas de hipótesis son un componente fundamental de la inferencia estadística. Nos permiten evaluar si los datos observados apoyan una hipótesis sobre una población. En esta lección, exploraremos conceptos como los errores tipo I y II, el valor p, y cómo realizar pruebas de hipótesis en R con ejemplos sencillos."
  },
  {
    "objectID": "docs/27-pruebas-hipotesis.html#introducción",
    "href": "docs/27-pruebas-hipotesis.html#introducción",
    "title": "Pruebas de Hipótesis",
    "section": "",
    "text": "Las pruebas de hipótesis son un componente fundamental de la inferencia estadística. Nos permiten evaluar si los datos observados apoyan una hipótesis sobre una población. En esta lección, exploraremos conceptos como los errores tipo I y II, el valor p, y cómo realizar pruebas de hipótesis en R con ejemplos sencillos."
  },
  {
    "objectID": "docs/27-pruebas-hipotesis.html#conceptos-clave",
    "href": "docs/27-pruebas-hipotesis.html#conceptos-clave",
    "title": "Pruebas de Hipótesis",
    "section": "Conceptos Clave",
    "text": "Conceptos Clave\nHipótesis Nula ((H_0)): Afirma que no hay efecto o diferencia. Es la hipótesis que intentamos refutar.\nHipótesis Alternativa ((H_a)): Afirma que hay un efecto o diferencia.\nError Tipo I ((\\alpha)): Rechazar (H_0) cuando es verdadera. El nivel de significancia, usualmente 0.05.\nError Tipo II ((\\beta)): No rechazar (H_0) cuando (H_a) es verdadera.\nValor p: Probabilidad de obtener un resultado igual o más extremo que el observado, asumiendo que (H_0) es cierta."
  },
  {
    "objectID": "docs/27-pruebas-hipotesis.html#ejemplo-de-prueba-de-hipótesis",
    "href": "docs/27-pruebas-hipotesis.html#ejemplo-de-prueba-de-hipótesis",
    "title": "Pruebas de Hipótesis",
    "section": "Ejemplo de Prueba de Hipótesis",
    "text": "Ejemplo de Prueba de Hipótesis\nVerificaremos si los estudiantes de un curso tienen una media de calificación de 75 usando una prueba t de una muestra.\n\nRPython"
  },
  {
    "objectID": "docs/27-pruebas-hipotesis.html#reflexión-y-discusión",
    "href": "docs/27-pruebas-hipotesis.html#reflexión-y-discusión",
    "title": "Pruebas de Hipótesis",
    "section": "Reflexión y Discusión:",
    "text": "Reflexión y Discusión:\nExamina el valor p en el contexto de este ejercicio. ¿Qué concluyes sobre la hipótesis?\nDiscute las implicaciones de cometer un error tipo I o tipo II en el contexto de este análisis. ¿Cómo podrían afectar cada uno de estos errores a las conclusiones y decisiones basadas en esta prueba?\nEsta lección proporciona una introducción práctica a las pruebas de hipótesis en R, mostrando cómo podemos usar herramientas estadísticas para extraer conclusiones con base en datos. Dominar estos conceptos y técnicas te permitirá realizar juicios informados y rigurosos en cualquier análisis estadístico que realices."
  },
  {
    "objectID": "docs/42-ejercicios-evalintroII.html",
    "href": "docs/42-ejercicios-evalintroII.html",
    "title": "Ejercicio Práctico parte II - Estudio de Caso",
    "section": "",
    "text": "En este ejercicio, seguiremos trabajando con el conjunto de datos de la Organización Mundial de la Salud (OMS) sobre la incidencia de enfermedades en diferentes países.\nSi ya obtuviste los datos limpios, puedes continuar con el siguiente paso.\nTus datos limpios deberían verse de la siguiente manera. En este ejercicio, los datos limpios ya están cargados en la variable oms_limpio."
  },
  {
    "objectID": "docs/42-ejercicios-evalintroII.html#antes-de-comenzar",
    "href": "docs/42-ejercicios-evalintroII.html#antes-de-comenzar",
    "title": "Ejercicio Práctico parte II - Estudio de Caso",
    "section": "Antes de comenzar",
    "text": "Antes de comenzar\n\n¿Cuántos países hay en nuestros datos?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\noms_limpio %&gt;%\n  distinct(pais) %&gt;% \n  count()\n\n\n\n\n\nComo ves, son muchos países. Para facilitar el análisis, vamos a filtrar para trabajar solo con algunos países: “México”, “Canadá”, “Bolivia”, “Guatemala”, “Estados Unidos”."
  },
  {
    "objectID": "docs/42-ejercicios-evalintroII.html#exploración-de-datos",
    "href": "docs/42-ejercicios-evalintroII.html#exploración-de-datos",
    "title": "Ejercicio Práctico parte II - Estudio de Caso",
    "section": "Exploración de datos",
    "text": "Exploración de datos\n\nVamos a filtrar y graficar los datos de los países seleccionados.\nNos interesa ver la tendencia de los casos de tuberculosis a través de los años.\n¿Cómo podemos ver tendencias en los datos? ¿Qué tipo de gráfico nos permitiría ver esto?\nSugerencia:\n\nPodríamos usar un gráfico de líneas para ver la tendencia de los casos de tuberculosis a través de los años. Muchas veces en conveniente juntar el gráfico de líneas con un gráfico de puntos para ver mejor la tendencia.\n¿Cómo se llama el geom que se usa para hacer gráficos de líneas en ggplot?\n¿Qué variables usarías en los ejes x y y? ¿Qué variable usarías para el color? ¿qué tipo de variables son estas?\nSugerencia:\n\nEn el eje x, podrías poner el año.\nEn el eje y, podrías poner la cantidad de casos.\nPara el color, podrías poner el país.\n\n\nNOTA: Para agilizar el análisis, vamos a hacer todo en un paso utilizando pipas: tomamos los datos limpios -&gt; filtramos los países -&gt; graficamos. Recuerda que para hacer esto, usamos el operador %&gt;% y para ggplot, usamos el operador + para agregar capas al gráfico.\nVamos a ver el primer ejemplo juntos:\n\n\n\n\n\n\n\n\n\n\n¿Cuál es el problema con el gráfico anterior?\nComo ves, tenemos muchas observaciones por cada país y año. Esto hace que el gráfico sea difícil de interpretar.\n¿Qué podríamos hacer para solucionar esto?\nSugerencia:\n\nPodríamos agrupar los datos por país y año, y promediar los casos de tuberculosis. (también podríamos sumar los casos con sum, ambos son válidos).\nDe esta manera, tendríamos una sola observación por país y año: el promedio de casos de tuberculosis en ese año en cada país.\n\nCompleta el gráfico, agrupando los datos por país y año y promediando los casos de tuberculosis:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\noms_limpio %&gt;%\n  filter(pais %in% c(\"México\", \"Canadá\", \"Bolivia\", \"Guatemala\", \"Estados Unidos\")) %&gt;%\n  group_by(anio, pais) %&gt;%\n  summarise(ncasos = mean(valor)) %&gt;%\n  ggplot(aes(x = anio, y = ncasos, color = pais)) +\n  geom_line() +\n  geom_point()\n\n\n\n\n\n¿Qué puedes observar en el gráfico?\nClaramente hay un país que tiene muchos más casos de tuberculosis que los demás. ¿Cuál es este país?\n\n\n\n\n\n\n\n\n\n\nviewof respuesta = Inputs.radio(\n  [ \"México\", \"Canadá\", \"Estados Unidos\", \"Guatemala\", \"Ninguna de las anteriores\"],\n  { value: \"Ninguna de las anteriores\", label: \"Marca tu respuesta\", class: \"vertical-radio\" }\n);\n\nhtml`${await do_respuestas(respuesta)}`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPor último, grafica el número total de casos de tuberculosis por país. ¿Qué tipo de gráfico usarías para esto? ¿Qué variables usarías en los ejes x y y? ¿Qué variable usarías para el color? ¿Qué tipo de variables son estas?\nSugerencia:\n\nPodrías usar un gráfico de barras para ver el número total de casos de tuberculosis por país.\n¿Cómo se llama el geom que se usa para hacer gráficos de barras en ggplot? Recuerda que tenemos dos formas de hacer gráficos de barras: geom_col y geom_bar. ¿Cuál usarías en este caso?\n¿Qué variables usarías en los ejes x y y? ¿Qué variable usarías para el color? ¿qué tipo de variables son estas?\nSugerencia:\n\nEn el eje x, podrías poner el país.\nEn el eje y, podrías poner el número total de casos. Estos casos los puedes obtener sumando los casos de tuberculosis en cada país.\nPara el color, podrías poner el país. Recuerda que en geom_col, si queremos que las barras tengan un color diferente por cada país, usamos fill para el “relleno” y color para el “borde” de las barras.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\noms_limpio %&gt;%\n  filter(pais %in% c(\"México\", \"Canadá\", \"Bolivia\", \"Guatemala\", \"Estados Unidos\")) %&gt;%\n  group_by(anio, pais) %&gt;%\n  summarise(ncasos = sum(valor)) %&gt;%\n  ggplot(aes(x = pais, y = ncasos, fill = pais)) +\n  geom_col()\n\n\n\n\n\nSigue siendo evidente que un país tiene muchos más casos de tuberculosis que los demás.\nSin embargo, esto puede deberse a muchas razones:\n\npoblación del país: a mayor población, esperamos mayor número de casos.\ncalidad de los servicios de salud: a mejor calidad de los servicios de salud, esperamos menor número de casos.\nla calidad de los datos: es posible que un país tenga un mayor registro de datos que otro. En este caso, podríamos tener un sesgo en los datos.\nentre otras razones.\n\nEn lo que queda del curso, vamos a ver cómo podemos responder a estas preguntas y cómo podemos hacer inferencias sobre nuestros datos.\nEn las siguientes lecciones, veremos cómo podemos hacer pruebas de hipótesis para responder preguntas como: ¿hay una diferencia significativa en el número de casos de tuberculosis entre hombres y mujeres?, ¿hay una diferencia significativa en el número de casos de tuberculosis entre países? Este tipo de preguntas son muy comunes en la investigación científica y en la toma de decisiones basada en datos.\nPor ahora, sigue practicando con tus datos y familiarizándote con las funciones de R y los paquetes de tidyverse. Trata de tomar datos de diferentes fuentes (preferentemente de tu tesis o trabajo) y practica lo que has aprendido en este curso: limpia tus datos, explóralos y visualízalos."
  },
  {
    "objectID": "docs/51-ancova-python.html",
    "href": "docs/51-ancova-python.html",
    "title": "ANCOVA: Análisis de Covarianza con Python",
    "section": "",
    "text": "Lección sobre ANCOVA: Análisis de Covarianza en Ciencias de la Salud y Biológicas\n\nIntroducción al ANCOVA\nEl Análisis de Covarianza (ANCOVA) es una extensión del ANOVA que incluye predictores continuos (covariables) junto con los predictores categóricos. ANCOVA permite ajustar las diferencias entre grupos teniendo en cuenta una covariable continua, como la edad, el peso, o cualquier otra medida continua que pueda influir en la variable dependiente.\nEn un ANCOVA, el modelo lineal incluye tanto las variables categóricas como una o más variables continuas. Este análisis es útil cuando queremos ajustar los efectos de las variables categóricas por una covariable, mejorando la precisión de nuestras estimaciones.\n\n\n\nPuntos clave a enseñar:\n\nANCOVA como modelo lineal: El modelo lineal en un ANCOVA es similar a los que usamos en ANOVA, pero con la adición de un término que representa la covariable continua. Por ejemplo, en un ANCOVA unidireccional, el modelo sería:\n[ y = _0 + _1 x_1 + _2 x_2 + + _3 ]\n\n(_0) es la intersección (la media para el grupo de referencia cuando la covariable es 0).\n(_1), (_2), etc. son los efectos de los grupos categóricos.\n(_3) es el efecto de la covariable continua (en este caso, la edad).\n\nAjuste por covariables: El objetivo principal del ANCOVA es ajustar las diferencias entre los grupos teniendo en cuenta la influencia de una covariable. Esto permite estimar los efectos de los grupos categóricos de manera más precisa.\nCodificación dummy: statsmodels maneja automáticamente la codificación dummy para las variables categóricas cuando se usa la sintaxis de fórmula.\nInterpretación: En un ANCOVA, se pueden interpretar tanto los efectos principales de los grupos categóricos como el efecto de la covariable continua.\n\n\n\n\nEjemplo en Python: ANCOVA\nA continuación, realizamos un ANCOVA utilizando statsmodels y visualizamos los resultados con seaborn.\n\nPaso 1: Generar los datos\nUtilizamos datos simulados y añadimos una covariable continua (age), que está correlacionada con la variable dependiente value.\n\n\n\n\n\n\n\n\n\n\nPaso 2: Visualización del ANCOVA\nCreamos una gráfica que muestra la relación entre la covariable age y la variable dependiente value, utilizando diferentes colores para los grupos.\n\n\n\n\n\n\n\n\n\n\nPaso 3: Códigos en Python: ANCOVA\nPodemos realizar el ANCOVA utilizando statsmodels.\n\n\n\n\n\n\n\n\n\n\nPaso 4: Interpretación de los resultados\nEn el resultado del ANCOVA, podemos examinar los efectos principales de los grupos y de la covariable age. La tabla ANCOVA nos muestra la significancia de cada término en el modelo.\n\n\n\n\nEjercicio Práctico\n\nEjercicio 1: Usa el conjunto de datos mtcars para realizar un ANCOVA, comparando el consumo de combustible (mpg) según el número de cilindros (cyl), ajustando por el peso del automóvil (wt).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRespuesta\n\n\n\n\n\nfrom statsmodels.datasets import get_rdataset\nmtcars = get_rdataset(\"mtcars\", \"datasets\", cache=True).data\n\n# ANCOVA con mtcars\nancova_mpg_cyl_wt_model = smf.ols('mpg ~ C(cyl) + wt', data=mtcars).fit()\nancova_mpg_cyl_wt_table = sm.stats.anova_lm(ancova_mpg_cyl_wt_model, typ=2)\n\n# Mostrar resultados\nprint(ancova_mpg_cyl_wt_table)\nprint(ancova_mpg_cyl_wt_model.summary())\n\n\n\n\n\n\nConclusión\nEl ANCOVA es una herramienta estadística poderosa que combina los efectos de factores categóricos y covariables continuas en un solo modelo. Este análisis permite ajustar por covariables, proporcionando estimaciones más precisas de los efectos de los grupos categóricos. Al entender cómo integrar covariables en un modelo lineal, los estudiantes pueden aplicar ANCOVA para analizar datos más complejos en ciencias de la salud y biológicas."
  },
  {
    "objectID": "docs/21.1-funciones-visualizacion-python.html",
    "href": "docs/21.1-funciones-visualizacion-python.html",
    "title": "Visualización de Datos Básica en Python",
    "section": "",
    "text": "En Python, las bibliotecas más populares para visualización de datos son matplotlib y seaborn. Permiten crear gráficos atractivos y flexibles, desde los más sencillos hasta representaciones complejas, con una sintaxis clara y poderosa."
  },
  {
    "objectID": "docs/21.1-funciones-visualizacion-python.html#introducción",
    "href": "docs/21.1-funciones-visualizacion-python.html#introducción",
    "title": "Visualización de Datos Básica en Python",
    "section": "",
    "text": "En Python, las bibliotecas más populares para visualización de datos son matplotlib y seaborn. Permiten crear gráficos atractivos y flexibles, desde los más sencillos hasta representaciones complejas, con una sintaxis clara y poderosa."
  },
  {
    "objectID": "docs/21.1-funciones-visualizacion-python.html#instalación-y-carga-de-bibliotecas",
    "href": "docs/21.1-funciones-visualizacion-python.html#instalación-y-carga-de-bibliotecas",
    "title": "Visualización de Datos Básica en Python",
    "section": "Instalación y Carga de Bibliotecas",
    "text": "Instalación y Carga de Bibliotecas\nPara usar estas bibliotecas, primero debes asegurarte de tenerlas instaladas:"
  },
  {
    "objectID": "docs/21.1-funciones-visualizacion-python.html#conceptos-básicos-de-matplotlib-y-seaborn",
    "href": "docs/21.1-funciones-visualizacion-python.html#conceptos-básicos-de-matplotlib-y-seaborn",
    "title": "Visualización de Datos Básica en Python",
    "section": "Conceptos Básicos de matplotlib y seaborn",
    "text": "Conceptos Básicos de matplotlib y seaborn\nVamos a usar el conjunto de datos mtcars, que puedes cargar desde un archivo CSV.\n\n\n\n\n\n\n\n\n\nCrear un Gráfico de Dispersión"
  },
  {
    "objectID": "docs/21.1-funciones-visualizacion-python.html#añadir-colores-por-categoría",
    "href": "docs/21.1-funciones-visualizacion-python.html#añadir-colores-por-categoría",
    "title": "Visualización de Datos Básica en Python",
    "section": "Añadir Colores por Categoría",
    "text": "Añadir Colores por Categoría\nColoreamos los puntos según la cantidad de cilindros:"
  },
  {
    "objectID": "docs/21.1-funciones-visualizacion-python.html#crear-un-histograma",
    "href": "docs/21.1-funciones-visualizacion-python.html#crear-un-histograma",
    "title": "Visualización de Datos Básica en Python",
    "section": "Crear un Histograma",
    "text": "Crear un Histograma"
  },
  {
    "objectID": "docs/21.1-funciones-visualizacion-python.html#ejercicio-crear-un-gráfico-básico",
    "href": "docs/21.1-funciones-visualizacion-python.html#ejercicio-crear-un-gráfico-básico",
    "title": "Visualización de Datos Básica en Python",
    "section": "Ejercicio: Crear un Gráfico Básico",
    "text": "Ejercicio: Crear un Gráfico Básico\n\nUsa el conjunto de datos mtcars para crear un gráfico de dispersión de wt (peso) contra mpg.\nAñade un título y etiquetas a los ejes.\nColorea los puntos según gear."
  },
  {
    "objectID": "docs/21.1-funciones-visualizacion-python.html#reflexión",
    "href": "docs/21.1-funciones-visualizacion-python.html#reflexión",
    "title": "Visualización de Datos Básica en Python",
    "section": "Reflexión",
    "text": "Reflexión\n\n¿Cómo ayuda la visualización a entender mejor los datos que estás analizando?\nExplora otros conjuntos de datos y trata de visualizar relaciones clave o distribuciones interesantes.\n\nEsta lección te ofrece un vistazo rápido al poder de matplotlib y seaborn, preparando el terreno para futuras exploraciones más profundas en visualización de datos."
  },
  {
    "objectID": "docs/30-variables-intro.html",
    "href": "docs/30-variables-intro.html",
    "title": "Introducción a los Tipos de Variables en Estadística con R",
    "section": "",
    "text": "En ciencia, para poner a prueba hipótesis y responder preguntas de investigación, medimos variables, que son elementos que pueden cambiar o variar. Estas variables pueden diferir entre personas dentro de una población (como la altura), entre lugares (como los niveles de desempleo) o con el tiempo (como el estado de ánimo a lo largo del día).\nLas hipótesis generalmente se formulan en términos de dos variables: una que se propone como la causa y otra como el efecto o resultado."
  },
  {
    "objectID": "docs/30-variables-intro.html#introducción",
    "href": "docs/30-variables-intro.html#introducción",
    "title": "Introducción a los Tipos de Variables en Estadística con R",
    "section": "",
    "text": "En ciencia, para poner a prueba hipótesis y responder preguntas de investigación, medimos variables, que son elementos que pueden cambiar o variar. Estas variables pueden diferir entre personas dentro de una población (como la altura), entre lugares (como los niveles de desempleo) o con el tiempo (como el estado de ánimo a lo largo del día).\nLas hipótesis generalmente se formulan en términos de dos variables: una que se propone como la causa y otra como el efecto o resultado."
  },
  {
    "objectID": "docs/30-variables-intro.html#conceptos-clave",
    "href": "docs/30-variables-intro.html#conceptos-clave",
    "title": "Introducción a los Tipos de Variables en Estadística con R",
    "section": "Conceptos Clave",
    "text": "Conceptos Clave\n\nVariable Independiente (VI)\n\nEs la variable que se considera la causa en una relación.\nEn experimentos, la variable independiente es aquella que se manipula deliberadamente para observar su impacto en otra variable.\nEjemplo: En un experimento sobre el impacto de las horas de estudio en el rendimiento académico, las “horas de estudio” serían la variable independiente.\n\n\n\nVariable Dependiente (VD)\n\nEs la variable que se cree que es afectada por la variable independiente. Es el resultado que se mide.\nEjemplo: Continuando con el ejemplo anterior, la “calificación en el examen” sería la variable dependiente, ya que depende de las horas de estudio.\n\n\n\nVariable Predictora y de Resultado\n\nEn estudios donde no se manipulan las variables directamente (como en estudios observacionales o correlacionales), los términos “variable independiente” y “variable dependiente” pueden no ser los más adecuados.\nEn su lugar, se utilizan los términos variable predictora (equivalente a la independiente) y variable de resultado (equivalente a la dependiente). Este enfoque es útil en estudios donde una o más variables se utilizan para predecir el resultado.\nEjemplo: En un estudio donde se analiza si el nivel socioeconómico predice el rendimiento académico, el nivel socioeconómico sería la variable predictora, mientras que el rendimiento académico sería la variable de resultado."
  },
  {
    "objectID": "docs/30-variables-intro.html#introducción-1",
    "href": "docs/30-variables-intro.html#introducción-1",
    "title": "Introducción a los Tipos de Variables en Estadística con R",
    "section": "Introducción",
    "text": "Introducción\nLas variables pueden clasificarse en diferentes tipos, lo que nos ayuda a comprender mejor los datos y a aplicar las técnicas estadísticas adecuadas.\n\nVariables Categóricas (Cualitativas)\nEstas variables representan categorías o grupos. Pueden clasificarse en diferentes subtipos:\n\nNominales:\n\n\nNo tienen un orden particular. Las categorías son solo nombres o etiquetas.\nEjemplo: Tipo de mascota (perro, gato, pájaro).\n\n\nOrdinales:\n\n\nTienen un orden o jerarquía, pero las diferencias entre categorías no son cuantificables o no son iguales.\nEjemplo: Puesto en una carrera (primero, segundo, tercero).\nEjemplo: Grados de satisfacción (muy insatisfecho, insatisfecho, satisfecho, muy satisfecho).\n\n\n\n\nVariables Binarias (Dicotómicas)\n\nSolo tienen dos categorías mutuamente excluyentes.\nEjemplo: Estado civil (casado/no casado), resultado de un examen (aprobado/reprobado).\n\n\n\nVariables Cuantitativas (Numéricas)\nEstas variables representan cantidades o valores numéricos. Pueden ser de dos tipos:\n\nContinuas:\n\n\nPueden tomar cualquier valor dentro de un rango. Es decir, entre dos valores cualesquiera, puede haber infinitos valores intermedios.\nEjemplo: Altura, peso, temperatura.\n\n\nDiscretas:\n\n\nSolo pueden tomar ciertos valores específicos, generalmente enteros.\nEjemplo: Número de hijos, número de autos en una familia.\n\n\n\n\nImportancia de los Tipos de Variables\nEs fundamental comprender el tipo de variable que estamos analizando, ya que esto influirá en las técnicas estadísticas que debemos utilizar. Por ejemplo, las pruebas aplicables a datos categóricos pueden ser diferentes de las que aplicamos a datos nu```{pyodide}méricos."
  },
  {
    "objectID": "docs/30-variables-intro.html#ejercicio-práctico-en-r-trabajando-con-diferentes-tipos-de-variables",
    "href": "docs/30-variables-intro.html#ejercicio-práctico-en-r-trabajando-con-diferentes-tipos-de-variables",
    "title": "Introducción a los Tipos de Variables en Estadística con R",
    "section": "Ejercicio Práctico en R: Trabajando con Diferentes Tipos de Variables",
    "text": "Ejercicio Práctico en R: Trabajando con Diferentes Tipos de Variables\n\nComo veremos en lo que resta del curso, es importante entender qué tipo de variable estamos tratando para elegir el método de análisis adecuado.\nIdentifica los diferentes tipos de variables que tenemos en el siguiente conjunto de datos:\nLos datos ya se encuentran cargados en el ejercicio en la variable datos_tipos_variables\nPrimero, vamos a explorar los datos con la función head() para ver las primeras filas.\n\n\nRPython\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA dimple vista, podemos determinar lo siguiente:\nID: Es una variable discreta.\nResultado_Examen: Es una variable categórica ordinal.\nEstado_Civil: Es una variable categórica nominal.\nVivo_Muerto: Es una variable categórica binaria.\nTemperatura: Es una variable continua.\nAnxiety_Score: Es una variable continua.\n\nSin embargo, existen diferentes formas de explorar los tipos de datos con diferentes funciones en R.\n\nRPython\n\n\nstr() - Podemos usar la función str() para obtener una descripción de las variables en el conjunto de datos. - Esta función nos proporciona información sobre el tipo de variable y los primeros valores de cada columna.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObserva que nos dice:\nEl número de observaciones (100).\nEl número de variables (6).\nEl nombre de las variables.\nID es identificada como un número entero (Int que significa integer).\nResultado_Examen, Estado_Civil y Vivo_Muerto son factores. Los factores son variables categóricas. También nos muestra los niveles de cada factor, que son las categorías o valores que puede tomar la variable. Por ejemplo, Resultado_Examen tiene 4 niveles: Fail, Pass, Merit, Distinction. La palabra Ord. significa que es una variable ordinal.\nLas variables Temperatura y Anxiety_Score son numéricas (num).\n\n\nRPython\n\n\nsummary() - Esta función nos proporciona un resumen de las variables en el conjunto de datos. - Observa que para las variables categóricas, nos muestra la frecuencia de cada nivel, es decir, cuántas veces aparece cada categoría en el conjunto de datos. - Para las variables numéricas, nos muestra un resumen estadístico, incluyendo la media, la mediana, los cuartiles, el mínimo y el máximo.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRPython\n\n\n\nglimpse()\n\nPodemos usar la función glimpse() del paquete dplyr para obtener un resumen de las variables en el conjunto de datos.\nUna ventaja de ver los datos con esta función es que nos muestra el tipo de variable que R ha asignado a cada columna.\nNOTa: en esta presentación no se alcanza a visualizar la salida completa de la función glimpse(), pero en tu computadora podrás verla completa.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRPython\n\n\n\nsapply() y class()\n\nsapply() es una función que aplica una función a cada elemento de una lista o vector.\nclass() es una función que nos permite obtener el tipo de variable de un objeto en R.\nPodemos usar sapply() con class() para obtener el tipo de variable de cada columna en el conjunto de datos.\n\n\n\n\n\n\n\n\n\n\n\n\n\nsapply() y class() / dtypes\n\nEn pandas, podemos usar el atributo .dtypes para obtener el tipo de dato de cada columna en el DataFrame."
  },
  {
    "objectID": "docs/30-variables-intro.html#cambiando-el-tipo-de-variable-recodificar",
    "href": "docs/30-variables-intro.html#cambiando-el-tipo-de-variable-recodificar",
    "title": "Introducción a los Tipos de Variables en Estadística con R",
    "section": "Cambiando el Tipo de Variable (recodificar)",
    "text": "Cambiando el Tipo de Variable (recodificar)\n\nRPython\n\n\n\nA veces, necesitamos cambiar el tipo de variable de una columna en un conjunto de datos.\nPor ejemplo, si una variable categórica se ha leído como numérica, necesitamos cambiarla.\nEsto se conoce como recodificar."
  },
  {
    "objectID": "docs/30-variables-intro.html#ejercicio-1-variables-de-carácter",
    "href": "docs/30-variables-intro.html#ejercicio-1-variables-de-carácter",
    "title": "Introducción a los Tipos de Variables en Estadística con R",
    "section": "Ejercicio 1: Variables de Carácter",
    "text": "Ejercicio 1: Variables de Carácter\nEn este ejercicio, los estudiantes deben crear una variable de carácter y verificar su tipo de dato.\n\nInstrucciones:\n\nReemplaza el guion bajo (______) por un texto entre comillas para crear una variable de carácter.\nCorre el código para verificar que el tipo de dato sea correcto.\n\n\nRPython\n\n\n\n\n\n\n\n\n\n\nEl tipo de dato debería ser character. Si el estudiante ha hecho todo correctamente, la salida de typeof(caracter) será \"character\".\n\n\n\n\n\n\n\n\n\n\n\n\n\nEl tipo de dato debería ser character. Si el estudiante ha hecho todo correctamente, la salida de typeof(caracter) será \"character\"."
  },
  {
    "objectID": "docs/30-variables-intro.html#ejercicio-2-variables-numéricas",
    "href": "docs/30-variables-intro.html#ejercicio-2-variables-numéricas",
    "title": "Introducción a los Tipos de Variables en Estadística con R",
    "section": "Ejercicio 2: Variables Numéricas",
    "text": "Ejercicio 2: Variables Numéricas\nEn este ejercicio, los estudiantes deben crear una variable numérica y verificar su tipo de dato.\n\nInstrucciones:\n\nReemplaza el guion bajo (______) por un número para crear una variable numérica.\nCorre el código para verificar que el tipo de dato sea correcto.\n\n\nRPython\n\n\n\n\n\n\n\n\n\n\nEl tipo de dato debería ser numeric. Si el estudiante ha hecho todo correctamente, la salida de typeof(numerica) y class(numerica) será \"double\" o \"numeric\".\n\n\n\n\n\n\n\n\n\n\n\n\n\nEl tipo de dato debería ser numeric. Si el estudiante ha hecho todo correctamente, la salida de typeof(numerica) y class(numerica) será \"double\" o \"numeric\".\n\n\n\n\n\n\n\n\nExplicación:\n\nEn el Ejercicio 1, el objetivo es que creen una variable que contenga texto, lo que en términos de programación en R se denomina una variable de carácter. El texto siempre debe ir entre comillas dobles o simples.\nEn el Ejercicio 2, deben crear una variable que contenga un número, lo que en R se conoce como una variable numérica. En este caso, pueden usar cualquier número (decimales o enteros)."
  },
  {
    "objectID": "docs/32-visualizacion-datos-python.html#introducción",
    "href": "docs/32-visualizacion-datos-python.html#introducción",
    "title": "Ejercicio I Visualización y Distribución de Datos con Python",
    "section": "Introducción",
    "text": "Introducción\n\nEn este ejercicio vamos a realizar gráficos utilizando seaborn y matplotlib.\n\nRecordemos lo siguiente:\n\nUn gráfico es un mapeo de variables de datos a atributos estéticos de objetos geométricos.\n\nAunque esta “gramática de gráficos” es la base de ggplot2 en R, los principios se aplican a seaborn en Python. Tiene tres componentes principales:\n\nDatos (data): el DataFrame de pandas que contiene las variables que queremos graficar.\nGeometría (geom): el tipo de gráfico que queremos crear (puntos, líneas, barras, etc.). En seaborn, esto se elige con funciones como scatterplot(), lineplot(), barplot().\nEstética (aes): atributos visuales del gráfico. Por ejemplo, la posición x e y, el color, la forma y el tamaño. Cada atributo estético se puede asignar a una columna de nuestro DataFrame."
  },
  {
    "objectID": "docs/32-visualizacion-datos-python.html#ejemplo-de-la-gramática-en-un-gráfico",
    "href": "docs/32-visualizacion-datos-python.html#ejemplo-de-la-gramática-en-un-gráfico",
    "title": "Ejercicio I Visualización y Distribución de Datos con Python",
    "section": "Ejemplo de la gramática en un gráfico",
    "text": "Ejemplo de la gramática en un gráfico\nVamos a ver un ejemplo de estos componentes en un gráfico. Para ello vamos a utilizar el paquete gapminder que ya está cargado.\nPara ver los datos de gapminder, puedes usar gapminder.head() en el bloque de código para ver las primeras filas, gapminder.describe() para un resumen estadístico, o gapminder.info() para ver la estructura de los datos.\n\n\n\n\n\n\n\n\nComo puedes ver, los datos de gapminder contienen información sobre la esperanza de vida (lifeExp), el PIB per cápita (gdpPercap) y la población de varios países a lo largo del tiempo. pop es la población, continent es el continente al que pertenece el país y year es el año de la observación.\n\nVeamos un gráfico a través de la gramática de los gráficos.\nEl siguiente gráfico está realizado con los datos de gapminder. Intentemos reconocer qué variables y secciones corresponden a la gramática de gráficos:\n\n\n\n\n\n\n\n\nMirando el código y el gráfico, podemos identificar que:\n\nDatos: el DataFrame gapminder se asigna al parámetro data.\nEstética: el eje x representa la variable gdpPercap, el eje y representa la variable lifeExp, el color (o hue) representa la variable continent y el tamaño (size) representa la variable pop.\nGeometría: generamos un gráfico de puntos, como indica la función scatterplot().\n\n\n\nCambiemos algunas propiedades\nSupongamos que queremos cambiar los ejes del gráfico. ¿Cómo cambiarías el código anterior para que el eje x represente la esperanza de vida y el eje y el PIB per cápita?\n\n\n\n\n\n\n\n\n\nRecuerda que los ejes están representados por los parámetros x (horizontal) e y (vertical).\n\n\nSolution. \nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ngapminder = pd.read_csv('./datos/gap_minder.tsv', sep='\\t')\nsns.scatterplot(data=gapminder, x='lifeExp', y='gdpPercap', hue='continent', size='pop', sizes=(20, 200))\nplt.show()\n\n¡Bien hecho!\nAdemás del gráfico de puntos (scatterplot), seaborn ofrece otros tipos de gráficos, como gráficos de líneas (lineplot), de barras (barplot), de áreas (fill_between de matplotlib) o histogramas (histplot)."
  },
  {
    "objectID": "docs/32-visualizacion-datos-python.html#gráfico-de-líneas",
    "href": "docs/32-visualizacion-datos-python.html#gráfico-de-líneas",
    "title": "Ejercicio I Visualización y Distribución de Datos con Python",
    "section": "Gráfico de líneas",
    "text": "Gráfico de líneas\nVamos a realizar otros gráficos utilizando los datos en gapminder. Para generar el gráfico de líneas, vamos a ver la evolución de la población de México. Los gráficos de líneas son útiles para mostrar la evolución de una variable a lo largo del tiempo.\nPrimero, filtra los datos de gapminder para obtener solo los datos de México y guárdalos en un nuevo DataFrame llamado Mex.\n\n\n\n\n\n\n\n\n\nRecuerda que el nombre del país es Mexico y que la columna que contiene el nombre del país es country.\n\n\nSolution. \nMex = gapminder[gapminder['country'] == 'Mexico']\nprint(Mex.head())\n\nAhora, a partir de los datos de México, crea un gráfico de línea (lineplot) que muestre en el eje x los años y en el y la población.\n\n\n\n\n\n\n\n\n\n\nEl DataFrame se llama Mex.\nLa variable que contiene los años se llama year.\nLa variable que contiene la población se llama pop.\n\n\n\nSolution. \nsns.lineplot(data=Mex, x='year', y='pop')\nplt.show()\n\n\nHagamos un gráfico de barras\nEn seaborn, barplot es ideal cuando quieres que la altura de la barra represente una estimación de una variable numérica para cada categoría. Si ya tienes los valores que quieres para la altura de las barras (como en nuestro caso, la población para cada año), barplot funciona perfectamente.\nVamos a transformar el gráfico anterior a barras.\n\n\n\n\n\n\n\n\n\nLos parámetros data, x e y son los mismos que en el gráfico de líneas.\n\n\nSolution. \nsns.barplot(data=Mex, x='year', y='pop')\nplt.show()\n\n\n\nHagamos un gráfico de área\nPara gráficos de área, podemos usar la función fill_between de matplotlib sobre un gráfico de líneas.\nModifica el siguiente código para generar un gráfico de áreas que nos muestre los años en el eje x y la población en el eje y.\n\n\n\n\n\n\n\n\n\nfill_between necesita los valores del eje x y los valores del eje y.\n\n\nSolution. \nplt.plot(Mex['year'], Mex['pop'])\nplt.fill_between(Mex['year'], Mex['pop'], alpha=0.3)\nplt.show()"
  },
  {
    "objectID": "docs/32-visualizacion-datos-python.html#visualizar-distribución-normal",
    "href": "docs/32-visualizacion-datos-python.html#visualizar-distribución-normal",
    "title": "Ejercicio I Visualización y Distribución de Datos con Python",
    "section": "Visualizar Distribución Normal",
    "text": "Visualizar Distribución Normal\n\nRecuerda que la distribución normal tiene 2 parámetros: la media \\(\\mu\\) y la desviación estándar \\(\\sigma\\).\n\nPara una distribución normal estandarizada, la media es 0 y la desviación estándar es 1.\nEscribe el código de Python necesario para simular y graficar los valores de una distribución normal usando scipy.stats.norm.pdf().\n\n\n\n\n\n\n\n\n\nnorm.pdf toma como argumentos el vector de valores (x), la media (loc) y la desviación estándar (scale).\n\n\nSolution. \nx = np.linspace(-5, 5, 100)\nmean = 0\nsd = 1\n\ny = norm.pdf(x, loc=mean, scale=sd)\n\nplt.plot(x, y)\nplt.show()"
  },
  {
    "objectID": "docs/32-visualizacion-datos-python.html#fuentes",
    "href": "docs/32-visualizacion-datos-python.html#fuentes",
    "title": "Ejercicio I Visualización y Distribución de Datos con Python",
    "section": "Fuentes",
    "text": "Fuentes\nEsperamos que esta pequeña introducción a los gráficos en Python te sea de utilidad. A continuación te dejamos una serie de materiales que pueden resultar muy útiles para continuar aprendiendo:\n\nGalería de Seaborn\nTutorial de Seaborn\nGalería de Matplotlib\nThe Python Graph Gallery"
  },
  {
    "objectID": "docs/32-visualizacion-datos-python.html#licencia",
    "href": "docs/32-visualizacion-datos-python.html#licencia",
    "title": "Ejercicio I Visualización y Distribución de Datos con Python",
    "section": "Licencia",
    "text": "Licencia\nEste curso se comparte bajo la licencia Creative Commons Attribution-ShareAlike 4.0 International License y fue realizado por Yanina Bellini Saibene y adaptado a Python por Santiago Garcia y GitHub Copilot."
  },
  {
    "objectID": "docs/71-ttest-wilcoxon.html#introducción",
    "href": "docs/71-ttest-wilcoxon.html#introducción",
    "title": "Prueba t y el Test de Rango de Wilcoxon",
    "section": "Introducción",
    "text": "Introducción\nLa prueba t de una muestra y el test de rango de Wilcoxon son herramientas fundamentales para evaluar si la media de una muestra es significativamente diferente de un valor hipotético. Ambos tests pueden interpretarse como modelos lineales simples, donde el objetivo es predecir la media de la variable dependiente.\n\nPrueba t de muestra única: Evalúa si la media de una muestra es significativamente diferente de un valor de referencia.\nTest de rango con signo de Wilcoxon: Es una alternativa no paramétrica a la prueba t para muestras únicas, que evalúa si la mediana de una muestra es significativamente diferente de un valor de referencia, utilizando los rangos de los datos en lugar de los valores originales.\n\n\n\nPuntos Clave\n\nPrueba t de muestra única como modelo lineal: El modelo lineal en este caso predice la media de la variable dependiente (\\(y\\)):\n\\[\ny = \\beta_0\n\\]\ndonde \\(\\beta_0\\) es la media de la muestra y se compara con el valor de referencia (hipótesis nula: \\(\\beta_0 = 0\\).\n\n\n\n\n\n\n\nNote\n\n\n\nObserva que la ecuación anterior es lo mismo que:\n\\[\n   y = \\beta_0 + \\beta_1 \\cdot x\n   \\]\nSolamente que no ponemos el último término ya que no tenemos una variable independiente (recuerda que estamos hablando de una muestra única). Por lo tanto, \\(x = 0\\).\n\n\n\nTest de Wilcoxon como modelo lineal: Similar a la prueba t, pero en lugar de usar los valores originales de \\(y\\), se utilizan los rangos con signo de \\(y\\):\n\\[\n{rango.signo}(y) = \\beta_0\n\\]\n\n\nEste test es útil cuando los datos no cumplen con los supuestos de normalidad.\n\n\n\n\n\n\n\nrango con signo\n\n\n\n\nPreviamente, vimos que si ordenamos en rango con la función rank(c(3.6, 3.4, -5.0, 8.2)), el resultado es 3, 2, 1, 4.\nUn rango con signo es lo musmo, pero el rango se obtiene, primero con el tamaño absoluto y luego se le asigna el signo original. En el ejemplo anterior, el rango con signo sería 2, 1, -3, 4.\n\n\n\n\nEquivalencia de los tests con modelos lineales: Tanto la prueba t como el test de Wilcoxon pueden expresarse como un modelo lineal simple, lo que permite interpretar los resultados de manera similar."
  },
  {
    "objectID": "docs/71-ttest-wilcoxon.html#ejemplo-en-r-prueba-t-de-una-muestra-y-test-de-wilcoxon",
    "href": "docs/71-ttest-wilcoxon.html#ejemplo-en-r-prueba-t-de-una-muestra-y-test-de-wilcoxon",
    "title": "Prueba t y el Test de Rango de Wilcoxon",
    "section": "Ejemplo en R: Prueba t de una muestra y Test de Wilcoxon",
    "text": "Ejemplo en R: Prueba t de una muestra y Test de Wilcoxon\nA continuación, vamos a realizar ambos tests (t-test y Wilcoxon) utilizando R y visualizaremos los resultados.\n\nPaso 1: Generar los datos\nVamos a trabajar con los datos guardados en la variable D_t1, que contiene una muestra de 20 observaciones con una media de 0.5 y una desviación estándar de 0.6.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaso 2: Visualización\nEl siguiente gráfico muestra los datos y la media de la muestra y (0.5) en azul. Los datos individuales están etiquetados con su valor.\n\n\n\n\n\n\n\n\nAhora, aplicamos la transformación de rangos con signo a los mismos datos y creamos una gráfica similar. No te preocupes si no entiendes el código, lo importante es que veas la gráfica y los rangos.\n\n\n\n\n\n\n\n\n\n\n\nt-test\nLa prueba t de una muestra puede realizarse fácilmente con la función t.test() en R, pero también se puede obtener el mismo resultado usando un modelo lineal con la función lm(). - Observa que para el modelo lineal, usamos y ~ 1 para indicar que solo estamos interesados en la media de la variable y, es decir, el intercepto. - En la función t.test(), especificamos la variable y del dataset D_t1. - Vamos a obtener los mismos resultados con ambos métodos: - La prueba t de una muestra: - media = 0.5 - valor-p = 0.00143 - Modelo lineal: - coeficiente = 0.5 - p-valor = 0.00143\n\n\n\n\n\n\n\n\n\n\nTest de Rango con Signo de Wilcoxon\nEl test de Wilcoxon se puede realizar con la función wilcox.test(), y también se puede realizar usando un modelo lineal aplicado a los rangos con signo. - Sin embargo, en este caso, los resultados no serán exactamente iguales, ya que el test de Wilcoxon y el modelo lineal tienen diferentes distribuciones de referencia para calcular el valor p. - En ambos casos se rechabza la hipótesis nula de que la media es cero, pero los valores p son diferentes. Abajo del gráfico se explica por qué.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\nEn el test de Wilcoxon, el estadístico es la suma de los rangos con signo (estadístico V).\nEn el modelo lineal, el estadístico es el valor t asociado al intercepto del modelo, que estima la media de los rangos con signo.\nAunque ambos enfoques están relacionados con los rangos con signo, el test de Wilcoxon y el modelo lineal tienen diferentes distribuciones de referencia para calcular el valor p (veremos esto en el tema siguiente de prueba de hipótesis).\n\nEl test de Wilcoxon utiliza la distribución exacta de los rangos\nEl modelo lineal utiliza la distribución t\n\n\nRegresaremos a la discusión de cómo diferentes pruebas pueden producir valores p diferentes en el tema de prueba de hipótesis. Por ahora soloobserva que podemos realizar la prueba de Wilcoxon con un modelo lineal o con la función wilcox.test()."
  },
  {
    "objectID": "docs/71-ttest-wilcoxon.html#pruebas-t-para-muestras-pareadas-y-test-de-wilcoxon",
    "href": "docs/71-ttest-wilcoxon.html#pruebas-t-para-muestras-pareadas-y-test-de-wilcoxon",
    "title": "Prueba t y el Test de Rango de Wilcoxon",
    "section": "Pruebas t para Muestras Pareadas y Test de Wilcoxon",
    "text": "Pruebas t para Muestras Pareadas y Test de Wilcoxon\n\nmuestra pareada: se refiere a dos mediciones tomadas en la misma unidad experimental, como antes y después de un tratamiento, o dos mediciones en el mismo individuo."
  },
  {
    "objectID": "docs/71-ttest-wilcoxon.html#teoría-pruebas-t-para-muestras-pareadas",
    "href": "docs/71-ttest-wilcoxon.html#teoría-pruebas-t-para-muestras-pareadas",
    "title": "Prueba t y el Test de Rango de Wilcoxon",
    "section": "Teoría: Pruebas t para Muestras Pareadas",
    "text": "Teoría: Pruebas t para Muestras Pareadas\nEn una prueba t para muestras pareadas, el objetivo es evaluar si las diferencias entre dos mediciones (por ejemplo, antes y después de un tratamiento) son significativamente diferentes de cero. Esto se puede interpretar como un modelo lineal donde la diferencia entre las dos mediciones es el valor de \\(y\\):\n\\[\ny_2 - y_1 = \\beta_0\n\\]\nLa hipótesis nula \\(H_0\\) en este caso es \\(\\beta_0 = 0\\).\nDe manera similar, el test de Wilcoxon para pares es la versión no paramétrica de la prueba t para muestras pareadas y se basa en los rangos con signo de las diferencias entre las dos muestras:\n\\[\n{rango.signo}(y_2 - y_1) = \\beta_0\n\\]\n\n\n\nSimplificando un poco, puedes pensar que la diferencia de medias en este caso son pendientes, como en la figura izquierda que presenta los datos de un mismo individuo en un tiempo 1 y un tiempo 2. Estas diferencias de pendientes se pueden evaluar mediante la prueba t-pareada, como en la figura de la derecha.\n\n\n\nCódigos en R: Prueba t para Muestras Pareadas\n\nVamos a trabajar con los datos guardados en los vectores antes y despues, que contiene dos mediciones (antes y después) de 10 sujetos.\n\n\n\n\n\n\n\n\n\n\nPara la prueba t para muestras pareadas, usamos la función t.test() con el argumento paired = TRUE.\n\n\n\n\n\n\n\n\n\n\nPara hacerlo como un modelo lineal, tenemos que usar la notación: lm(y - y2 ~ 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nVes que obtenemos los mismos resultados con ambos métodos?\n\nEn la prueba t para muestras pareadas:\n\nmedia de las diferencias = -0.54\nvalor-p = 0.0492\n\nEn el modelo lineal:\n\ncoeficiente (intercepto) = -0.54\np = 0.0492\n\n\n\n\n\n\n\nCódigos en R: Test de Wilcoxon para Pares\nEl test de Wilcoxon para pares es la versión no paramétrica de la prueba t para muestras pareadas y se basa en los rangos con signo de las diferencias entre las dos muestras. - De nuevo, los valores p serán similares, pero no exactamente iguales.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLas pruebas NO paramétricas NO comparan medias!!\n\n\n\nComo hemos visto y observaras en el output anterior, las pruebas no paramétricas no comparan las medias como lo hacen las pruebas paramétricas. En su lugar, estas pruebas se basan en rangos en lugar de valores absolutos.\n\nEn las pruebas paramétricas (como el t-test o ANOVA), se comparan las medias entre los grupos o condiciones.\nEn las pruebas no paramétricas, no se comparan directamente las medias. En lugar de ello, se comparan medianas, rangos o distribuciones de los datos. Esto hace que las pruebas no paramétricas sean más robustas cuando los datos no son normales o contienen valores atípicos.\n\n\n\n\n\n\nConclusión\nLas pruebas t de muestra única y para muestras pareadas, junto con sus contrapartes no paramétricas (Wilcoxon), son herramientas poderosas para evaluar diferencias en medias. Al entender que estos tests pueden expresarse como modelos lineales simples, podemos unificar el análisis de estas pruebas y aplicar este conocimiento a una amplia variedad de datos y situaciones.\nMás adelante, veremos cómo usar ggpubr para visualizar los resultados de estas pruebas y obtener gráficos con los resultados de los tests:"
  }
]